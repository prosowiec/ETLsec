ticker,year,quarter,transcriptID,transcript,date
META,2024,1,2024-Q1-META,"Operator: Good afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta First Quarter Earnings Conference Call. [Operator Instructions] This call will be recorded. Thank you very much. 
 Ken Dorell, Meta's Director of Investor Relations, you may begin. 
Kenneth Dorell: Thank you. Good afternoon, and welcome to Meta Platform's First Quarter 2021 Earnings Conference Call. Joining me today to discuss our results are Mark Zuckerberg, CEO; and Susan Li, CFO. 
 Before we get started, I would like to take this opportunity to remind you that our remarks today will include forward-looking statements. Actual results may differ materially from those contemplated by these forward-looking statements. Factors that could cause these results to differ materially are set forth in today's earnings press release and in our annual report on Form 10-K filed with the SEC. 
 Any forward-looking statements that we make on this call are based on assumptions as of today, and we undertake no obligation to update these statements as a result of new information or future events. 
 During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.fb.com. 
 And now I'd like to turn the call over to Mark. 
Mark Zuckerberg: All right. Thanks, Ken, and everyone, thanks for joining. It's been a good start to the year, both in terms of product momentum and business performance. We estimate that more than 3.2 billion people use at least one of our apps each day, and we're seeing healthy growth in the U.S. And I want to call out WhatsApp specifically, where the number of daily actives and message sends in the U.S. keeps gaining momentum, and I think we're on a good path there. We've also made good progress on our AI and metaverse efforts, and that's where I'm going to focus most of my comments today. 
 So let's start with AI. We're building a number of different AI services, from Meta AI, our AI assistant that you can ask any question across our apps and glasses, to creator AIs that help creators engage their communities and that fans can interact with, to business AIs that we think every business eventually on our platform will use to help customers buy things and get customer support to internal coding and development AIs to hardware like glasses for people to interact with AIs and a lot more. 
 Last week, we had the major release of our new version of Meta AI that is now powered by our latest model, Llama 3. And our goal with Meta AI is to build the world's leading AI service, both in quality and usage.
 The initial rollout of Meta AI is going well. Tens of millions of people have already tried it. The feedback is very positive. And when I first checked in with our teams, the majority of feedback we were getting was people asking us to release Meta AI for them wherever they are. So we've started launching Meta AI in some English speaking countries, and we'll roll out in more languages and countries over the coming months.
 You all know our product development playbook by this point. We release an early version of a product to a limited audience to gather feedback and start improving it, and then once we think it's ready, then we make it available to more people. That early release was last fall and with this release, we are now moving to that next growth phase of our playbook. We believe that Meta AI with Llama 3 is now the most intelligent AI assistant that you can freely use. And now that we have the superior quality product, we are making it easier for lots of people to use it within WhatsApp, Messenger, Instagram and Facebook. 
 Now in addition to answering more complex queries, a few other notable and unique features from this release. Meta AI now creates animations from still images and now generates high-quality images so fast that it can create and update them as you are typing, which is pretty awesome. I've seen a lot of people commenting about that experience online and how they've never seen or experienced anything like it before. 
 In terms of the core AI model and intelligence that's powering Meta AI, I'm very pleased with how Llama 3 has come together so far. The 8 billion and 70 billion parameter models that we released are best-in-class for their scale. The 400-plus billion parameter model that we're still training seems on track to be industry leading on several benchmarks. And I expect that our models are just going to improve further from open source contributions. 
 Overall, I view the results our teams have achieved here as another key milestone in showing that we have the talent, data and ability to scale infrastructure to build the world's leading AI models and services. And this leads me to believe that we should invest significantly more over the coming years to build even more advanced models and the largest scale AI services in the world. As we're scaling CapEx and energy expenses for AI, we'll continue focusing on operating the rest of our company efficiently. But realistically, even with shifting many of our existing resources to focus on AI, we'll still grow our investment envelope meaningfully before we make much revenue from some of these new products.
 I think it's worth calling that out that we've historically seen a lot of volatility in our stock during this phase of our product playbook, where we're investing in scaling a new product but aren't yet monetizing it. We saw this with Reels, Stories as newsfeed transition to mobile and more. And I also expect to see a multiyear investment cycle before we fully scale Meta AI, business AIs and more into the profitable services I expect as well. Historically, investing to build these new scaled experiences in our apps has been a very good long-term investment for us and for investors who have stuck with us. And the initial signs are quite positive here, too. But building the leading AI will also be a larger undertaking than the other experiences we've added to our apps, and this is likely going to take several years. 
 On the upside, once our new AI services reach scale, we have a strong track record of monetizing them effectively. There are several ways to build a massive business here, including scaling business messaging, introducing ads or paid content into AI interactions and enabling people to pay to use bigger AI models and access more compute. And on top of those, AI is already helping us improve app engagement, which naturally leads to seeing more ads and improving ads directly to deliver more value. So if the technology and products evolve in the way that we hope, each of those will unlock massive amounts of value for people and business for us over time. 
 We're seeing good progress on some of these efforts already. Right now, about 30% of the posts on Facebook feed are delivered by our AI recommendation system. That's up 2x over the last couple of years. And for the first time ever, more than 50% of the content that people see on Instagram is now AI recommended. AI has also been a huge part of how we create value for advertisers by showing people more relevant ads. And if you look at our 2 end-to-end AI-powered tools, Advantage+ shopping and Advantage+ app campaigns, revenue flowing through those has more than doubled since last year. 
 We're also going to continue to be very focused on efficiency as we scale Meta AI and other AI services. Some of this will come from improving how we train and run models. Some improvements will come from the open source community, and we're improving cost efficiency is one of the main areas that I expect that open sourcing will help us improve similar to what we saw with Open Compute. We'll also keep making progress on building more of our own silicon. Our Meta training and inference accelerator chip has successfully enabled us to run some of our recommendations-related workloads on this less expensive stack. And as this program matures over the coming years, we plan to expand this to more of our workloads as well. And of course, as we ramp these investments, we will also continue to carefully manage headcount and other expense growth throughout the company. 
 Now in addition to our work on AI, our other long-term focus is the metaverse. It's been interesting to see how these 2 themes have come together. 
 This is clearest when you look at glasses. I used to think that AR glasses wouldn't really be a mainstream product until we had full holographic displays -- and I still think that, that's going to be awesome and is the long-term mature state for the product. But now it seems pretty clear that there's also a meaningful market for fashionable AI glasses without a display. Glasses are the ideal device for an AI assistant because you can let them see what you see and hear what you hear. So they have full context on what's going on around you as they help you with whatever you're trying to do. Our launch this week of Meta AI with Vision on the glasses is a good example where you can now ask questions about things that you're looking at. 
 Now one strategy dynamic that I've been reflecting on is that an increasing amount of our Reality Labs work is going towards serving our AI efforts. We currently report on our financials as if Family of Apps and Reality Labs were 2 completely separate businesses, but strategically, I think of them as fundamentally the same business with the vision of Reality Labs to build the next generation of computing platforms in large part so that we can build the best apps and experiences on top of them. Over time, we'll need to find better ways to articulate the value that's generated here across both segments so it doesn't just seem like our hardware costs increase as our glasses ecosystem scales, but all the value flows to a different segment. 
 The Ray-Ban Meta glasses that we built with Essilor Luxottica continue to do well and are sold out in many styles and colors. So we're working to make more and release additional styles as quickly as we can. We just released the new cat-eye Skyler design yesterday, which is more feminine. And in general, I'm optimistic about our approach of starting with the classics and expanding with an increasing diversity of options over time. If we want everyone to be able to use wearable AI, I think eyewear is a bit different from phones or watches in that people are going to want very different designs. So I think our approach of partnering with the leading eyewear brands will help us serve more of the market. 
 I think a similar open ecosystem approach will help us expand the virtual and mixed reality headset market over time as well. We announced that we're opening up Meta Horizon OS, the operating system we've built to power Quest. As the ecosystem grows, I think there will be sufficient diversity in how people use mixed reality, that there will be demand for more designs than we'll be able to build. For example, a work-focused headset may be slightly less designed for motion but may -- you want to be lighter by connecting to your laptop; a fitness-focused headset may be lighter with sweat-wicking materials; an entertainment-focused headset may prioritize the highest resolution displays over everything else; a gaming-focused headset may prioritize peripherals and haptics or a device that comes with Xbox controllers and a game pass subscription out of the box.  
 Now to be clear, I think that our first-party Quest devices will continue to be the most popular headsets as we see today, and we'll continue focusing on advancing the state-of-the-art tech and making it accessible to everyone. But I also think that opening our ecosystem and opening our operating system will help the overall mixed reality ecosystem grow even faster.  
 Now in addition to AI and the metaverse, we're seeing good improvements across our apps. I touched on some of the most important trends already with WhatsApp growth in the U.S. and AI-powered recommendations in our feeds and reels already. But I do want to mention that video continues to be a bright spot. This month, we launched an updated full-screen video player on Facebook that brings together reels, longer videos and live content into a single experience with a unified recommendation system. On Instagram, reels and video continue to drive engagement, with reels alone now making up 50% of the time that's spent within the app.
 Threads is growing well, too. There are now more than 150 million monthly actives, and it continues to generally be on the trajectory that I hoped to see. And of course, my daughters would want me to mention that Taylor Swift is now on Threads, that one was a big deal in my house. 
 All right. That is what I wanted to cover today. I am proud of the progress we've made so far this year. We've got a lot more execution ahead to fulfill the opportunities ahead of us. A big thank you to all of our teams who are driving all these advances and to all of you for being on this journey with us. And now here is Susan. 
Susan Li: Thanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis unless otherwise noted. Q1 total revenue was $36.5 billion, up 27% on both a reported and constant currency basis. Q1 total expenses were $22.6 billion, up 6% compared to last year.  
 In terms of the specific line items, cost of revenue increased 9% as higher infrastructure-related costs were partially offset by lapping Reality Labs' inventory-related valuation adjustments. R&D increased 6%, driven mostly by higher headcount-related expenses and infrastructure costs, which were partially offset by lower restructuring costs.  
 Marketing and sales decreased 16% due mainly to lower restructuring costs, professional services and marketing spend. G&A increased 20% as higher legal-related expenses were partially offset by lower restructuring costs.  
 We ended the first quarter with over 69,300 employees, up 3% from Q4. First quarter operating income was $13.8 billion, representing a 38% operating margin. Our tax rate for the quarter was 13%. Net income was $12.4 billion or $4.71 per share.  
 Capital expenditures, including principal payments on finance leases, were $6.7 billion, driven by investments in servers, data centers and network infrastructure. Free cash flow was $12.5 billion. We repurchased $14.6 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders, ending the quarter with $58.1 billion in cash and marketable securities and $18.4 billion in debt.  
 Moving now to our segment results. I'll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, with approximately 3.2 billion people using at least one of our Family of Apps on a daily basis in March. Q1 total Family of Apps revenue was $36 billion, up 27% year-over-year. Q1 Family of Apps ad revenue was $35.6 billion, up 27% or 26% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year-over-year growth, followed by gaming and entertainment and media. 
 On a user geography basis, ad revenue growth was strongest in Rest of World and Europe at 40% and 33%, respectively. Asia Pacific grew 25% and North America grew 22%. In Q1, the total number of ad impressions served across our services increased 20%, and the average price per ad increased 6%. Impression growth was mainly driven by Asia Pacific and Rest of World. Pricing growth was driven by advertiser demand, which was partially offset by strong impression growth, particularly from lower-monetizing regions and services.  
 Family of Apps other revenue was $380 million in Q1, up 85%, driven by business messaging revenue growth from our WhatsApp business platform. We continue to direct the majority of our investments toward the development and operation of our Family of Apps. In Q1, Family of Apps expenses were $18.4 billion, representing approximately 81% of our overall expenses. Family of Apps expenses were up 7% due mainly to higher legal and infrastructure costs that were partially offset by lower restructuring costs.  
 Family of Apps operating income was $17.7 billion, representing a 49% operating margin. Within our Reality Labs segment, Q1 revenue was $440 million, up 30%, driven by Quest headset sales. Reality Labs expenses were $4.3 billion, down 1% year-over-year as higher head count-related expenses were more than offset by lapping inventory-related valuation adjustments and restructuring costs. Reality Labs operating loss was $3.8 billion.  
 Turning now to the business outlook. There are 2 primary factors that drive our revenue performance: our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we remain pleased with engagement trends and have strong momentum across our product priorities. Our investments in developing increasingly advanced recommendation systems continue to drive incremental engagement on our platform, demonstrating that people are finding added value by discovering content from accounts they are not connected to. The level of recommended content in our apps has scaled as we've improved these systems, and we see further opportunity to increase the relevance and personalization of recommendations as we advance our models.  
 Video also continues to grow across our platform, and it now represents more than 60% of time on both Facebook and Instagram. Reels remains the primary driver of that growth, and we're progressing on our work to bring together Reel's longer-form video and live video into one experience on Facebook.  
 In April, we rolled out this unified video experience in the U.S. and Canada, which is increasingly powered by our next-generation ranking architecture that we expect will help deliver more relevant video recommendations over time.  
 We're also introducing deeper integrations of generative AI into our apps in the U.S. and more than a dozen other countries. Along with using Meta AI within our chat surfaces, people will now be able to use Meta AI in search within our apps as well as feed and groups on Facebook. We expect these integrations will complement our social discovery strategy as our recommendation systems help people to discover and explore their interests, while Meta AI enables them to dive deeper on topics they're interested in. Threads also continues to see good traction as we continue to ship valuable features and scale the community.  
 Now to the second driver of our revenue performance, increasing monetization efficiency. There are 2 parts to this work. The first is optimizing the level of ads within organic engagement. Here, we continue to advance our understanding of users' preferences for viewing ads to more effectively optimize the right time, place and person to show an ad to.  
 For example, we are getting better at adjusting the placement and number of ads in real time based on our perception of a user's interest and ad content and to minimize disruption from ads as well as innovating on new and creative ad formats. We expect to continue that work going forward, while surfaces with relatively lower levels of monetization, like video and messaging, will serve as additional growth opportunities. 
 The second part of improving monetization efficiency is enhancing marketing performance. Similar to our work with organic recommendations, AI is playing an increasing role in these efforts. First, we are making ongoing ads modeling improvements that are delivering better performance for advertisers. One example is our new ads ranking architecture, Meta Lattice, which we began rolling out more broadly last year. This new architecture allows us to run significantly larger models that generalize learnings across objectives and surfaces in place of numerous smaller ad models that have historically been optimized for individual objectives and surfaces. This is not only leading to increased efficiency as we operate fewer models but also improving ad performance. 
 Another way we're leveraging AI is to provide increased automation for advertisers. Through our Advantage+ portfolio, advertisers can automate one step of the campaign setup process, such as selecting which ad creative to show, or automate their campaign completely using our end-to-end automation tools, Advantage+ shopping and Advantage+ app ads. We're seeing growing use of these solutions, and we expect to drive further adoption over the course of the year while applying what we learned to our broader ads investments. 
 Next, I'd like to discuss our approach to capital allocation. We continue to see compelling investment opportunities to both improve our core business in the near term and capture significant longer-term opportunities in generative AI and Reality Labs. As we develop more advanced and compute-intensive recommendation models and scale capacity for our generative AI training and inference needs, we expect that having sufficient infrastructure capacity will be critical to realizing many of these opportunities. As a result, we expect that we will invest significantly more in infrastructure over the coming years. 
 Our other long-term initiatives that we're continuing to make significant investments in is Reality Labs. We are also starting to see our AI initiatives increasingly overlap with our Reality Labs work. For example, with Ray-Ban Meta smart glasses, people in the U.S. and Canada can now use our multimodal Meta AI assistant for daily tasks without pulling out their phone. 
 Longer term, we expect generative AI to play an increasing role in our mixed reality products, making it easier to develop immersive experiences. Accelerating our AI efforts will help ensure we can provide the best version of our services as we transition to the next computing platform. We expect to pursue these opportunities while maintaining a focus on operating discipline, and we believe our strong financial position will allow us to support these investments while also returning capital to shareholders through share repurchases and dividends. 
 In addition, we continue to monitor an active regulatory landscape, including the increasing legal and regulatory headwinds in the EU and the U.S. that could significantly impact our business and our financial results. We also have a jury trial scheduled for June in a suit brought by the state of Texas regarding our use of facial recognition technology, which could ultimately result in a material loss.  
 Turning now to the revenue outlook. We expect second quarter 2024 total revenue to be in the range of $36.5 billion to $39 billion. Our guidance assumes foreign currency is a 1% headwind to year-over-year total revenue growth based on current exchange rates.  
 Turning now to the expense outlook. We expect full year 2024 total expenses to be in the range of $96 million to $99 billion, updated from our prior outlook of $94 million to $99 billion due to higher infrastructure and legal costs.  
 For Reality Labs, we continue to expect operating losses to increase meaningfully year-over-year due to our ongoing product development efforts and our investments to further scale our ecosystem.  
 Turning now to the CapEx outlook. We anticipate our full year 2024 capital expenditures will be in the range of $35 billion to $40 billion, increased from our prior range of $30 billion to $37 billion as we continue to accelerate our infrastructure investments to support our AI road map. While we are not providing guidance for years beyond 2024, we expect CapEx will continue to increase next year as we invest aggressively to support our ambitious AI research and product development efforts.  
 On to tax. Absent any changes to our tax landscape, we expect our full year 2024 tax rate to be in the mid-teens.  
 In closing, Q1 was a good start to the year. We're seeing strong momentum within our Family of Apps and are making important progress on our longer-term AI and Reality Labs initiatives that have the potential to transform the way people interact with our services over the coming years.  
 With that, Krista, let's open up the call for questions. 
Operator: [Operator Instructions] And your first question comes from the line of Eric Sheridan from Goldman Sachs. 
Eric Sheridan: Maybe I'll ask a two-parter. Mark, you used the analogy of other investments cycles you've been through around products like Stories and Reels. I know you're not giving long-term guidance today, but using those analogies, how should investors think about the length and depth of this investment cycle with respect to either AI and/or Reality Labs more broadly and mixed reality?  
 And you both talked about the impact AI is having on the advertising ecosystem. What are you watching for in terms of adoption or utility on the consumer side to know that AI adoption is tracking along with the investment cycle? 
Mark Zuckerberg: Yes. In terms of the timing, I think it's somewhat difficult to extrapolate from previous cycles. But I guess like the main thing that we see is that we will usually take, I don't know, a couple of years, I mean, it could be a little more, it could be less to focus on building out and scaling the products. And we typically don't focus that much on monetization of the new areas until they reach significant scale because it's so much higher leverage for us just to improve monetization on other things before these new products are at scale.  
 So you enter this period where I think kind of smart investors see that the product is scaling and that there's a clear monetizable opportunity there even before the revenue materializes. And I think we've seen that with Reels and with Stories and with the shift to mobile and all these things, where basically, we build out the inventory first for a period of time and then we monetize it.  
 And during that time, when it's scaling, sometimes it's not just the case that we're not making money from that thing. It can often actually be the case that it displaces other revenue from other things. So like you saw with Reels, I mean, it scaled and there was a period where it was not profitable for us as it was scaling before it became profitable. So I think that's more the analogy that I'm making on this.  
 But I think it's -- what that suggests is that what we should all be focused on for the next period is as the consumer products scale, Meta AI really just launched in a meaningful way so we don't have any kind of hard stats to share on that. But I'd say that's the main thing that I'm focused on for this year and probably a lot of next year is growing that product and the other AI products and the engagement around them. And I think we should all have quite a bit of confidence that if those are on a good track to scale, then they're going to end up being very large businesses. So that's the main point that I was trying to make there. 
Operator: Your next question comes from the line of Brian Nowak from Morgan Stanley. 
Brian Nowak: Thanks for taking my questions, I have 2. The first one is on sort of the recommendation engine improvements and even, Susan, when you talked about further opportunities to increase the relevance of the models. Could you just unpack that a little bit for us? Can you give us examples of where you're still running the model in a suboptimal basis or opportunities for improved signal capture use or data you're not using? Where are sort of the areas of improvement you see from here?  
 And then the second one, when you talk about driving incremental adoption of AI tools for advertisers, what are sort of some of the main gating factors you've encountered to get advertisers to test these tools? And how do you think about sort of addressing that throughout '24 and '25? 
Susan Li: Thanks, Brian. So to your first question, where are there more opportunities for us to leverage and improve our recommendations models to drive engagement? One of the things I would say is, historically, each of our recommendation products, including Reels, in-feed recommendations, et cetera, has had their own AI model.  
 And recently, we've been developing a new model architecture with the aim for it to power multiple recommendations products. We started partially validating this model last year by using it to power Facebook Reels. And we saw meaningful performance gains, 8% to 10% increases in watch time as a result of deploying this.  
 This year, we're actually planning to extend the singular model architecture to recommend content across not just Facebook Reels, but also Facebook's video tab as well. So while it's still too early to share specific results, we're optimistic that the new model architecture will unlock increasingly relevant video recommendations over time. And if it's successful, we'll explore using it to power other recommendations.  
 And analog exists, I would say, on the ad side. We've talked a little bit about the new model architecture Meta Lattice that we deployed last year that consolidates smaller and more specialized models into larger models that can better learn what characteristics improve ad performance across multiple services, like feed and Reels and multiple types of ads and objectives at the same time. And that's driven improved ad performance over the course of 2023 as we deployed it across Facebook and Instagram to support multiple objectives.  
 And over the course of 2024, we expect to further enhance model performance and include support for even more objectives like web and app and ROAS. So there's a lot of work that we're investing in, in the underlying model architecture for both organic engagement and ads that we expect is going to continue to deliver increasing ads performance over time.  
 The second question you asked was around getting advertisers to test and adopt gen AI tools. There are 2 flavors of this. The more near-term version is around the gen AI ad creative features that we have put into our ads creation tools. And it's early, but we're seeing adoption of these features across verticals and different advertiser sizes.  
 In particular, we've seen outsized adoption of image expansion with small businesses, and this will remain a big area of focus for us in 2024, and I expect that improvements to our underlying foundation models will enhance the quality of the outputs that are generated and support new features on the road map. But right now, we have features supporting text variations, image expansion and background generation, and we're continuing to work to make those more performant for advertisers to create more personalized ads at scale.  
 The longer-term piece here is around business AIs. We have been testing the ability for businesses to set up AIs for business messaging that represent them in chats with customers, starting by supporting shopping use cases such as responding to people asking for more information on a product or its availability. So this is very, very early. We've been testing this with a handful of businesses on Messenger and WhatsApp, and we're hearing good feedback with businesses saying that the AIs have saved them significant time while customer -- consumers noted more timely response times. And we're also learning a lot from these tests to make these AIs more performant over time as well. So we'll be expanding these tests over the coming months, and we'll continue to take our time here to get it right before we make it more broadly available. 
Operator: Your next question comes from the line of Mark Shmulik from Bernstein Research. 
Mark Shmulik: I guess back to that product playbook that we talked about a few times, with kind of Reels now such a large share of kind of time spent on Instagram and Facebook, how do we think about the next leg of kind of monetization growth from here? In particular, as we kind of get back to kind of shopping on platform or other ways to monetize, any color there on the road map kind of just beyond ad insertion from here?  
 And then, Susan, just on the ad market, in particular, previously, we heard a lot about kind of Chinese-based advertiser contribution. Any color you could share there on kind of how that spend is trending? 
Susan Li: Sure. Thanks, Mark. So Reels revenue continued to grow across Instagram and Facebook in Q1, and that's driven both by higher engagement and increased monetization efficiency through our ads ranking and delivery improvements. And we -- as we've mentioned before, we don't plan on quantifying the impact from Reels going forward, but it remains a positive contributor to overall revenue. And we expect that there are going to be opportunities for us to continue improving performance and growing supply.   
 So on the performance improvements, we are investing in ongoing ranking improvements. We're continuing to make ads easier and more intuitive to interact with through work like optimizing call to actions and post-click experiences, which are especially important for DR performance. And we're also optimizing ads to feel more native to Reels.  
 In Q1, we rolled out our gen AI image expansion tools across Facebook and Instagram Reels after having introduced it to Instagram feed in Q4, and we're seeing, again, outsized adoption with small businesses. So we're excited about the opportunities to continue making these ads more performant. And even though ads -- the Reels ad loads, sorry, has increased over the last year, it remains lower on a per time basis than both Feed and Stories. So we're going to continue to look for opportunities to thoughtfully grow it in the future and invest in creative ways to address the structural supply constraints of the Reels format being more video-heavy, including higher density experiences and formats and increasingly personalizing ad loads, which we think will make sure that we're really putting ads in front of people when they're most likely to be interested and engaged with them.  
 The second question you asked was around China. Growth in spend from China advertisers remained strong in Q1. This was driven by online commerce and gaming, and it's reflected in our Asia Pacific advertisers segment, which remained the fastest-growing region, at 41% year-over-year in Q1. Now we did see strength across other geographies as well, including a 6-point acceleration in total revenue growth from North America advertisers.  
 So I would say that we aren't quantifying the Q1 contribution from China, and we don't have forward-looking expectations to share on quarterly China-based ad revenue, but I will say that we are lapping periods of increasingly strong demand over the course of 2024 given the recovery of China-based advertisers in 2023 from their prior pandemic-driven headwinds. 
Operator: Your next question comes from the line of Doug Anmuth from JPMorgan. 
Douglas Anmuth: Can you just talk about what's changed most in your view in the business and the opportunity now versus 3 months ago? And is there anything you're more cautious about in revenue in the ad market? And is the AI opportunity just even bigger, and therefore, requiring more investment than expected? 
 And then, Susan, can you also just comment on how you're thinking about that ability to sustain growth rates over the next few quarters as you face tougher comps off a big base of ad dollars? 
Mark Zuckerberg: Yes, I can speak to the first one. I think we've gotten more optimistic and ambitious on AI. So previously, I think that our work in this -- I mean when you were looking at last year, when we released Llama 2, we were very excited about the model and thought that, that was going to be the basis to be able to build a number of things that were valuable that integrated into our social products. But now I think we're in a pretty different place. So with the latest models, we're not just building good AI models that are going to be capable of building some new good social and commerce products. I actually think we're in a place where we've shown that we can build leading models and be the leading AI company in the world. And that opens up a lot of additional opportunities beyond just ones that are the most obvious ones for us.  
 So that's -- this is what I was trying to refer to in my opening remarks where I just view the success that we've seen with the way that Llama 3 and Meta AI have come together as a real validation technically that we have the talent, the data and the ability to scale infrastructure to do leading work here.  
 And with Meta AI, I think that we are on our path to having Meta AI be the most used and best AI assistant in the world, which I think is going to be enormously valuable. So all of that basically encourages me to make sure that we're investing to stay at the leading edge of this.  
 And we're doing that at the time when we're also scaling the product before it is making money. So that's the analogy that I was making before, which is we've gone through some of those cycles before. But fundamentally, I think if you look at the facts of what our team is able to produce, I think it just -- our optimism and ambition have just grown quite a bit, and I think that this is just going to end up being quite an important set of products for us. So it was already going to be. Now I think it has the potential to be even more important. 
Susan Li: And I can take that second question, Doug. So we aren't giving full year 2024 guidance. And obviously, our revenue for the full year will be influenced by many factors, including macro conditions and things that are harder to predict the further out you go. And of course, over the course of 2024, we will also be lapping periods of increasingly strong demand. With that said, we expect to see good opportunities to continue growing engagement across our products, driven by the investments we made in AI-based content recommendations, our ongoing video work. And we also expect that we will continue to drive ads performance gains and continue to make our ads sort of more effective and deliver increasing value to advertisers.  
 One thing I'd share, for example, is that we actually grew conversions at a faster rate than we grew impressions over the course of this quarter. So we are -- we're expecting to -- which basically suggests that our conversion grade is growing and is one of the ways in which our ads are becoming more performant. So I feel like there's a lot of opportunity for us, both with our organic engagement growth and with continuing to make the ads better and to continue driving more results for advertisers. 
Operator: Your next question comes from the line of Justin Post from Bank of America. 
Justin Post: First on the CapEx, mostly, you're kind of talking about an investment cycle here. Is there any way you could kind of use some of the metaverse spend over into AI? Are they converging and kind of use some of the money from the other areas to kind of fund the AI?  
 And then second, longer-term investors are very focused on returns on capital. Obviously, great returns on CapEx in the past with your margins today. How do we think about the returns on the capital you're spending? How are you thinking about it, I guess, going forward 2, 3 years out? 
Susan Li: So on the -- I would say -- well, I can start with the second part, and then I'll defer to Mark on the first one. In terms of measuring the ROI on our CapEx investments, we've broadly categorized our AI investments into 2 buckets. I think of them as sort of core AI work and then strategic bets, which would include gen AI and the advanced research efforts to support that. And those are just really at different stages as it relates to being able to measure the return and drive revenue for our business. So with our core AI work, we continue to have a very ROI-driven approach to investment, and we're still seeing strong returns as improvements to both engagement and ad performance have translated into revenue gains.  
 Now the second area, strategic bets, is where we are much earlier. Mark has talked about the potential that we believe we have to create significant value for our business in a number of areas, including opportunities to build businesses that don't exist on us today. But we'll need to invest ahead of that opportunity to develop more advanced models and to grow the usage of our products before they drive meaningful revenue.  
 So while there is tremendous long-term potential, we're just much earlier on the return curve than with our core AI work. What I'll say though is we're also building our systems in a way that gives us fungibility in how we use our capacity so we can flex it across different use cases as we identify what are the best opportunities to put that infrastructure toward. 
Mark Zuckerberg: And then on the question of shifting resources from other parts of the company. I would say, broadly, we actually are doing that in a lot of places in terms of shifting resources from other areas, whether it's compute resources or different things in order to advance the AI efforts. For Reality Labs specifically, I'm still really optimistic about building these new computing platforms long term. I mentioned in my remarks upfront that one of the bigger areas that we're investing in Reality Labs is glasses. We think that that's going to be a really important platform for the future.  
 Our outlook for that, I think, has improved quite a bit because previously, we thought that, that would need to wait until we have these full holographic displays to be a large market. And now we're a lot more focused on the glasses that we're delivering in partnership with Ray-Ban, which I think are going really well. And -- so that, I think, has the ability to be a pretty meaningful and growing platform sooner than I would have expected. So it is true that more of the Reality Labs work, like I said, is sort of focused on the AI goals as well. But I still think that we should focus on building these long-term platforms, too. 
Operator: Your next question comes from the line of Youssef Squali from Truist Securities. 
Youssef Squali: Mark, with the upcoming ban or sale of TikTok signed into law earlier today, how do you think that will impact the U.S. social media landscape? And then, in particular, what do you say to people who believe that this is potentially a slippery slope in terms of the government picking up -- picking winners and losers? 
 And Susan, how big is Advantage+ in terms of the spend on the platform and just in terms of its impact on overall CPM stabilizing? 
Susan Li: Thanks, Youssef. We've obviously been following the events related to TikTok closely, but at this stage, it is just too early, I think, to assess its impact or what it would mean for our business. 
 To your second question on Advantage+, we're continuing to see good traction across our Advantage+ portfolio, including both with solutions, I mentioned this, that automate individual steps of a campaign creation setup as well as ones that automate the full end-to-end process. So on the single-step automation, Advantage+ audience, for example, has seen significant growth in adoption since we made it the default audience creation experience for most advertisers in Q4. And that enables advertisers to increase campaign performance by just using audience inputs as a suggestion rather than a hard constraint. And based on tests that we ran, campaigns using Advantage+ audience targeting saw, on average, a 28% decrease in cost per click or per objective compared to using our regular targeting.  
 On the end-to-end automation products like Advantage+ shopping and Advantage+ app campaigns, we're also seeing very strong growth. Mark mentioned the combined revenue flowing through those 2 has more than doubled since last year. And we think there's still significant runway to broaden adoption, so we're trying to enable more conversion types for Advantage+ shopping. In Q1, we began expanding the list of conversions that businesses could optimize for. So previously, it only supported purchase events, and now we've added 10 additional conversion types. And we're continuing to see strong adoption now across verticals.  
 So generally, I would say we are building a lot more functionality into the Advantage+ tools over time. also where a lot of our gen AI ads creative features have been introduced and where advertisers have the opportunity to experiment with those. And we'll keep looking to apply what we learn from these products more broadly to our ads investments over the course of the year. 
Operator: Your next question comes from the line of Ken Gawrelski from Wells Fargo. 
Kenneth Gawrelski: As you look out through the coming period of product investment, how should we think about the relationship between Family of Apps revenue and cost growth? Is there any insight you can give us there? 
 And then maybe just one that's a little bit more specific to the G&A growth in 1Q. You called out legal expenses. Just wanted to see if there's anything onetime in there that would cause the elevated growth in 1Q. 
Susan Li: Yes. On the second part of your question first, so on the G&A side, that was really driven by legal expenses. We recognized some accruals in Q1 related to ongoing legal matters, and you'll see more detail on that in the 10-Q. 
 On the first part of your question, which is really about sort of the kind of long-term margin profile of Family of Apps, we aren't giving guidance on that per se. But one of the things that we really have been very disciplined about over the course of 2023 and continuing is really operating the business in a very efficiency oriented way. So we're being very disciplined with allocation of new resources. This is a muscle that we really built over 2023 that we believe is important for us to keep carrying forward. And I think you'll see us continue to emphasize that, especially with the Family of Apps business being at the scale that it is. 
Operator: Your next question comes from the line of Ross Sandler from Barclays. 
Ross Sandler: Great. Mark, you partnered with Google and Bing for Meta AI organic search citations. So I guess stepping back, do you think that Meta AI longer term could bring in search advertising dollars at some point? Or do you view this as what others are doing, where you kind of attach a premium subscription tier once people kind of get going on it? 
 And then the second question is, you mentioned that you guys are working on building AI tools for businesses and creators. So just, I guess, how do you see the business model evolving when we all get to the stage of interacting with something like Taylor Swift's custom AI for merchandise or tickets or something like that. How is that going to play out? 
Mark Zuckerberg: All right. So yes, on the Google and Microsoft partnerships, yes, I mean we work with them to have real-time information in Meta AI. It's useful. I think it's pretty different from search. We're not working on search ads or anything like that. I think this will end up being a pretty different business. 
 I do think that there will be an ability to have ads and paid content in Meta AI interactions over time as well as people being able to pay for whether it's bigger models or more compute or some of the premium features and things like that. But that's all very early in fleshing out. 
 The thing that I actually think is probably -- the biggest clear opportunity is all the work around business messaging. That's in addition to the stuff that we're already doing, just generate to increase engagement and ads quality in the apps. But business messaging thing, I mean, whether it's a creator or one of the 100-plus million businesses on our platform, we basically want to make it very easy for all of these folks to set up an AI to engage with their community. For a business, that's going to be able to do sales and commerce and customer support. And I think it will be similar for creators, although there will be more of a kind of just fun and engaging part there, but a lot of creators are on the platform because they see this as a business too, whether they're trying to sell concert tickets or products or whatever it is that their business goal is. 
 And a lot of these folks either aren't advertising as much as they could or, in business, the business messaging parts, I think, are still relatively undermonetized compared to where they will be. And I think a lot of that is because the cost of engaging with people in messaging is still very high. But AI should bring that down just dramatically for businesses and creators. And I think that, that has the potential. That's probably the -- beyond just increasing engagement and increasing the quality of the ads, I think that, that's probably one of the nearer-term opportunities, even though that will -- it's not like next quarter or the quarter after that scaling thing, but it's -- but that's not like a 5-year opportunity either. 
 So I think -- that is one that I think is going to be pretty exciting to look at. But yes, I mean, as Meta AI scales too, I think that, that will have its own opportunities to monetize, and we'll build that out over time. But like I tried to emphasize, we're in the phase of this where the main goal is getting many hundreds of millions or billions of people to use Meta AI as a core part of what they do. That's the kind of next goal, building something that is super valuable. We think this has the potential to be at a very large scale. And that's sort of the next step on the journey. 
Kenneth Dorell: Krista, we have time for one last question. 
Operator: And that question comes from the line of Ron Josey from Citi. 
Ronald Josey: Mark, I want to follow up on a prior question that you mentioned optimism has grown internally quite a bit just with all the improvements and investments and innovations you're making. And we're seeing that in the experience for a few days of Meta AI. So can you just talk to us maybe how the $400 billion parameter model just might evolve the experience on Meta or how you think things might change over the next, call it, months, years, et cetera, as maybe messaging becomes a greater focus and things along those lines? So just a vision longer term. 
Mark Zuckerberg: Yes. I mean I think that the next phase for a lot of these things are handling more complex tasks and becoming more like agents rather than just chat bots, right? So when I say chatbot, what I mean is you send it a message and it replies to your message, right? So it's almost like almost a 1:1 correspondence. 
 Whereas what an agent is going to do is you give it an intent or a goal, then it goes off and probably actually performs many queries on its own in the background in order to help accomplish your goal, whether that goal is researching something online or eventually finding the right thing that you're looking to buy. There's a lot of complexity and sort of different things. I think people don't even realize that they will be able to ask computers to do for them. 
 And I think basically, the larger models and then the more advanced future versions that will be smaller as well are just going to enable much more interesting interactions like that. So I mean if you think about this, I mean, even some of the business use cases that we talked about, you don't really just want like sales or customer support chatbot that can just respond to what you say. And if you're a business, you have a goal, right? You're trying to support your customers well and you're trying to position your products in a certain way and encourage people to buy certain things that map to their interests and would they be interested in? And that's more of like a multiturn interaction, right? 
 So the type of business agent that you're going to be able to enable with just a chatbot is going to be very naive compared to what we're going to have in a year even, but beyond that, too, is just the reasoning and planning abilities if these things grow to be able to just help guide people through the business process of engaging with whatever your goals are as a creator of a business. 
 So I think that that's going to be extremely powerful. And I think the opportunity is really big. So -- and on top of that, I think what we've shown now is that we have the ability to build leading models in our company. So I think it makes sense to go for it, and we're going to. And I think it's going to be a really good long-term investment. But I did just want to spell out on this call today, the extent to which we're focusing on this and investing in this for the long term because that's what we do. 
Kenneth Dorell: Great. Thank you for joining us today. We appreciate your time, and we look forward to speaking with you again soon. 
Operator: This concludes today's conference call. Thank you for your participation, and you may now disconnect.",2024-04-24
META,2024,2,2024-Q2-META,"Operator: Good afternoon. My name is Krista and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta Second Quarter Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers’ remarks there will be a question-and-answer session. [Operator Instructions] This call will be recorded. Thank you very much. Kenneth Dorell, Meta's Director of Investor Relations, you may begin.
Kenneth Dorell : Thank you. Good afternoon and welcome to Meta Platform's Second Quarter 2024 Earnings Conference Call. Joining me today to discuss our results are Mark Zuckerberg, CEO, and Susan Li, CFO. Before we get started, I would like to take this opportunity to remind you that our remarks today will include forward-looking statements. Actual results may differ materially from those contemplated by these forward-looking statements. Factors that could cause these results to differ materially are set forth in today's earnings press release and in our Quarterly Report on Form 10-Q, filed with the SEC. Any forward-looking statements that we make on this call are based on assumptions as of today and we undertake no obligation to update these statements as a result of new information or future events. During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying Investor Presentation are available on our website at investor.fb.com. And now I'd like to turn the call over to Mark.
Mark Zuckerberg : All right, thanks Ken. And hey everyone, thanks for joining today. This was a strong quarter for our community and business. We estimate that there are now more than 3.2 billion people using at least one of our apps each day. The growth we're seeing here in the US has especially been a bright spot. WhatsApp now serves more than 100 million monthly actives in the US, and we're seeing good year-over-year growth across Facebook, Instagram, and Threads as well, both in the US, and globally. I'm particularly pleased with the progress that we're making with young adults on Facebook. The numbers we are seeing, especially in the US, really go against the public narrative around who's using the app. A couple of years ago, we started focusing our apps more on 18 to 29 year olds and it's good to see that those efforts are driving good results. Another bright spot is Threads which is about to hit 200 million monthly actives. We're making steady progress towards building what looks like it's going to be another major social app. And we are seeing deeper engagement, and I'm quite pleased with the trajectory here. The big theme right now is, of course, AI. And I'll focus my comments today on three areas. What AI means for our family of apps and core business. What new AI experiences and opportunities we see, and how AI is shaping our metaverse work. So let's start. Across Facebook and Instagram, advances in AI continue to improve the quality of recommendations and drive engagement. And we keep finding that as we develop more general recommendation models, content recommendations get better. In this quarter, we rolled out our full screen video player and unified video recommendation service across Facebook, bringing Reels, longer videos, and live into a single experience. And this has allowed us to extend our unified AI systems, which had already increased engagement on Facebook Reels more than our initial move from CPUs to GPUs did. Over time I'd like to see us move towards a single unified recommendation system that powers all of the content including things like people you may know, across all of our surfaces. We're not there yet. They're still upside, and we're making good progress here. AI is also going to significantly evolve our services for advertisers in some exciting ways. It used to be that advertisers came to us with a specific audience they wanted to reach, like a certain age group, geography, or interests. Eventually, we got to the point where our ad systems could better predict who would be interested than the advertisers could themselves. But today, advertisers still need to develop creative themselves. And in the coming years, AI will be able to generate creative for advertisers as well. And we'll also be able to personalize it as people see it. Over the long term, advertisers will basically just be able to tell us a business objective and a budget, and we're going to go do the rest for them. We're going to get there incrementally over time, but I think this is going to be a very big deal. Moving on to some of the brand new experiences that AI enables, last quarter we started broadly rolling out our assistant Meta AI, and it is on track to achieve our goal of becoming the most used AI assistant by the end of the year. We have an exciting roadmap ahead of things that we want to add, but the bottom-line here is that Meta AI feels like it is on track to be an important service and it's improving quickly both in intelligence and features. Some of the use cases are utilitarian like searching for information or role-playing difficult conversations before you have them with another person and other uses are more creative like the new imagine yourself feature that lets you create images of yourself doing whatever you want in whatever style you want and part of the beauty of AI is that it's general. So we're still uncovering the wide range of use cases that it's valuable for. An important part of our vision is that we're not just creating a single AI, but enabling lots of people to create their own AIs. And this week we launched AI Studio, which lets anyone create AIs to interact with across our apps. I think the creators are especially going to find this quite valuable. There are millions of creators across our apps, and these are people who want to engage more with their communities, and their communities want to engage more with them, but there are only so many hours in the day. So now they are going to be able to use AI Studio to create AI agents that can channel them to chat with their community, answer people's questions, create content and more. So I'm quite excited about this. But this goes beyond creators too. Anyone is going to be able to build their own AIs based on their interests or different topics that they are going to be able to engage with or share with their friends. Business AIs are the other big piece here. We're still in Alpha testing with more and more businesses. The feedback we're getting is positive so far. Over time, I think that just like every business has a website, a social media presence, and an email address, in the future I think that every business is also going to have an AI agent that their customers can interact with. And our goal is to make it easy for every small business, eventually every business, to pull all of their content and catalog into an AI agent that drives sales and saves them money. When this is working at scale, I think that this is going to dramatically accelerate our business messaging revenue. There are a lot of other new opportunities here that I'm excited about too, but I'll save those for another day when we're ready to roll them out. The engine that powers all these new experiences is the Llama family of foundation models. In this quarter we released Llama 3.1 which includes the first frontier level open source model as well as new and industry leading small and medium sized models. The $405 billion model has better cost performance relative to the leading closed models, and because it's open, it is immediately the best choice for fine-tuning and distilling your own custom models of whatever size you need. I think we are going to look back at Llama 3.1 as an inflection point in the industry where open source AI started to become the industry standard, just like Linux is. I often get asked why I'm so bullish on Open Source. I wrote a letter along with the Llama 3.1 release, explaining why I believe that Open Source is better for developers, for Meta app, and for the world more broadly. My view is that Open Source will be safer, will enable innovation that improves all of our lives faster, and we'll also create more shared prosperity. For Meta's own interests, we're in the business of building the best consumer and advertiser experiences. And to do that, we need to have access to the leading technology infrastructure and not get constrained by what competitors will let us do. But these models are ecosystems. They're not just isolated pieces of software that we can develop by ourselves. So if we want the most robust ecosystem of tools, efficiency improvements, silicon optimizations, and other integrations to develop around our models, then we need them to be widely used by developers across the industry. And once we know that we're going to have access to the leading models, then I'm confident that we are going to be able to build the best social and advertising experiences. Part of why I'm so optimistic about this is that we have a long track record of success with open source. We've saved billions of dollars with open compute project by having supply chains standardized on our infrared designs. Open sourcing tools like PyTorch and React has led to real benefits for us from all the industry's contributions. This approach has consistently worked for us and I expect it will work here too. Another major area of focus is figuring out the right level of infra capacity to support training more and more advanced models. Llama 3 is already competitive with the most advanced models, and we're already starting to work on Llama 4, which we're aiming to be the most advanced in the industry next year. We are planning for the compute clusters and data we'll need for the next several years. The amount of compute needed to train Llama 4 will likely be almost 10 times more than what we used to train Llama 3, and future models will continue to grow beyond that. It's hard to predict how this trend -- how this will trend multiple generations out into the future. But at this point, I'd rather risk building capacity before it is needed rather than too late, given the long lead times for spinning up new inference projects. And as we scale these investments, we're of course, going to remain committed to operational efficiency across the company. The last area that I want to discuss is how AI is shaping our metaverse work, which continues to be our other long-term focus. Last quarter, I discussed how advances in AI have pulled in the timelines for some of our products. A few years ago, I would have predicted that holographic AR would be possible before Smart AI, but now it looks like those technologies will actually be ready in the opposite order. We're well positioned for that because of the Reality Labs investments that we've already made. Ray-Ban Meta Glasses continue to be a bigger hit sooner than we expected, thanks in part to AI. Demand is still outpacing our ability to build them, but I'm hopeful that we'll be able to meet that demand soon. EssilorLuxottica has been a great partner to work with on this, and we are excited to team up with them to build future generations of AI glasses, as we continue to build our long-term partnership. Quest 3 sales are also outpacing our expectations. And I think that's because it is not just the best MR headset for the price, but it's the best headset on the market, period. In addition to gaming, people are increasingly taking advantage of Quest's capabilities as a general computing platform, spending time watching videos, browsing websites, extending their PC via virtual desktop, and more. Horizon also continues to grow across VR, mobile, and desktop, and I expect that it will become an increasingly important part of that ecosystem as well. We're hosting our Annual Connect Conference on September 25th, and we will have lots of exciting updates around all of our AI and Metaverse work, so I encourage you to tune into that. At the end of the day, we are in the fortunate position where the strong results that we're seeing in our core products and business give us the opportunity to make deep investments for the future. And I plan to fully seize that opportunity to build some amazing things that will pay off for our community and our investors for decades to come. The progress we're making on both the foundational technology and product experiences suggests that we're on the right track. I'm proud of what our team has accomplished so far, and I'm optimistic about our ability to execute on the opportunities ahead. As always, thank you to our teams who are pushing all this important work forward, and thanks to all of you for being on this journey with us. And now here is Susan.
Susan Li : Thanks Mark and good afternoon everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis unless otherwise noted. Q2 total revenue was $39.1 billion up 22% or 23% on a constant currency basis. Q2 total expenses were $24.2 billion, up 7% compared to last year. In terms of the specific line items, cost of revenue increased 23% driven primarily by higher infrastructure and reality labs inventory costs. R&D increased 13%, primarily driven by higher headcount-related expenses and infrastructure costs which were partially offset by lower restructuring costs. Marketing and sales decreased 14%, due mainly to lower restructuring and headcount-related costs. G&A decreased 12%, mostly due to lower legal-related expenses. We ended the first quarter with almost 70,800 employees, up 2% from Q1. Second quarter operating income was $14.8 billion, representing a 38% operating margin. Our tax rate for the quarter was 11%. Net income was $13.5 billion, or $5.16 per share. Capital expenditures, including principal payments on finance leases, were $8.5 billion, driven by investments in servers, data centers, and network infrastructure. Free cash flow was $10.9 billion. We repurchased $6.3 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders, ending the quarter with $58.1 billion in cash and marketable securities and $18.4 billion in debt. Moving now to our segment results. I'll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, with approximately 3.27 billion people using at least one of our Family of Apps on a daily basis in June. Q2 total Family of Apps revenue was $38.7 billion, up 22% year-over-year. Q2 Family of Apps ads revenue was $38.3 billion, up 22% or 23% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year-over-year growth, followed by gaming and entertainment and media. On a user geography basis, ad revenue growth was strongest in rest of world and Europe at 33% and 26% respectively. Asia Pacific grew 20% and North America grew 17%. On an advertiser geography basis, total revenue growth continued to be strongest in Asia Pacific at 28%. The growth was below the first quarter rate of 41%, as we lapped a period of stronger demand from China-based advertisers. In Q2, the total number of ad impressions served across our services and the average price per ad both increased 10%. Impression growth was mainly driven by Asia Pacific and rest of world. Pricing growth was driven by increased advertiser demand in part due to improved ad performance. This was partially offset by impression growth particularly from lower monetizing regions and surfaces. Family of Apps other revenue was $389 million, up 73%, driven primarily by business messaging revenue growth from our WhatsApp business platform. We continue to direct the majority of our investments toward the development and operation of our Family of Apps. In Q2, Family of Apps expenses were $19.4 billion, representing approximately 80% of our overall expenses. Family of Apps expenses were up 4%, mostly due to higher infrastructure and headcount related expenses, which were partially offset by lower restructuring costs. Family of Apps operating income was $19.3 billion, representing a 50% operating margin. Within our Reality Labs segment, Q2 was $353 million, up 28% driven primarily by Quest headset sales. Reality Labs expenses were $4.8 billion, up 21% year-over-year, driven mainly by higher headcount-related expenses and Reality Labs inventory costs. Reality Labs operating loss was $4.5 billion. Turning now to the business outlook. There are two primary factors that drive our revenue performance, our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. To deliver engaging experiences, we remain focused on executing our priorities, including video and in-feed recommendations. On Instagram, Reels engagement continues to grow as we make ongoing enhancements to our recommendation systems. Part of this work has been focused on increasing the share of original posts within recommendations so people can discover the best of Instagram, including content from emerging creators. Now, more than half of recommendations in the US come from original posts. On Facebook, we're seeing encouraging early results from the global rollout of our unified video player and ranking systems in June. This initiative allows us to bring all video types on Facebook into one viewing experience, which we expect will unlock additional growth opportunities for short-form video, as we increasingly mix shorter videos into the overall base of Facebook video engagement. We expect the relevance of video recommendations will continue to increase as we benefit from unifying video ranking across Facebook and integrating our next-generation recommendation systems. These have already shown promising gains since we began using the new systems to support Facebook Reels recommendations last year. We expect to expand these new systems to support more services beyond Facebook video over the course of this year and next year. We are also seeing good momentum with our longer-term engagement priorities, including Generative AI and Threads. People have used Meta AI for billions of queries since we first introduced it. We're seeing particularly promising signs on WhatsApp in terms of retention and engagement, which has coincided with India becoming our largest market for Meta AI usage. You can now use Meta AI in over 20 countries and eight languages, and in the US we are rolling out new features like Imagine Edit, which allows people to edit images they generate with Meta AI. Beyond Generative AI, the Threads community also continues to grow and deepen their engagement, as we ship new features and enhance our content recommendation systems. Now to the second driver of our revenue performance, increasing monetization efficiency. There are two parts to this work. The first is optimizing the level of ads within organic engagement. We continue to see opportunities to grow ad supply on lower monetizing surfaces like video, including within Facebook as the mix of overall video engagement shifts more to shorter videos over time, which creates more ad insertion opportunities. More broadly, we are continuing to get better at determining the best ads to show and when to show them during a person session across both Facebook and Instagram. This is enabling us to drive revenue growth and conversions without increasing the number of ads or in some cases even reducing ad load. The second part of improving monetization efficiency is enhancing marketing performance. We continue to be pleased with our progress here, with AI playing an increasingly central role. We're improving ad delivery by adopting more sophisticated modeling techniques made possible by AI advancements, including our Meta Lattice ad ranking architecture, which continued to provide ad performance and efficiency gains in the second quarter. We're also making it easier for advertisers to maximize ad performance and automate more of their campaign setup with our Advantage+ suite of solutions. We're seeing these tools continue to unlock performance gains, with a study conducted this year demonstrating 22% higher return on ad spend for US advertisers after they adopted Advantage+ Shopping campaigns. Advertiser adoption of these tools continues to expand and we are adding new capabilities to make them even more useful. For example, this quarter we introduced flexible format to Advantage+ Shopping, which allows advertisers to upload multiple images and videos in a single ad that we can select from and automatically determine which format to serve in order to yield the best performance. We have also now expanded the list of conversions that businesses can optimize for using Advantage+ shopping to include an additional 10 conversion types, including objectives like add to cart. Looking forward, we believe Generative AI will play a growing role in how businesses market and engage with customers at scale. We expect this technology will continue to make it easier for businesses to develop customized and diverse ad creatives. We've seen promising early results since introducing our first Generative AI ad features, image expansion, background generation, and text generation with more than 1 million advertisers using at least one of these solutions in the past month. In May, we began rolling out full image generation capabilities into Advantage+ Creative, and we're already seeing improved performance from advertisers using the tool. Finally, we expect AI will help businesses communicate with customers more efficiently through messaging. We're starting by testing the ability for businesses to use AI in their chats with customers to help sell their goods and services and to generate leads. While we are in the early stages, we continue to expand the number of advertisers we are testing with and have seen good advances in the quality of responses since we began using Llama 3. Next, I’d like to discuss our approach to capital allocation which remains unchanged. We continue to invest both in enhancing our core experiences in the near-term and developing technologies that we believe will transform how people engage with our services in the years ahead. We expect that having sufficient compute capacity will be central to many of these opportunities. So we’re investing meaningfully in infrastructure to support our core AI work in content ranking and ads, as well as our generative AI and advanced research efforts. Our ongoing investment in core AI capacity is informed by the strong returns we've seen and expect to deliver in the future, as we advance the relevance of recommended content and ads on our platform. While we expect the returns from Generative AI to come in over a longer period of time, we’re mapping these investments against the significant monetization opportunities that we expect to be unlocked across customized ad creative, business messaging, a leading AI assistant and organic content generation. As we scale generative AI training capacity to advance our foundation models, we’ll continue to build our infrastructure in a way that provides us with flexibility in how we use it over time. This will allow us to direct training capacity to gen AI inference or to our core ranking and recommendation work, when we expect that doing so would be more valuable. We will also continue our focus on improving the cost efficiency of our workloads over time. Reality Labs remains our other long-term initiative that we continue to invest meaningfully in. Quest 3 is selling well and Ray-Ban Meta smart glasses are showing very promising traction with the early signals that we’re seeing across demand, usage and retention increasing our confidence in the long-run potential of AR glasses. Finally, as we pursue these investments across near and long-term priorities, we will remain focused on operating the business efficiently. Turning now to the revenue outlook. We expect third quarter 2024 total revenue to be in the range of $38.5 billion to $41 billion. Our guidance assumes foreign currency is a 2% headwind to year-over-year total revenue growth based on current exchange rates. Turning now to the expense outlook. We expect full year 2024 total expenses to be in the range of $96 billion to $99 billion, unchanged from our prior outlook. For Reality Labs, we continue to expect 2024 operating losses to increase meaningfully year-over-year due to our ongoing product development efforts and investments to scale our -- to further scale our ecosystem. While we do not intend to provide any quantitative guidance for 2025 until the fourth quarter call, we expect infrastructure costs will be a significant driver of expense growth next year. As we recognize depreciation and operating costs associated with our expanded infrastructure footprint. Turning now to the CapEx outlook. We anticipate our full year 2024 capital expenditures will be in the range of $37 billion to $40 billion, updated from our prior range of $35 billion to $40 billion. While we continue to refine our plans for next year, we currently expect significant CapEx growth in 2025 as we invest to support our AI research and our product development efforts. On to tax. Absent any changes to our tax landscape, we expect our full year 2024 tax rate to be in the mid-teens. In addition we continue to monitor an active regulatory landscape, including the increasing legal and regulatory headwinds in the EU and the US that could significantly impact our business and our financial results. In closing, Q2 was another good quarter. We continue to execute well across our business priorities and have exciting opportunities in front of us to deliver more value to the people and businesses using our products around the world. With that, Krista let's open up the call for questions.
Operator: Thank you. We will now be open the line for question-and-answer session [Operator Instructions] And your first question comes from the line of Brian Nowak from Morgan Stanley. Please go ahead.
Brian Nowak: Great. Thanks for taking my questions. I have two, one for Mark, one for Susan. Mark I wanted to sort of go back to some of the new generative AI-enabled use cases for users and advertisers. You talked about Meta AI, Studio, chatbots, [foundation] (ph) models. If you could just sort of hone in on one or two of those that you are most excited about, we are seeing good signal that could be a real driver for the business in '25, '26 just so we sort of know where are you most focused on all those opportunities it would be helpful. And the second one, Susan, you have a lot of CapEx priorities from building new infrastructure for next-generation models, compute capacity. Just walk us through again on the CapEx philosophy and any guardrails you have around ensuring you generate a healthy return on invested capital for investors from all the CapEx. Thanks.
Mark Zuckerberg: I can take the first one. So I think the things that will drive the most results in 2025 and 2026 are actually the first category of things that I talked about in my comments which are the ways that AI is shaping the existing products. So the ways that it is improving recommendations and helping people find better content, as well as making the advertising experiences more effective. I think there is a lot of upside there. Those are already products that are at scale. The AI work that we are doing is going to improve that. It will improve the experience and the business results. The other areas that we are working on, I mean I think you all know this from following our business for a while, but we have a relatively long business cycle of starting a new product, scaling it to something that reaches 1 billion people or more and only then really focusing on monetizing at scale. So realistically, for things like Meta AI or AI Studio, I mean these are things that I think will increase engagement in our products and have other benefits that will improve the business and engagement in the near term. But before we are really talking about monetization of any of those things by themselves, I mean I don't think that anyone should be surprised that I would expect that -- that will be years, right? It's just -- I think that that's like what we've seen with Reels, it's what we saw with all these things. But I think for those who have followed our business for a long time, you can also get a pretty good sense of when things are going to work years in advance. And I think that the people who bet on those early indicators tend to do pretty well, which is why I wanted to share in my comments the early indicator that we had on Meta AI, which is I mean look, it is early. Last quarter, we -- I think it just started rolling it out a week or two before our earnings call. This time we are a few months later. And what we can say is I think we are on track to achieve our goal of being the most used AI assistant by the end of this year. And I think that is a pretty big deal. Is that the only thing we want to do? No. I mean we obviously want to kind of grow that and grow the engagement on that to be a lot deeper, and then we will focus on monetizing it over time. But the early signals on this are good and I think that -- that's kind of all that we could reasonably have insight into at this point. But I do think that part of what's so fundamental about AI is, it is going to end up affecting almost every product that we have in some way. It will improve the existing ones and will make a whole lot of new ones possible. So it is why there are all the jokes about how all the tech CEOs get on these earnings calls and just talk about AI the whole time. It is because it is actually super exciting, and it is going to change all these different things over multiple time horizons.
Susan Li: And Brian, I can take the second question. On the ROI part of your question, I’d broadly characterize our AI investments into two buckets; core AI and Gen AI. And the two are really at different stages, as it relates to driving revenue for our businesses and our ability to measure returns. On our core AI work, we continue to take a very ROI based approach to our investment here. We are still seeing strong returns as improvements to both engagement and ad performance have translated into revenue gains and it makes sense for us to continue investing here. Gen AI is where we are much earlier, as Mark just mentioned in his comments. We don't expect our Gen AI products to be a meaningful driver of revenue in 2024. But we do expect that they are going to open up new revenue opportunities over time that will enable us to generate a solid return off -- of our investment while we are also open sourcing subsequent generations of Llama. And we've talked about the four primary areas that we are focused here on the Gen AI opportunities to enhance the core ads business, to help us grow in business messaging, the opportunities around Meta AI, and the opportunities to grow core engagement over time. The other thing I’d say is, we are continuing to build our AI infrastructure with fungibility in mind, so that we can flex capacity where we think it will be put to best use. The infrastructure that we build for gen AI training can also be used for Gen AI inference. We can also use it for ranking and recommendations by making certain modifications like adding general compute and storage. And we are also employing a strategy of staging our data center sites, at various phases of development, which allows us to flex up to meet more demand and less lead time if needed while limiting how much spend we are committing to in the outer years. So while we do expect that we are going to grow CapEx significantly in 2025, we feel like we have a good framework in place in terms of thinking about where the opportunities are and making sure that we have the flexibility to deploy it, as makes the most sense.
Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please go ahead.
Mark Shmulik: Yes. Hi, thanks for taking my question. Just as we look at the revenue guidance and the outlook, Susan, any color you can share on just kind of the state of the overall digital ad market? And you've highlighted some areas where you are seeing strength versus kind of some of the idiosyncratic efforts you've made to kind of improve the efficacy of the ad product. Thank you.
Susan Li: Hi, Mark. We are continuing to see healthy global advertising demand, and we are also delivering ongoing ad performance improvements just related to all of the investments that we've continued to make over time. And improving the sort of ads, targeting ranking, delivery, all of the fundamental infrastructure there. And we expect that all of that will continue to benefit ad spend in Q3. We do expect year-over-year growth to slow in Q3, as we are lapping strong growth from China-based advertisers, as well as strong Reels impression growth from a year ago. And we also expect modestly larger FX headwinds in Q3 based on current rates.
Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.
Eric Sheridan: Thank you so much for taking the question. I'll just ask one. You called out building community size and what's happened in the United States, as well as Threads. How are you thinking about those newer faster-growing elements of either Messaging or Threads as a platform and the mix between the potential for engagement growth and overall monetization longer term of either the messaging layer or Threads and what you are most excited about there to build to sort of capitalize on scale but bring it back towards monetization? Thank you.
Mark Zuckerberg: I can start and Susan can jump in, if she has anything else that she wants to add. So the WhatsApp stat I think, is really important as a business trend just because the United States punches above its weight in terms of, it is such a large percent of our revenue. So before, WhatsApp was sort of the leading messaging app in many countries around the world but not in the US. And I think now that we're starting to make inroads into leading in the US as more and more people use the product and realize that, hey, it was a really good experience, the best experience for cross-platform communication and groups and on all these different things. I think that -- that's going to just mean that all of the work that we are doing to grow the business opportunity there over time is just going to have a big tailwind if the US ends up being a big market. So that's one reason why it's really relevant. It is obviously also personally somewhat gratifying to see all the people around us starting to use WhatsApp, so I think that is pretty fun but maybe somewhat less relevant from a business perspective. Threads, I think it is another example of something that it got off to about as good of a start of any app that I can think of. I think, it was the fastest growing app to 100 million people. And it is a good reminder that even when you have that start, the path from there to 1 billion people using an app is still multiple years. And that's our product cycle. And I think that -- that's something that is a little bit different about Meta in the way we build consumer products and the business around them than a lot of other companies that ship something and start selling it and making revenue from it immediately. So I think that's something that our investors and folks thinking about analyzing the business, if needed to always grapple with, is all these new products, we ship them and then there is a multiyear time horizon between scaling them and then scaling them into not just consumer experiences but very large businesses. But the thing that I think is just super exciting about Threads is that we've been building this company for 20 years, and there are just not that many opportunities that come around to grow 1 billion person app. I mean, there are -- I don't know, maybe a dozen of them in the world or something, right? I mean, there are certainly more of them outside the company than inside the company, but we do pretty well and being able to add another one to the portfolio if we execute really well on this is just really exciting to have that potential. Now obviously, there is a ton of work between now and there. I mean, we are almost at 200 million. So it is a really good milestone, I'm excited about that. A lot of work between this and it being a large part of the business. But I do think that these kind of opportunities are pretty rare and that's something that we are just really excited about. I think the team is doing great work on it.
Susan Li: Eric, I would just add to that in terms of [nearer-term] (ph) sources of impression growth, we really expect that video is going to remain a source of impression growth for us in the second half. On Instagram, we expect Reels to continue to drive growth, while on Facebook, we expect to grow overall video time, while increasing the mix of short-form video, which creates more impression growth opportunities. And generally we expect continued community growth foracross our apps.
Operator: Your next question comes from the line of Doug Anmuth with JPMorgan. Please go ahead.
Douglas Anmuth: Hi, thanks for taking my questions. One for Mark, one for Susan. Mark just in terms of infrastructure and CapEx, you've talked about currently building out not just for Llama 3 and 4 but really out to 7 perhaps and then Llama 4, 10x the compute required versus Llama 3. Just given how much you are building ahead, how does that influence the shape of the CapEx curve over a multiyear period? And then Susan, if you could talk a little bit more about the 3Q outlook. I know you are talking about tougher comps, but at the same time, it really suggests only 1 point of FX neutral [decel] (ph) at the high end. So just curious if there's anything else you can point to more specifically that's driving the expected strength here. Thanks.
Susan Li: Thanks, Doug. I can go ahead and talk about both of those. So your first question was sort of about the longer-term CapEx outlook. We haven't really shared an outlook sort of on the longer-term CapEx trajectory. In part infrastructure is an extraordinarily dynamic planning area for us right now. We are continuing to work through what the scope of the Gen AI road maps will look like over that time. Our expectation obviously again, is that we are going to significantly increase our investments in AI infrastructure next year, and we'll give further guidance as appropriate. But we are building all of that CapEx, again with the factors in mind that I talked about previously thinking about both how to build it flexibly, so we can deploy to core AI and Gen AI use cases as needed. And making sure that we both feel good about the returns that we're seeing on the core AI investments, which we are able to measure more immediately. And then we feel good about the opportunities in the gen AI efforts. Your second question was about the Q3 revenue outlook. Again I mentioned this earlier. We have seen healthy global advertising demand on our platform. We are delivering ongoing ad performance improvements, which again we feel like is a result of many, many quarters of effort that have accrued and will continue to accrue value to our platform. And we saw basically in Q2 where revenue grew 22% that there was broad-based strength across regions and verticals including particular strength among smaller advertisers, and we expect that generally to continue into Q3.
Operator: Your next question comes from the line of Justin Post with Bank of America. Please go ahead.
Justin Post: Great. Thank you. I just want to get back to the comment on US young adult user growth, especially maybe on Facebook and Instagram. I know you made a big change with Reels a couple of years ago. But what are those users doing on Facebook and Instagram? And can you give us any quantification of the usage growth? Thank you.
Susan Li: Thanks, Justin. So building products with young adults in mind has been a core priority area for the Facebook team in recent years, and we've been very encouraged to see these efforts translate into engagement growth with this cohort. We have seen healthy growth in young adult app usage in the US and Canada for the past several quarters. And we have seen that products like Groups and Marketplace have seen particular traction with young adults. Posting to groups in the US and Canada has been growing. That's been boosted mainly by young adults. And we also see that they are active users of Marketplace, which has benefited from product improvements and strong demand for second-hand products in the US.
Operator: Your next question comes from the line of Mark Mahaney with Evercore ISI. Please go ahead.
Mark Mahaney: I was going to ask about Marketplace so that's a nice segue. It is a great, somewhat under-monetized or arguably very under-monetized asset. I know you indirectly monetize it and it's a very large marketplace. It may even be bigger than eBay. Your thoughts on what you may want to do in the future in terms of monetizing it, in part maybe even improve the quality of the Marketplace. And then secondly, I just want to ask you about headcount. It is down about 1% year-over-year. You are pretty much back at par with where the employee headcount was prior to significant reduction. How should we think about headcount growth going forward? Did you talk about a significant growth in CapEx? Should we expect a moderate growth in headcount significant? Any thoughts on that would be helpful. Thank you.
Susan Li: Thanks Mark. On your first question about Marketplace, again we are obviously excited that it's been one of the drivers of strength in young adults. I would probably just say that more generally, Marketplace is one prong in a broader commerce strategy that we have which continues to be focused on basically creating the best shopping experience on our platform. Marketplace is obviously consumer oriented. The broader part of the commerce strategy is about making it easier for businesses to advertise their products, for buyers to find and purchase relevant items on our platform. And to that end, I’d say that we feel quite happy with also the investments we've been making in Shops ads. Shops ads revenue is growing at a strong year-over-year pace. We are seeing Shops ads drive incremental performance for advertisers, and it's also working well in combination with some of our other products like Advantage+ shopping. Your second question was about headcount. We continue to be disciplined about where we are allocating new headcount to ensure that it's really focused on our core company priorities, but we are also working down a prior hiring underrun. And as we further close that hiring underrun over the course of this year, I do expect that we will end 2024 with in-seat reported headcount that is meaningfully higher than where we ended 2023. We aren't providing sort of 2025 headcount growth expectations yet as we haven't started our budgeting process yet. But again, I expect that we’ll primarily target our hiring to focus on priority areas, and we will be running a very disciplined headcount process.
Operator: Your next question comes from the line of Youssef Squali with Truist Securities. Please go ahead.
Youssef Squali: Great. Thank you very much. So the AI system using Llama 3.1 has been incorporated in different variations and looks really impressive and seems to be getting closer to becoming a full search engine for virtually everything except for commercial queries so far. So are there any plans to open it up to the broader web? Kind of like what may be OpenAI is off to testing, maybe link it to third-party marketplaces for commercial search, et cetera. And then on Ray-Ban, can you maybe talk a little bit more about the opportunity to deepen your relationship with EssilorLuxottica? What would that look like? What kind of areas are the most exciting to you, Mark in that relationship? Thank you.
Mark Zuckerberg: Yes. I'm very excited with how Llama 3.1 landed. I think the team there is doing really great work going from the first version of Llama, the Llama 2 last year that was a generation behind the frontier and now Llama 3.1, which is basically competitive and in some ways, leading the other top-closed models. Meta AI uses a version of Llama 3.1 as well as a bunch of other services that we've built to kind of build a cohesive product. And when I was talking before about we have the initial usage trends around Meta AI but there is a lot more that we want to add. Things like commerce and you can just go vertical by vertical and build out specific functionality to make it useful in all these different areas are eventually, I think what we're going to need to do to make this just as -- to fulfill the potential around just being the ideal AI assistant for people. So it is a long road map. I don't think, that this stuff is going to get finished in the next couple of quarters or anything like that. But this is part of what's going to happen over the next few years as we build something that will I think, just be a very widely used service. So I'm quite excited about that. And we are going to continue working on Llama 2. So I mean, you mentioned Llama, and I think the question was a little more about Meta AI but they are both -- I mean, they're related Llama is sort of like the engine that powers the product and it's open source, and I'm just excited about the progress that we are making on both of those. On the smart glasses, EssilorLuxottica is a great partner. We are now in the second generation of the Ray-Ban Meta glasses. They are doing well, better than I think we had expected, and we expected them to grow meaningfully from the first generation so that's been a very positive surprise. And I think part of that is that it is just well-positioned to dovetail well with the AI revolution that we are seeing and offering all kinds of new functionality there. So that was great. But EssilorLuxottica is a great company that has a lot of different products that we hope to be able to partner with to just continue building new generations of the glasses and deepen the AI product and make it better and better. I think there is a lot more to go from here. And compared to what we thought at this point, it's doing quite well compared to, I think what it needs to be, to be like a really leading piece of consumer electronics, I think we are still early but all the signs are good.
Operator: Your next question comes from the line of Ron Josey with Citi. Please go ahead.
Ronald Josey: Great. Thanks for taking the question. I want to get back, Mark, to the commentary on open source and Llama 3. Totally understand that Meta is not offering a public cloud, and so what I wanted to hear from you is maybe a little bit more on the product vision of products that come out of Llama 3. And meaning potentially offering some of these products to other companies, call it for customer service or call center offerings or other verticals. And so any insights on just how you envision maybe the open source and Llama 3.1, can sort of offer greater enterprise services for others to benefit from? Thank you.
Mark Zuckerberg: So Llama is the foundation model that people can shape into all kind of different products. So whether it's Meta AI for ourselves or the AI Studio or the business agents or like the assistant that's in the Ray-Ban glasses, like all these different things are basically products that have been built with Llama. And similarly, any developer out there is going to be able to take it and build a whole greater diversity of different things as well. Like I talked about, I think -- the reason why open sourcing this is so valuable for us is that we want to make sure that we have the leading infrastructure to power the consumer and business experiences that we are building. But the infrastructure, it's not just a piece of software that we can build in isolation. It really is an ecosystem with a lot of different capabilities that other developers and people are adding to the mix, whether that's new tools to distill the models into the size that you want for a custom model, or ways to fine-tune things better or make inference more efficient or all different other kinds of methods that we haven't even thought of yet, the silicon optimizations that the silicon companies are doing, all the stuff. It is an ecosystem. So we can't do all that ourselves. And if we built Llama and just kind of kept it within our walls, then it wouldn't actually be as valuable for us to build all the products that we are building as it is going to end up being. So that's the business strategy around that. And that's why we don't feel like we need to necessarily build a cloud and sell it directly in order for it to be a really positive business strategy for us. And part of what we are doing is working closely with AWS, I think, especially did great work for this release. Other companies like Databricks, Nvidia, of course, other big players like Microsoft with Azure, and Google Cloud, they are all supporting this. And we want developers to be able to get it anywhere. I think that's one of the advantages of an open source model like Llama is – it is not like you're locked into one cloud that offers that model, whether it's Microsoft with OpenAI or Google with Gemini or whatever it is, you can take this and use it everywhere and we want to encourage that. So I'm quite excited about that. The enterprise and business applications that we are going to be most focused on, though, in addition to just optimizing the advertiser experience like I talked about in my comments earlier, it is the business agent piece. I just think that there is a huge potential like I said earlier. I think pretty much every business today, it has an e-mail address. They have a website. They have social media accounts. I think in the future, they are going to have at least one, if not multiple business agents that can do the whole range of things from interacting to help people buy things to helping support the sales that they've done, if they have issues with the product, if they need to get in touch with you for something. And we already see people interacting with businesses over messaging working quite well in countries that have low cost of labor. But the thing is that in order to have someone answering everyone's questions is quite expensive in a lot of countries. And I think that this is like a thing that AI, I think is just going to be very well suited towards doing. And when we can make that easy for the hundreds of millions of businesses that use our platforms to pull in all their information and their catalogs, and the history and all the content that they've shared and really just quickly stand up an agent, I think that's going to be awesome. So we can combine Llama with a lot of custom work that we're doing in our business teams and couple that with all the other investment that the rest of the ecosystem is doing to make Llama good. And I think that's going to be huge, but that's just one area. I mean, this really goes across all of the different products that we are building, both consumer and business. So it is a lot of exciting stuff.
Kenneth Dorell: Krista, we have time for one last question.
Operator: Thank you. That question will come from the line of Ross Sandler with Barclays. Please go ahead.
Ross Sandler: Great. Mark, so on Monday in your interview with Jensen, you said something along the lines of if scaling ended up stopping one day, you'd have five years of product work to do and ahead of you. So outside of agents or AI assistants, what other areas in AI are you thinking about or looking at in that five-year road map? And then the second question is maybe one more stab at the capacity question. You guys said that Llama 3.1 was trained on 16,000 H100s. You've also said that you're going to have 600,000 available by year-end. So even if we kind of go up to 160,000 GPUs for Llama 4, we have plenty of extra capacity for inference and future products. I guess how are you guys modeling out this entire kind of CapEx road map between training, inference, and future things? That's all. Thanks a lot.
Mark Zuckerberg: I can start with the first one, and then I'll let Susan answer the second one. It is an interesting question. It is a little hypothetical because I mean, I do think it's true that if, let's say, there were no future foundation models. I think there would just be a huge amount of product innovation that the industry would bring to bear, and that just takes time. But then at the same time there are going to be future foundation models, and they are going to be awesome and unlock new capabilities and we are planning our products around those. So I'm not really planning our product road map assuming that there isn't future innovation. On the contrary, we are planning what's going to be in Llama 4 and Llama 5 and beyond based on what capabilities we think are going to be most important for the road map that I just laid out for having the breadth of utility that you're going to need in something like Meta AI, making it set businesses and creators and individuals can stand up any kind of AI agents that they want, that you are going to have these kind of real-time, multimodal glasses with you all the time that will just be increasingly useful for all the things that you're doing. And that -- I guess this kind of dovetails what I'd expect Susan to talk about next. And we do have this huge set of use cases already about people wanting to discover content and interact with their friends and businesses reaching people, and all that stuff is getting better with this, too. So there is -- I guess my point there was its just – there is some lag between the technology becoming available and the products becoming kind of fully explored in the space. And I just think that -- that was kind of my way of saying that I think that this is just a very exciting area where there's just going to be a lot of innovation for a long time to come. I'll let Susan take a stab at the numbers around the GPUs and all that.
Susan Li: Thank you. We are clearly in the process of building out a lot of capacity, and Mark has alluded to that in his comments about what we have needed to train prior generations and the next generation of Llama. And we are -- and that's driving sort of what we've talked about in terms of the significant growth in CapEx in 2025. And we aren't really in the position now to share a longer-term outlook. When we think about sort of any given new data center project that we are constructing, we think about how we will use it over the life of the data center. We think about the amount of capacity we would use in terms of training whatever the subsequent generations of Llama are and it is architected around that. But then we also look at how we might use it several years into its lifetime towards other use cases across our core business, across what we think might be future needs for inference, for generative AI-based products. So there is sort of a whole host of use cases for the life of any individual data center ranging from gen AI training at its outset to potentially supporting gen AI inference to being used for core ads and content ranking and recommendation and also thinking through the implications, too, of what kinds of servers we might use to support those different types of use cases. So we are really mapping across a wide range of potential use cases when we undertake any given project. And we are really doing that with both a long time horizon in mind, again, because of the long lead times in spinning up data centers, but also recognizing that there are multiple decision points in the lifetime of each data center in terms of thinking through when to order servers and what servers to order and what you will put them towards. And that gives us flexibility to make the sort of the best decisions based on the information we have in the future.
Kenneth Dorell: Great. Thank you all for joining us today. We appreciate your time, and we look forward to speaking with you again soon.
Operator: This concludes today's conference call. Thank you for your participation, and you may now disconnect.",2024-07-31
META,2024,3,2024-Q3-META,"Operator: Good afternoon. My name is Krista and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta Third Quarter Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers’ remarks there will be a question-and-answer session. [Operator Instructions] This call will be recorded. Thank you very much. Kenneth Dorell, Meta's Director of Investor Relations, you may begin.
Kenneth Dorell: Thank you. Good afternoon and welcome to Meta Platform's Third Quarter 2024 Earnings Conference Call. Joining me today to discuss our results are Mark Zuckerberg, CEO, and Susan Li, CFO. Before we get started, I would like to take this opportunity to remind you that our remarks today will include forward-looking statements. Actual results may differ materially from those contemplated by these forward-looking statements. Factors that could cause these results to differ materially are set forth in today's earnings press release and in our Quarterly Report on Form 10-Q, filed with the SEC. Any forward-looking statements that we make on this call are based on assumptions as of today and we undertake no obligation to update these statements as a result of new information or future events. During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying Investor Presentation are available on our website at investor.fb.com. And now I'd like to turn the call over to Mark.
Mark Zuckerberg: Thanks, Ken. This was a good quarter with strong product and business momentum and with parts of our long-term vision around AI and the future of computing coming into sharper focus. We estimate that there are now more than 3.2 billion people using at least one of our apps each day and we're seeing rapid adoption of Meta AI and Llama, which is quickly becoming a standard across the industry. So let's start with some highlights from the apps. For WhatsApp, the US remains one of our fastest-growing countries and we just passed a milestone of 2 billion calls made globally every day. On Facebook, we continue to see positive trends with young adults, especially in the US. On Instagram, global growth remains strong. We also lunched teen accounts this quarter which add built-in protections that limit who teens are messaging and what content they can see. On Threads, the community now has almost 275 million monthly actives. It's been growing more than a million signups per day. Engagement is growing too, so we continue to be on track towards this becoming our next major social app. We are making a lot of progress with our AI efforts too, and we're seeing AI have a positive impact on nearly all aspects of our work, from our core business engagement and monetization to our long-term roadmaps for new services and computing platforms. I think that this partially comes from having a vision and roadmap that is aligned with the direction that technology is heading, but even more importantly from our teams doing some really excellent work on execution on so many fronts. Meta AI now has more than 500 million monthly active improvements to our AI driven feed and video recommendations have led to an 8% increase in time spent on Facebook and a 6% increase on Instagram this year alone. More than a million advertisers used our Gen AI tools to create more than 15 million ads in the last month and we estimate that businesses using image generation are seeing a 7% increase in conversions and we believe that there's a lot more upside here. We are also seeing great momentum with Llama. Llama token usage has grown exponentially this year and the more widely that Llama gets adopted and becomes the industry standard the more that the improvements to its quality and efficiency will flow back to all of our products. This quarter we released Llama 3.2 including the leading small models that run on device and open source multimodal models. We are working with enterprises to make it easier to use and now we're also working with the public sector to adopt Llama across the US government. The Llama 3 models have been something of an inflection point in the industry but I'm even more excited about Llama 4 which is now well into its development. We're training the Llama 4 models on a cluster that is bigger than 100,000 H100s or bigger than anything that I've seen reported for what others are doing. I expect that the smaller Llama 4 models will be ready first and they'll be ready we expect sometime early next year and I think that they're going to be a big deal on several fronts, new modalities capabilities, stronger reasoning and much faster. It seems pretty clear to me that open source will be the most cost effective, customizable, trustworthy, performant and easiest to use option that is available to developers and I am proud that Llama is leading the way on this. Right now it's the time of the year at Meta when we plan our budget for the next year, and that's still in progress, but I wanted to share a few things that have stood out to me as we've gone through this process so far. First, it's clear that there are a lot of new opportunities to use new AI advances to accelerate our core business that should have strong ROI over the next few years, so I think we should invest more there. And second, our AI investments continue to require serious infrastructure, and I expect to continue investing significantly there too. We haven't decided on a final budget yet, but those are some of the directional trends that I'm seeing. Now, moving on, this quarter, we also had several milestones around Reality Labs and the integration of AI and wearables. Ray-Ban Meta AI glasses are the prime example here. They're great-looking glasses that let you take photos and videos, listen to music, and take calls, but what makes them really special is the Meta AI integration. With our new updates, it'll be able to not only answer your questions throughout the day, but also help you remember things, give you suggestions as you're doing things using real-time multimodal AI, and even translate other languages right in your ear for you. I continue to think that glasses are the ideal form factor for AI because you can let your AI see what you see, hear what you hear, and talk to you. Demand for the glasses continues to be very strong. The new clear edition that we released at Connect sold out almost immediately and has been trading online for over $1,000. We've deepened our partnership with EssilorLuxottica to build future generations of smart eyewear that deliver both cutting-edge technology and style. At Connect, we also showed Orion, our first full holographic AR glasses. We've been working on this one for about a decade, and it gives you a sense of where this is all going. We're not too far off from being able to deliver great looking glasses that let you seamlessly blend the physical and digital worlds so you can feel present with anyone no matter where they are. And we're starting to see the next computing platform come together and it's pretty exciting. All right, we also released our newest mixed reality headset Quest 3S. It brings the best capabilities of Quest 3, high quality color pass-through, a new chipset, and more at the much more accessible price point of $300. Reviews are great so far and I'm looking forward to seeing how well it does this holiday season as more people get their hands on it. So overall, this has been a good quarter. I'm pretty amped about all the work that we're doing right now. This may be the most dynamic moment that I've seen in our industry and I am focused on making sure that we build some awesome things and make the most of the opportunities ahead. And if we do this well then, the potential for Meta and everyone building with us will be massive. As always, I'm grateful for everyone who is on this journey with us, our teams, our partners, and our investors. And now here's Susan.
Susan Li : Thanks, Mark. And good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis, unless otherwise noted. Q3 total revenue was $40.6 billion, up 19% or 20% on a constant currency basis. Q3 total expenses were $23.2 billion, up 14% compared to last year. In terms of the specific line items, cost of revenue increased 19% driven primarily by higher infrastructure costs. R&D increased 21%, mostly driven by higher headcount related expenses and infrastructure costs. Marketing and sales decreased 2% driven primarily by lower restructuring costs. G&A decreased 10% driven primarily by lower legal related expenses. We ended the third quarter with over 72,400 employees, up 9% year-over-year with growth primarily driven by hiring in our priority areas of monetization, infrastructure, Reality Labs, generative AI, as well as regulation and compliance. Third quarter operating income was $17.4 billion, representing a 43% operating margin. Our tax rate for the quarter was 12%. Net income was $15.7 billion or $6.03 per share. Capital expenditures, including principal payments on finance leases, were $9.2 billion driven by investments in servers, data centers, and network infrastructure. Our capital expenditures were impacted in part by the timing of third quarter server deliveries, which will be paid for in the fourth quarter. Free cash flow was $15.5 billion. In Q3, we completed a debt offering of $10.5 billion, re-purchased $8.9 billion of our Class A common stock, and paid $1.3 billion in dividends to shareholders, ending the quarter with $70.9 billion in cash and marketable securities, and $28.8 billion in debt. Moving now to our segment results. I'll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, with more than 3.2 billion people using at least one of our Family of Apps on a daily basis in September. Q3 Total Family of Apps revenue was $40.3 billion, up 19% year -over -year. Q3 Family of Apps ad revenue was $39.9 billion, up 19% or 20% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year -over -year growth, followed by healthcare and entertainment and media. On a user geography basis, ad revenue growth was strongest in rest of world in Europe, at 23% and 21%, respectively. Asia Pacific grew 18%, and North America grew 16%. On an advertiser geography basis, total revenue growth was strongest in North America and Europe at 21%. Rest of world was up 17%, while Asia Pacific was the slowest growing region at 15%, decelerating from our second quarter growth rate of 28% due mainly to lapping a period of stronger demand from China-based advertisers. In Q3, the total number of ad impressions served across our services increased 7%, and the average price per ad increased 11%. Impression growth was mainly driven by Asia Pacific and rest of world. Pricing growth was driven by increased advertiser demand, in part due to improved ad performance. This was partially offset by impression growth, particularly from lower monetizing regions and surfaces. Family of Apps Other revenue was $434 million, up 48%, driven primarily by business messaging revenue growth from our WhatsApp business platform. We continue to direct the majority of our investments for the development and operation of our Family of Apps. In Q3, Family of Apps expenses were $18.5 billion, representing approximately 80% of our overall expenses. Family of Apps expenses were up 13%, primarily due to higher infrastructure and headcount related expenses, partially offset by lower legal related expenses. Family of Apps operating income was $21.8 billion, representing a 54% operating margin. Within our Reality Labs segment, Q3 revenue was $270 million, up 29% driven by hardware sales. Reality Labs expenses were $4.7 billion, up 19% year-over-year, driven primarily by higher headcount related expenses and infrastructure costs. Reality Labs operating loss was $4.4 billion. Turning now to the business outlook. There are two primary factors that drive our revenue performance. Our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we are focused on both improving people's experiences within our apps today and investing in longer term initiatives that have the potential to contribute to engagement in the years ahead. We expect our content recommendations roadmap will span both of these timeframes as we have newer term work streams focused on improving recommendations as well as multi-year initiatives to develop innovative new approaches. I'll focus first on the near term. In the third quarter, we continue to see daily usage grow year-over-year across Facebook and Instagram, both globally and in the US. On Facebook, we're seeing strong results from the global rollout of our unified video player in June. Since introducing the new experience and prediction systems that power it, we've seen a 10% increase in time spent within the Facebook video player. This month, we've entered the next phase of Facebook's video product evolution. Starting in the US and Canada, we are updating the standalone video tab to a full screen viewing experience, which will allow people to seamlessly watch videos in a more immersive experience. We expect to complete this global rollout in early 2025. On Instagram, Reels continues to see good traction, and we're making ongoing progress with our focus on promoting original content, with more than 60% of recommendations now coming from original posts in the U.S. This is helping people find unique and differentiated content on Instagram, while also helping earlier stage creators get discovered. Next, let me talk more about our multi-year roadmap for recommendations. Previously, we operated separate ranking and recommendation systems for each of our products because we found that performance did not scale if we expanded the model size and compute power beyond a certain point. However, inspired by the scaling laws we were observing with our large language models, last year we developed new ranking model architectures capable of learning more effectively from significantly larger datasets. To start, we have been deploying these new architectures to our Facebook video ranking models, which has enabled us to deliver more relevant recommendations and unlock meaningful gains in watch time. Now, we're exploring whether these new models can unlock similar improvements to recommendations on other services. After that, we will look to introduce cross-surface data to these models so our systems can learn from what is interesting to someone on one surface of our apps and use it to improve their recommendations on another. This will take time to execute, and there are other explorations that we will pursue in parallel. However, over time we are optimistic that this will unlock more relevant recommendations while also leading to higher engineering efficiency as we operate a smaller number of recommendations. Beyond recommendations, we're making progress with our other longer term engagement priorities, including generative AI and Threads. Meta AI usage continues to scale as we make it available in more countries and languages. We're seeing lifts in usage as we improve our models and have introduced a number of enhancements in recent months to make Meta AI more helpful and engaging. Last month, we began introducing voice so you can speak with Meta AI more naturally and it's now fully available in English to people in the US, Australia, Canada, and New Zealand. In the US, people can now also upload photos to Meta AI to learn more about them, write captions for posts, and add, remove, or change things about their images with a simple text prompt. These are all built with our first multimodal foundation model, Llama 3.2. Threads remains another area where we see exciting potential. We are bringing on an increasing number of new users each quarter while depth of engagement also continues to grow. Looking ahead, we plan to introduce more features to make it even easier for people to stay up to date on topics they care about. Now to the second driver of our revenue performance, increasing monetization efficiency. There are two parts to this work. The first is optimizing the level of ads within organic engagement. We continue to see opportunities to grow ad supply on lower monetizing surfaces like video. Within Facebook, video engagement continues to shift to short form following the unification of our video player, and we expect this to continue with the transition of the video tab to a full screen format. This is resulting in organic video impressions growing more quickly than overall video time on Facebook, which provides more opportunities to serve ads. Across both Facebook and Instagram, we're also continuing our broader work to optimize when and where we should show ads within a person's session. This is enabling us to drive revenue and conversion growth without increasing the number of ads. The second part of improving monetization efficiency is enhancing marketing performance. Similar to organic content ranking, we are finding opportunities to achieve meaningful ads performance gains by adopting new approaches to modeling. For example, we recently deployed new learning and modeling techniques that enable our ad systems to consider the sequence of actions a person takes before and after seeing an ad. Previously, our ad system could only aggregate those actions together without mapping the sequence. This new approach allows our systems to better anticipate how audiences will respond to specific ads. Since we adopted the new models in the first half of this year, we've already seen a 2% to 4% increase in conversions based on testing within selected segments. We're also evolving our ads platform to ensure that the results we drive are customized to each business' objectives and to the way they measure value. In Q3, we introduce changes to our ads ranking and optimization models to take more of the cross-publisher journey into account, which we expect to increase the Meta-attributed conversions that advertisers see in their third-party analytics tools. We're also testing new features and settings for advertisers that will allow them to optimize their campaigns for what they value most, such as driving incremental conversions rather than absolute conversions. Finally, there is continued momentum with our Advantage + solutions, including our ad creative tools. We're seeing strong retention with advertisers using our generative AI-powered image expansion, background generation, and text generation tools, and they're already driving improved performance for advertisers even at this early stage. Earlier this month, we began testing our first video generation features, video expansion and image animation. We expect to make them more broadly available by early next year. Next, I'd like to discuss our approach to capital allocation. We continue to take a long-term view in running the business, which involves investing in a portfolio of opportunities that we expect will generate returns over different time periods. We are very optimistic about the set of opportunities in front of us and believe that investing now in both infrastructure and talent will not only accelerate our progress, but increase the likelihood of maximizing returns within each area. This includes investing in both near-term initiatives to deliver continued healthy revenue growth within our core business, as well as longer-term opportunities that have the scale to deliver compelling returns over time. Given the lead time of our longer-term investments, we also continue to maximize our flexibility so that we can react to market developments. Within Reality Labs, this has benefited us as we've evolved our roadmap to respond to the earlier-than-expected success of smart glasses. Within generative AI, we expect significantly scaling up our infrastructure capacity now while also prioritizing its fungibility will similarly position as well to respond to how the technology and market develop in the years ahead. Moving now to our financial outlook. We expect fourth quarter 2024 total revenue to be in the range of $45 billion to $48 billion. Our guidance assumes foreign currency is approximately neutral to year-over-year total revenue growth based on current exchange rates. Turning now to the expense outlook. We expect full year 2024 total expenses to be in the range of $96 billion to $98 billion updated from our prior range of $96 billion to $99 billion. For Reality Labs, we continue to expect 2024 operating losses to increase meaningful year-over-year due to our ongoing product development efforts and investments to further scale our ecosystem. Turning now to the CapEx outlook. We anticipate our full year 2024 capital expenditures will be in the range of $38 billion to $40 billion, updated from our prior range of $37 billion to $40 billion. We continue to expect significant capital expenditure growth in 2025. Given this, along with the back-end weighted nature of our 2024 CapEx, we expect a significant acceleration in infrastructure expense growth next year as we recognize higher growth in depreciation and operating expenses of our expanded infrastructure fleet. On to tax, absent any changes to our tax landscape, we expect our fourth quarter 2024 tax rate to be in the low teens. In addition, we continue to monitor an active regulatory landscape, including the increasing legal and regulatory headwinds in the EU and the U.S. that could significantly impact our business and our financial results. In closing, this was another good quarter for our business. Our global community continues to grow. We're seeing ongoing momentum across our core priorities, and we have exciting opportunities ahead of us to drive further growth in our core business in 2025 and capitalize on the longer-term opportunities ahead. With that, Krista, let's open up the call for questions.
Operator: [Operator Instructions] And your first question comes from Brian Nowak with Morgan Stanley.
Brian Nowak: Thanks for taking my questions. I have two. One for Mark and one for Susan. Mark, I wanted to sort of ask you about Meta AI a little bit. Can you help us understand some of the more recurring types of interactions or query types you're seeing with this product and whether they have commercial intent? And then just over time, how do you think about building your own in-house search offering as opposed to partnering and having another player partner those queries? And then, Susan, I wanted to ask you about sort of headcount because you talked a lot about sort of infrastructure investment into ‘25. How do we sort of think about relative headcount investments into ‘25 to sort of support all that infrastructure versus what you've been doing in 2024? Thanks.
Susan Li : Brian, thanks for the question. This is Susan. So your first question was around what kinds of recurring interactions that we see between people and their usage of Meta AI. And we're seeing first of all, I think, as Mark mentioned, just we're excited about the progress of Meta AI. It's obviously very early in its journey, but it continues to be on track to be the most used AI assistant in the world by end of year, and it has over 500 million monthly actives. And people are using it for many things. A number of the frequent use cases we're seeing include information gathering help with how-to tasks, which is the largest use case. But we also see people using it to go deeper on interest, to look for content on our services, for image generation. That's also been another pretty popular use case so far. And I would say that in the near term, our focus is really on making Meta AI increasingly valuable for people. And if we're successful, we think there will be a broadening set of queries that people use it for, including more monetizable queries over time. The second part of your question Meta AI draws from content across the web to address timely questions from users and it provides sources for those results from our search engine partners. We've integrated with Bing and Google, both of whom offer great search experiences. Like other companies, we also train our Gen AI models on content that is publicly available online and we crawl the web for a variety of purposes. Your second question was really, I think, around maybe how we're thinking about headcount in 2025. And we are still working through our budgeting processes for ‘25. That's in part why we changed our forward-looking guidance approach to give guidance in the next call. But as we're working through this, we are looking at where there are opportunities for us to invest in our strategic priorities, and that includes monetization, infrastructure, Reality Labs, Gen AI, our ongoing investments in regulation and compliance, and we're really evaluating each of those opportunities with an eye towards what either the measurable ROI looks like or what the strategic opportunity looks like, depending on what the area is. And we're supporting that by continuing to really focus on streamlining our operations elsewhere. So we don't have specifics to share about headcount growth in 2025, but that gives you a little bit of the flavor of where we are in the budgeting process.
Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs.
Eric Sheridan: Thanks so much for taking the question. Maybe just one building on that question from Brian and going back to Mark's comments about the learnings as you do go through the business planning process. Mark, I wanted to understand better what you continue to learn about what the biggest opportunity sets are to apply AI to when you think about your platform, your product portfolio, and your internal processes because you sound quite optimistic about key learnings and how they continue to ramp and maybe even accelerate in terms of the potential for return profile. I just want to go a little bit deeper into what your key learnings are as you go through that process. Thank you.
Mark Zuckerberg: I think the main point here is just that it seems broadly applicable to a very wide variety of products. There are areas that are more part of our core business from making feed more relevant and reels more relevant to making ads more relevant, to helping advertisers generate better ads, to helping people create the content that they want, helping our integrity operations and compliance and the work that we do there. That's important. It's very valuable across all these aspects of the core business, but then it also is going to enable completely new types of services. We didn't have something like Meta AI before. We didn't have something like the Ray-Ban Meta Glasses before, and AI is going to be a really important ingredient of all of these things. There are also other new products like that, things around AI Studio. This year, we really focused on rolling out Meta AI as kind of our Single Assistant that people can ask any question to, but there's a lot of opportunities that I think will see ramp more over the next year in terms of both consumer and business use cases for people interacting with a wide variety of different AI agents, consumer ones with AI Studio around whether it's different creators or different kind of agents that people create for entertainment. Or on the business side, we do want to continue making progress on this vision of making it so that any small business or any business over time can, with a few clicks, stand up an AI agent that can help do customer service and sell things to all of their customers around the world. I think that that's a huge opportunity. So it's very broad, and I think part of what we're seeing is that there are a lot of opportunities. Some of the longer-term ones around Meta AI or AI Studio, those aren't necessarily a next few years massive profit opportunity, but there are a lot of things in the core business around engagement and monetization, which I think will be over the next few years. So I think we're trying to make sure that we get the right people working on this and that we have the right amount of investment that's just going towards what we view as a very, very large opportunity.
Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan/
Douglas Anmuth: Great. Thanks for taking the questions. Maybe just to follow up first on Meta AI, Mark, helpful context for me to understand how people are using the platform today, maybe you can just talk more about some of that functionality over time as agents are introduced, just how you really expect to use cases to expand beyond just longer and more complex queries. And then, Susan, on CapEx, just trying to understand your comment on 4Q a little bit more, it sounds like some of the payments pushed into 4Q with the guidance suggesting $15 billion to $17 billion in CapEx in the quarter. And is that something we should think about as run rate into 2025? Thank you.
Mark Zuckerberg: Yes, I mean, I can take the Meta AI question, although I'm sort of intentionally now not saying too much about the new capabilities and modalities that we're launching with Llama 4 e that are coming to Meta AI. I mean, I noted in the comments upfront that with each major generational update, I expect that there will be large new capacities that get added, but I think that that's just going to be, that's partially what I'm excited about, and we'll talk more about that next year when we're ready to. One of the trends that I do think we're going to see though is having the models, not just power Meta AI or our Single Assistant, but across AI Studio and business agents have that grow. I mean, this year, if you look back to where we were about a year ago, we were starting to roll out Meta AI. This year, we have really so far succeeded in having that grow and having a lot of people use that. There's obviously a lot more depth of engagement and new use cases that we want to add over time, but I'd say that we're today with AI Studio and business AIs about where we were with Meta AI about a year ago. So I think in the next year, our goal around that is going to be to try to make those pretty widespread use cases, even though there's going to be a multi-year path to getting kind of the depth of usage and the business results around that that we want. So there's a lot to do here though, and I'm excited to talk about that starting earlier next year.
Susan Li : Thanks Doug. So your second question was about Q4 CapEx. The expected step up in Q4 CapEx from Q3 is that part of that comes from increases in server spend and to a lesser extent data center CapEx, but with servers, there are these timing dynamics at play that you referred to because we had these server deliveries that landed late in Q3, and so the cash doesn't go out the door basically till Q4, and that's when you'll see the CapEx show up. And given the nature of capital expenditures generally, there is some actually quite a bit of lumpiness quarter-to-quarter. So it's a little bit hard to sort of extrapolate from any particular quarter. Overall, I'd say we're growing our infrastructure investments significantly this year, and we expect significant growth again in 2025.
Operator: Your next question comes from the line of Justin Post with Bank of America.
Justin Post: Great. I think I'll ask a cost question this time. Just thinking about use of AI and employee productivity, how are you able to utilize AI internally, and are you seeing big productivity gains in your R&D group? And second, I know I'll go after the headcount one more time, but Susan, how flexible is your headcount as you think about cost growth in other areas? Thanks.
Susan Li : Justin, so I'll take a crack at both of those. On the use of AI and employee productivity, it's certainly something that we're very excited about. I don't know that we have anything particularly quantitative that we're sharing right now. I think there are different efficiency opportunities with AI that we've been focused on in terms of where we can reduce costs over time and generate savings through increasing internal productivity in areas like coding for example, it's early, but we're seeing a lot of adoption internally of our internal assistant and coding agent. And we continue to make Llama more effective at coding, which should also make this use case increasingly valuable to developers over time. There are also places where we hope over time that we'll be able to deploy these tools against a lot of our content moderation efforts to help make the big body of content moderation work that we undertake to help it make it more efficient and effective for us to do so. And there are lots of other places around the company where I would say we're relatively early in exploring the way that we can use LLM-based tools to make different types of work streams more efficient. So all that is to say it's something we're pretty excited about. We have lots of teams focused on it. There are sort of small opportunities and G&A functions to what we hope will be big opportunities in areas like content moderation and coding productivity over time. On your second question about headcount, we're really, again, we're still mid-budget, so there's, we don't have very much that is definitive to share about this at the time. But as we're evaluating where there are opportunities for us to make good investments, we really think about there is a bucket of very ROI-driven headcount opportunities. We're very rigorous about the way we think about returns there and what the return opportunity is and what we think is the likelihood of those returns and what is the aggregate incrementality of those investments. And those are all things that sort of we're evaluating when we think about where to invest in the core business and where we think we can deliver sort of ROI on a near-term basis. And then at the same time, we're also assessing what the opportunities look like, again, some of the more medium and long-term strategic areas of investment. And that includes our efforts in Gen AI and the infrastructure needed to support it and includes our investments in Reality Labs. And so those are all things that we're kind of assessing in kind of a portfolio of what we think we would do in 2025. With a couple of thoughts, one is, again, where can we sort of build the most flexibility into the way that we're thinking about either infrastructure or headcount plans. And the second is we're really focused across the company on our efficiency efforts broadly and making sure that we feel like we're continuing to push the whole company, including areas in which we expect that we will be making additional headcount investments to think about how they can be more efficient in 2025 than they were in 2024.
Operator: Your next question comes from the line of Ross Sandler with Barclays.
Ross Sandler: Great. Just two quick ones, Mark. You said something along the lines of the more standardized Llama becomes, the more improvements will flow back to the core Meta business. And I guess, could you dig in a little bit more on that? So the series of Llama models are being used by lots of developers building different things in AI. I guess, how are you using that vantage point to incubate new ideas inside Meta? And then second question is, you mentioned on one of the podcasts after the Meta Connect that assuming scaling laws hold up, we may need hundreds of billions of compute CapEx to kind of reach our goals around Gen AI. So I guess how quickly could you conceivably stand up that much infrastructure given some of the constraints around energy or custom ASICs or other factors? Is there any more color on the speed by which we could get that amount of compute online at Meta? Thank you.
Mark Zuckerberg: Yes, I can try to give some more color on this. I mean, the improvements to Llama, I'd say come in a couple of flavors. There's sort of the quality flavor and the efficiency flavor. There are a lot of researchers and independent developers who do work. And because Llama is available, they do the work on Llama and they make improvements and then they publish it and it becomes, it's very easy for us to then incorporate that both back into Llama and into our Meta products like Meta AI or AI Studio or Business AI because the work to be examples that are being shown are people doing it on our stack. Perhaps more importantly is just the efficiency and cost. I mean, this stuff is obviously very expensive. When someone figures out a way to run this better, if they can run it 20% more effectively, then that will save us a huge amount of money. And that was sort of the experience that we had with open compute and part of why we are leaning so much into open source here in the first place is that we found counterintuitively with open compute that by publishing and sharing the architectures and designs that we had for our compute, the industry standardized around it a bit more. We got some suggestions also that helped us save costs, and that just ended up being really valuable for us. Here, one of the big costs is chips. A lot of the infrastructure there, what we're seeing is that as Llama gets adopted more, you're seeing folks like NVIDIA and AMD and optimize their chips more to run Llama specifically well, which clearly benefits us. So it benefits everyone who's using Llama, but it makes our products better rather than if we were just on an island building a model that no one was kind of standardizing around in the industry. So that's some of what we're seeing around Llama and why I think it's good business for us to do this in an open way. In terms of Scaling Infra, when I talk about our teams executing well, some of that goes towards delivering more engaging products and some of it goes towards delivering more revenue. On the Infra side, it goes towards building out the expenses faster, right. So I think part of what we're seeing this year is the Infra team is executing quite well. And I think that's why over the course of the year, we've been able to build out more capacity and going into the year, we had a range for what we thought we could potentially do. And we have been able to do, I think, more than I think we'd kind of hoped and expected at the beginning of the year. And while that reflects as higher expenses, it's actually something that I'm quite happy that the team is executing well on. And I think that will, so that execution makes me somewhat more optimistic that we're going to be able to keep on building this out at a good pace. But that's part of this whole thing is this part of the formula around kind of building out the infrastructures is maybe not what investors want to hear in the near term that we're growing that, but I just think that the opportunities here are really big. We're going to continue investing significantly in this. And I'm proud of the teams that are doing great work to stand up a large amount of capacity. So that way we can deliver world class models and world class products.
Operator: Your next question comes from the line of Ron Josey with Citi.
Ronald Josey: Great. Thanks for taking the question. Maybe a bigger picture one as well, Mark, just this time on Threads, now one of the core apps on its way to becoming the next major social app and 275 million AMUs, wanted to hear your thoughts on how this product evolves over time, specifically from a monetization perspective, but also next steps on users. And then, Susan, with pricing up 11% in the quarter, I want to hear more about the pricing dynamics on the platform. I think you talked about just pricing increasing due to greater advertising demand and improved ad performance. So help us understand that a little bit more. Thank you.
Susan Li : Thanks, Ron. So your first question was about Threads. We're making good progress there. We are continuing to launch more features and make improvements to our ranking stack. We feel very good about the continued user growth on Threads. We're bringing on an increasing number of users each quarter and depth of engagement also continues to grow and in Q3, we saw especially strong user growth in key markets like the US, Taiwan, and Japan and we've added a number of new features over the course of Q3 including, account insights for businesses and creators to see how their posts perform, the ability to save multiple drafts, continuing to deliver on our commitment to integrate Threads with the Fediverse and basically we're very focused on continuing to build out the sort of functionality of Threads over time and being responsive to what users tell us that they're interested in. Specifically, as it pertains to monetization, we don't expect Threads to be a meaningful driver of 2025 revenue at this time. We've been just pleased with the growth trajectory and, again, are really focused on introducing features that the community finds valuable in working to deepen growth and engagement. Your second question was about the increase in average price per ad, so that grew 11% year-over-year driven by strong advertiser demand and part of that is because of better ad performance over time also and we saw that CPM growth accelerate slightly from 10% in Q2 in part because we experienced lower impression growth in Q3, but more broadly as we think about price and growth and this metric, the year-over-year growth in reported price per ad, there's a lot that goes into that including the auction dynamics resulting from fluctuations and impression growth. And one of the things that we feel like we're very focused on is really the input metrics. What are the conversions that we are delivering to advertisers? Are they getting more value over time? The sort of blended reported price per ad is complicated because all of those things get rolled up into it. There are so many different objectives that advertisers are optimizing for. Those objectives have very different values that make them hard to compare on an apples to apples basis. But we care a lot about conversion growth, which is growing, continues to grow faster than impression growth. And are we seeing healthy cost per action or cost per conversion trends, which we are. And as long as we continue to get better at driving conversions for advertisers, that should have the effect of lifting CPMs over time because we're delivering more conversions for impressions served and that will result in higher value impressions.
Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo.
Ken Gawrelski: Thanks for the opportunity. I appreciate that. I have a bigger picture, kind of like ecosystem question here is, when we think, I'm curious, how far do you think we are from seeing a proliferation of third-party AI applications, specifically on the kind of the consumer side? I know we're seeing more and more on the enterprise side, agents, et cetera. But when do we see, how far out until we see a proliferation of consumer applications in the AI space? And how do you think about, and how does Meta think of itself as one of those key, it was one of those key application applications in the mobile internet and the desktop internet. But now you're also seemingly an infrastructure player as well. So I'd love to hear your thoughts there. Thank you.
Mark Zuckerberg: Yes, I mean, there are a lot of consumer products that we're working on. And with Llama, I would expect that app developers will be able to build a lot of really good things too. I've touched on Meta AI and AI Studio and Business AI as a bunch. And I expect those to be important parts of the consumer experience. Another part that I haven't talked about quite as much yet is the opportunity for AI to help people create content that just makes people's feed experiences better. But if you look at the big trends and feeds over the history of the company, it started off as friends, right. So all the updates that were in there were basically from your friends posting things. And then we went into this era where we added in creator content too. We're now a very large percent of the content on Instagram and Facebook is not from your friends. It may not even be from people that you're following directly. It could just be recommended content from creators that we can algorithmically determine is going to be interesting and engaging and valuable to you. And I think we're going to add a whole new category of content which is AI generated or AI summarized content or kind of existing content pulled together by AI in some way and I think that that's going to be just very exciting for Facebook and Instagram and maybe Threads or other kind of feed experiences over time. It's something that we're starting to test different things around this. I don't know if we know exactly what's going to work really well yet. Some things are promising. I don't know that this isn't going to be a big impact on the business in ‘25 would be my guess. But I think that there is, I have high confidence that over the next several years, this is going to be an important trend and one of the important applications. But you're going to get that, you're going to get Meta AI, AI studio, Business AI has been a whole lot of things that developers would do with Llama 2.
Operator: Your next question comes from the line of Youssef Squali with Truist Securities.
Youssef Squali: Yes, thank you very much, Mark, it appears that Meta AI now calls the web and provides conversational answers about pretty much anything including current events. And so with over 10 million advertisers and one of the best URLs offerings out there in your core business, just wondering if there are any plans to start maybe testing ads on commercial queries and move Meta AI closer to becoming a real answer engines for the billions of queries that you guys are already seeing. And then Susan, one of the biggest areas of pushback we get is around the reality of lasting the ongoing losses there. I think 16 billion last year, probably north of 20 billion this year. The question is, are we getting any closer to peak losses there or alternatively, what products do you think have the biggest potential there over the next couple of years? Thanks.
Susan Li : I'm happy to take both of these, Youssef, so your first question was on plans to provide ads on commercial queries. I think I alluded to this maybe in a much earlier question. Right now, we're really focused on making Meta AI as engaging and valuable a consumer experience as possible. Over time we think there will be a broadening set of queries that people use it for, and I think that the monetization opportunities will exist when over time as we get there. But right now, I would say we are really focused on the consumer experience above all, and it's just sort of a playbook for us with products that we put out in the world where we really dial in the consumer experience before we focus on what the monetization could look like. The second part of your question is about Reality Labs. We aren't sharing expectations beyond 2024 at this point. And we are certainly as we think about the 2025 budgeting process for Reality Labs, we're certainly thinking about where we want to make sure we're putting our sort of focus and energy. We are very excited again about the progress that we've seen with our smart glasses as well as the sort of strong consumer interest in them. And so we're kind of thinking about where we want to make sure that we are investing appropriately behind the consumer momentum that we see. Overall, I'd say Reality Labs is clearly one of our strategic long-term priorities and we expect it will be an area of significant investment as we build out towards the very ambitious product roadmap that we have there.
Operator: Your last question comes from the line of Mark Mahaney with Evercore ISI.
Mark Mahaney: Let me throw out two questions, please. One, this is a year in which we've had a lot of unusual events that could be driving ad revenue, major elections in not just the U.S. but Europe and in India and major sports events like World Cup and then there's some other things. Is there any, just in thinking about comps for next year and maybe in the future, anything, Susan, you would call out, like, how much of an impact there may have come from these one in every four or five year events. And then secondly, could you just talk a little bit more about WhatsApp monetization and where you are with that now? It sounds like that's the business messaging part; it's really feeding it nicely into other revenue. But help us think about where the monetization levels of WhatsApp are now versus where they can be two or three years down the road, how far away we are from optimization. Thank you.
Susan Li : Thanks, Mark. So your first question was about sort of the revenue backdrop in 2024. You mentioned events that occur once every four or five years, so I imagine we're talking about the Olympics. We historically have not seen meaningful incremental contribution from events like the Olympics. We believe that was largely the case this year. So when we think about the Q4 outlook and when we think about going into next year, we generally expect growth to continue to benefit from the healthy global advertising demand that we've seen. We think that our investments in improving our ads performance will continue to accrue benefits to advertisers. But obviously there's a big range of possible macro backdrops and that's something that we try to reflect in the range of revenue guidance that we give. But I don't know that there are a lot of specific events that we would say had a material sort of idiosyncratic to 2024 type of revenue impact. Your second question was around WhatsApp monetization and where we are. And right now what I would say again is click to message is really the big focus area for us here. We're seeing continued traction in this area. And in particular growth and click-to-WhatsApp ads remain particularly strong. And so we're continuing to focus both on scaling click-to-WhatsApp ads in more markets where WhatsApp has strong user adoption like Brazil for example. It's obviously earlier in the US but we're seeing good growth in click-to-WhatsApp ads and are continuing to invest in scaling in consumer adoption of WhatsApp in the US also which will create bigger opportunities down the line. So, and then of course a lot of work that we're doing to make the click to messaging ads more effective and helping to focus for the particular, helping advertisers optimize sorry for the particular conversion events that they care about. The other element of revenue on WhatsApp, I would say, is paid messaging that continues to grow at a strong pace again. This quarter remains, in fact, the primary driver of growth in our Family of Apps, other revenue line, which was up 48% in Q3, and we're seeing generally a strong increase in the volume of paid conversations driven both by growth in the number of businesses adopting paid messaging, as well as in the conversational volume per business.
Kenneth Dorell : Great. Thank you for joining us today. We appreciate your time, and we look forward to speaking with you again soon.
Operator: This concludes today's conference call. Thank you for your participation. And you may now disconnect.",2024-10-30
META,2024,4,2024-Q4-META,"Operator: Good afternoon. My name is Krista and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta Fourth Quarter and Full-Year 2024 Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speaker's remarks, there will be a question-and-answer session. [Operator Instructions] And this call will be recorded. Thank you very much. Kenneth Dorell, Metta's Director of Investor Relations, you may begin.
Kenneth Dorell: Thank you. Good afternoon and welcome to Meta Platforms fourth quarter and full year 2024 earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO and Susan Li, CFO. Before we get started, I would like to take this opportunity to remind you that our remarks today will include forward‐looking statements. Actual results may differ materially from those contemplated by these forward‐looking statements. Factors that could cause these results to differ materially are set forth in today’s earnings press release, and in our quarterly report on form 10-Q filed with the SEC. Any forward‐looking statements that we make on this call are based on assumptions as of today and we undertake no obligation to update these statements as a result of new information or future events. During this call we will present both GAAP and certain non‐GAAP financial measures. A reconciliation of GAAP to non‐GAAP measures is included in today’s earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.atmeta.com. And now, I’d like to turn the call over to Mark.
Mark Zuckerberg: All right. Thanks, Ken. Thanks everyone for joining today. We ended 2024 on a strong note with now more than 3.3 billion people using at least one of our apps each day. This is going to be a really big year. I know it always feels like every year is a big year, but more than usual it feels like the trajectory for most of our long-term initiatives is going to be a lot clearer by the end of this year. So I keep telling our teams that this is going to be intense, because we have about 48-weeks to get on the trajectory we want to be on. In AI, I expect this is going to be the year when a highly intelligent and personalized AI assistant reaches more than 1 billion people, and I expect Meta AI to be that leading AI assistant. Meta AI is already used by more people than any other assistant, and once a service reaches that kind of scale it usually develops a durable long-term advantage. We have a really exciting roadmap for this year with a unique vision focused on personalization. We believe that people don't all want to use the same AI, people want their AI to be personalized to their context, their interests, their personality, their culture, and how they think about the world. I don't think that there's just going to be one big AI that everyone uses that does the same thing. People are going to get to choose how their AI works and what it looks like for them. I continue to think that this is going to be one of the most transformative products that we’ve made. And we have some fun surprises that I think people are going to like this year. I think this very well be the year when Llama and open source become the most advanced and widely used AI models as well. Llama 4 is making great progress in training. Llama 4 mini is done with pre-training and our reasoning models and larger model are looking good too. Our goal with Llama 3 was to make open source competitive with closed models, and our goal for Llama 4 is to lead. Llama 4 will be natively multimodal; it's an omni-model and will have agentic capabilities, so it's going to be novel and it’s going to unlock a lot of new use cases. I'm looking forward to sharing more of our plan for the year on that over the next couple of months. I also expect that 2025 will be the year when it becomes possible to build an AI engineering agent that has coding and problem-solving abilities of around a good mid-level engineer. And this is going to be a profound milestone and potentially one of the most important innovations in history, as well as over time, potentially a very large market. Whichever company builds this first I think is going to have a meaningful advantage in deploying it to advance their AI research and shape the field. So that's another reason why I think that this year is going to set the course for the future. Our Ray-Ban Meta AI glasses are a real hit, and this will be the year when we understand the trajectory for AI glasses as a category. Many breakout products in the history of consumer electronics have sold 5 million to 10 million units in their third generation. This will be a defining year that determines if we're on a path towards many hundreds of millions and eventually billions of AI glasses and glasses being the next computing platform like we've been talking about for some time or if this is just going to be a longer grind. But it's great overall to see people recognizing that these glasses are the perfect form factor for AI, as well as just great, stylish glasses. These are all big investments, especially the hundreds of billions of dollars that we will invest in AI infrastructure over the long-term. I announced last week that we expect to bring online almost 1 gigawatt of capacity this year, and we're building a 2 gigawatt and potentially bigger AI datacenter, that is so big that it will cover a significant part of Manhattan if it were placed there. We're planning to fund all this by at the same time investing aggressively in initiatives that use these AI advances to increase revenue growth. And we've put together a plan that will hopefully accelerate the pace of these initiatives over the next few years. That’s what a lot of our new headcount growth is going towards. And how well we execute on this will also determine our financial trajectory over the next few years. There are a number of other important product trends related to our family of apps that I think we’re going to know more about this year as well. We're going to learn what's going to happen with TikTok, and regardless of that I expect Reels on Instagram and Facebook to continue growing. I expect Threads to continue on its trajectory to become the leading discussion platform and eventually reach 1 billion people over the next several years. Threads now has more than 320 million monthly actives and has been adding more than 1 million sign-ups per day. I expect WhatsApp to continue gaining share and making progress towards becoming the leading messaging platform in the U.S. like it is in a lot of the rest of the world. WhatsApp now has more than 100 million monthly actives in the U.S. Facebook is used by more than 3 billion monthly actives and we're focused on growing its cultural influence. And I'm excited this year to get back to some OG Facebook. All right. So this is also going to be a pivotal year for the metaverse. The number of people using Quest and Horizon has been steadily growing, and this is a year when a number of long-term investments that we've been working on that will make the metaverse more visually stunning and inspiring will really start to land. So I think we’re going to know a lot more about Horizon's trajectory by the end of this year. This is also going to be a big year for redefining our relationship with governments. We now have a U.S. administration that is proud of our leading companies, prioritizes American technology winning, and that will defend our values and interests abroad. And I'm optimistic about the progress and innovation this is can unlock. So this is going to be a big year. I think this is the most exciting and dynamic that I have ever seen our industry. Between AI, glasses, massive infrastructure projects, doing a bunch of work to try to accelerate our business, and building the future of social media, we have a lot to do. And I think we're going to build some awesome things that shape the future of human connection. As always, I'm grateful for everyone who is on this journey with us. Thank you and here’s Susan.
Susan Li: Thanks Mark and good afternoon everyone. Let’s begin with our consolidated results. All comparisons are on a year-over-year basis unless otherwise noted. Q4 total revenue was $48.4 billion, up 21% on both a reported and constant currency basis. Q4 total expenses were $25 billion, up 5%, compared to last year. Before I cover the specific cost lines, I would note that our fourth quarter expense growth rate reflects a 13 percentage point favorable impact from legal accrual reductions in Q4 and lower year-over-year restructuring costs. In terms of the specific line items. Cost of revenue increased 15%, driven mostly by higher infrastructure costs. R&D increased 16%, primarily driven by higher employee compensation and infrastructure costs, which were partially offset by lower restructuring costs. Marketing & Sales were approximately flat year-over-year. G&A decreased 67%, driven mostly by lower legal-related expenses due to a $1.55 billion reduction in legal accruals related to certain legal proceedings. We ended the year with over 74,000 employees, up 10% year-over-year, with growth primarily driven by hiring in priority areas of monetization, infrastructure, generative AI, Reality Labs, as well as regulation and compliance. Fourth quarter operating income was $23.4 billion, representing a 48% operating margin. Our tax rate for the quarter was 12%. Net income was $20.8 billion or $8.02 per share. Capital expenditures, including principal payments on finance leases, were $14.8 billion, driven by investments in servers, data centers and network infrastructure. Free cash flow was $13.2 billion. We paid $1.3 billion in dividends to shareholders, ending the year with $77.8 billion in cash and marketable securities and $28.8 billion in debt. Moving now to our segment results. I’ll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, and we estimate more than 3.3 billion people used at least one of our Family of Apps on a daily basis in December. Q4 Total Family of Apps revenue was $47.3 billion, up 21% year-over-year. And Q4 Family of Apps ad revenue was $46.8 billion, up 21% on both a reported and constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year-over-year growth. On a user geography basis, ad revenue growth was strongest in Rest of World at 27%, followed by Asia-Pacific and Europe at 23% and 22%, respectively. North America grew 18%. In Q4, the total number of ad impressions served across our services increased 6% and the average price per ad increased 14%. Impression growth was mainly driven by Asia-Pacific. Pricing growth benefited from increased advertiser demand, in part driven by improved ad performance. This was partially offset by impression growth, particularly from lower-monetizing regions and surfaces. Family of Apps other revenue was $519 million, up 55%, driven primarily by business messaging revenue growth from our WhatsApp Business Platform. We continue to direct the majority of our investments toward the development and operation of our Family of Apps. In Q4, Family of Apps expenses were $19 billion, representing 76% of our overall expenses. Family of Apps expenses were up 5%, primarily due to growth in infrastructure costs and employee compensation, which were partially offset by lower legal-related expenses. Family of Apps operating income was $28.3 billion, representing a 60% operating margin. Within our Reality Labs segment, Q4 revenue was $1.1 billion, driven by hardware sales and up 1% year-over-year. Reality Labs expenses were $6 billion, up 6% year-over-year, driven primarily by higher infrastructure costs and employee compensation, partially offset by lower restructuring costs. Reality Labs operating loss was $5 billion. Turning now to the business outlook. There are two primary factors that drive our revenue performance: our ability to deliver engaging experiences for our community, and our effectiveness at monetizing that engagement over time. On the first, daily actives continue to grow across Facebook, Instagram and WhatsApp year-over-year, both globally and in the United States. In Q4, global video time grew at double-digit percentages year-over-year on Instagram, and we’re seeing particular strength in the U.S. on Facebook, where video time spent was also up double-digit rates year-over-year. We see continued opportunities to drive video growth in 2025 through ongoing optimizations to our ranking systems. We’re also making several product bets that are focused on setting up our platforms for longer-term success. Creators are one of our central focuses. On Instagram, we continue to prioritize original posts in recommendations to help smaller creators get discovered. We also want to ensure creators have a place to experiment with their content, so we introduced a new feature in Q4 that allows creators to first share a Reel with people who don’t follow them. This allows them to test content and see what performs best before deciding to share it with their followers, and also helps introduce them to entirely new audiences. Creative tools is another area we’re investing in. In the coming weeks, we’ll launch a new standalone app called Edits that provides a full suite of creative tools to make it easier for creators to make great Reels on their phone. Another focus is making it easier for people to connect over content. Reels are already reshared over 4.5 billion times a day, and we’ve been introducing more features that bring together the social and entertainment aspects of Instagram. In the U.S., we recently launched a new destination in Reels that consists of content your friends have left a note on or liked. We’re seeing very positive early results and will look to expand this globally in the coming months. On Threads, we made tremendous progress in 2024 and our focus this year is establishing Threads as the place people come to keep up with what they care about. We’re making a number of updates to our recommendation systems to prioritize more recent posts, surface content from top creators, and ensure people see more of the content from accounts they follow. We will also continue improving custom feeds so people can build personalized feeds on topics they’re interested in. Finally, Meta AI usage continues to scale, with more than 700 million monthly actives. We’re now introducing updates that will enable Meta AI to deliver more personalized and relevant responses by remembering certain details from people’s prior queries and considering what they engage with on Facebook and Instagram to develop better intuition for their interests and preferences. Now to the second driver of our revenue performance: increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to grow supply on lower monetizing surfaces, like video, while optimizing ad supply on each of our surfaces to deliver ads at the time and place they will be most relevant to people. For example, we are continuing to better personalize when ads show up, including the optimal locations in the depth of someone’s feed, to introduce ad supply when it’s most optimal for the user and revenue. This is enabling efficient supply growth. Longer term, we also see impression growth opportunities on unmonetized surfaces like Threads, which we are beginning to test ads on this quarter. We expect the introduction of ads on Threads will be gradual and don’t anticipate it being a meaningful driver of overall impression or revenue growth in 2025. The second part of increasing monetization efficiency is improving marketing performance. The ongoing enhancements to our ads ranking systems are an important driver of this work. In the second-half of 2024, we introduced an innovative new machine learning system in partnership with Nvidia, called Andromeda. This more efficient system enabled a 10,000 times increase in the complexity of models we use for ads retrieval, which is the part of the ranking process where we narrow down a pool of tens of millions of ads to the few thousand we consider showing someone. The increase in model complexity is enabling us to run far more sophisticated prediction models to better personalize, which ads we show someone. This has driven an 8% increase in the quality of ads that people see on objectives we’ve tested. Andromeda’s ability to efficiently process larger volumes of ads also positions us well for the future as advertisers use our generative AI tools to create and test more ads. Another way we’re delivering value for advertisers is through increased automation of their ad campaigns with Advantage+. Adoption of Advantage+ shopping campaigns continues to scale, with revenue surpassing a $20 billion annual run-rate and growing 70% year-over-year in Q4. Given the strong performance and interest we’re seeing in Advantage+ Shopping and our other end-to-end solutions, we’re testing a new streamlined campaign creation flow so advertisers no longer need to choose between running a manual or Advantage+ Sales or App campaign. In this new setup, all campaigns optimizing for sales, app or lead objectives will have Advantage+ turned on from the beginning. This will allow more advertisers to take advantage of the performance Advantage+ offers, while still having the ability to further customize aspects of their campaigns when they need to. We plan to expand to more advertisers in the coming months before fully rolling it out later in the year. Advantage+ creative is another area where we’re seeing momentum. More than 4 million advertisers are now using at least one of our generative AI ad creative tools, up from one million six months ago. There has been significant early adoption of our first video generation tool that we rolled out in October, Image Animation, with hundreds of thousands of advertisers already using it monthly. Next, I would like to discuss our approach to capital allocation. Our primary focus remains investing capital back into the business, with infrastructure and talent being our top priorities. On the first, we expect compute will be central to many of the opportunities we’re pursuing as we advance the capabilities of Llama, drive increased usage of generative AI products and features across our platform, and fuel core ads and organic engagement initiatives. We’re working to meet the growing capacity needs for these services by both scaling our infrastructure footprint and increasing the efficiency of our workloads. Another way we’re pursuing efficiencies is by extending the useful lives of our servers and associated networking equipment. Our expectation going forward is that we’ll be able to use both our non-AI and AI servers for a longer period of time before replacing them, which we estimate will be approximately 5.5 years. This will deliver savings in annual CapEx and resulting depreciation expense, which is already included in our guidance. Finally, we’re pursuing cost efficiencies by deploying our custom MTIA silicon in areas where we can achieve a lower cost of compute by optimizing the chip to our unique workloads. In 2024 we started deploying MTIA to our ranking and recommendation inference workloads for ads and organic content. We expect to further ramp adoption of MTIA for these use cases throughout 2025 before extending our custom silicon efforts to training workloads for ranking and 0recommendations next year. From a hiring standpoint, our focus continues to be on adding technical talent to support our strategic priorities. In the fourth quarter, nearly 90% of our year-over-year headcount growth was within the R&D function. The remaining growth was primarily in cost of revenue as we added infrastructure headcount to support our data center operations. In 2025, we expect headcount growth will continue to be primarily driven by technical roles across our priority initiatives within infrastructure, monetization, Reality Labs, generative AI, as well as regulation and compliance. We anticipate headcount growth in our business functions will remain relatively limited. To achieve our ambitions in these areas, we will need to continue executing at a rapid pace. We’re supporting this by building tools to help our engineering base be more productive. As part of our efficiency focus over the past two years, we’ve made significant improvements in our internal processes and developer tools and introduced new tools like our AI-powered coding assistant, which is helping our engineers write code more quickly. Looking forward, we expect that the continuous advancements in Llama’s coding capabilities will provide even greater leverage to our engineers, and we are focused on expanding its capabilities to not only assist our engineers in writing and reviewing our code, but also to begin generating code changes to automate tool updates and improve the quality of our code base. Finally, we expect our strong financial position will enable us to support these investments while continuing to return capital to shareholders through share repurchases and dividends. Moving to our financial outlook. We expect first quarter 2025 total revenue to be in the range of $39.5 billion to $41.8 billion. This reflects 8% to 15% year-over-year growth, or 11% to 18% growth on a constant currency basis as our guidance assumes foreign currency is an approximately 3% headwind to year-over-year total revenue growth, based on current exchange rates. This also reflects the effect of lapping leap day in the first quarter of 2024. While we are not providing a full-year 2025 revenue outlook, we expect the investments we’re making in our core business this year will give us an opportunity to continue delivering strong revenue growth throughout 2025. Turning now to the expense outlook. We expect full-year 2025 total expenses to be in the range of $114 billion to $119 billion. We expect the single largest driver of expense growth in 2025 to be infrastructure costs, driven by higher operating expenses and depreciation. We expect employee compensation to be the second-largest factor as we add technical talent in the priority areas that I referenced earlier. Turning now to the CapEx outlook. We anticipate our full-year 2025 capital expenditures will be in the range of $60 billion to $65 billion. We expect CapEx growth in 2025 will be driven by increased investment to support both our generative AI efforts and our core business. The majority of our CapEx in 2025 will continue to be directed toward our core business. On to tax. Absent any changes to our tax landscape, we expect our full-year 2025 tax rate to be in the range of 12% to 15%. In addition, we continue to monitor an active regulatory landscape, including legal and regulatory headwinds in the EU and the U.S. that could significantly impact our business and our financial results. In closing, this was a good year for our company, with investments across our priority areas delivering strong business performance and innovative new products for our community. We have a compelling set of opportunities to invest in this year, which we expect will help us drive continued strong growth and develop transformative technologies that shape the future of our company and of the industry. With that, Krista, let’s open up the call for questions.
Operator: Thank you. Thank you. We will now open the lines for a question-and-answer session. [Operator Instructions] And our first question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.
Brian Nowak: Thanks for taking my questions. Mark, I appreciate all the excitement about this year and all the innovation to come. I know there's a lot of announcements throughout the course of the year, but I wonder if you could just share a few sort of high-level examples of your vision on new potential use cases and offerings that could drive utility for your users and value for your advertisers. As you sort of think about Llama 4 and Meta AI changing throughout 2025? And then the second one on custom silicon, maybe a question for either of you. Just any learnings on the difference between your custom silicon and third-party chips in your ranking models and results? And how should we think about the main gating factors as to how quickly you'd be able to move a higher percentage of your engagement to your custom silicon? Thanks.
Mark Zuckerberg: On the first one, I tried to lay this out in my opening comments a bit. I mean we're very focused on Meta AI as a highly intelligent and personalized assistant that you can access across our apps. There's a website, you can access it outside of our apps, too. I think that the quality of this is just -- it's going to keep on improving and improved a lot over the last year. We're also finding more ways that it's useful to integrate it into our services to help more people discover it. I think that, that's undoubtedly why so many hundreds of millions of people are using it today, obviously, because it's kind of easy to discover what we're doing and then keep using it. I don't know. I want to keep some surprises and fun for the stuff that we're going to release this year. I gave a bit of detail on what we're planning to do with Llama 4 that I'm sure technical people will enjoy, because we haven't talked about that before. But I'm going to refrain from adding a whole lot more on what we're launching this year. But it's the different things that I talked about. It's Meta AI. I do expect Llama 4 to be a very exciting set of releases. It's not just one thing. Just like with Llama 3, there were kind of a few different models at different dates, I think we'll see that with Llama 4 too. And then the AI engineer piece, I'm really excited about it. I mean, I don't know that that's going to be an external product anytime soon. But I think for what we're working on, our goal is to advance AI research and advance our own development internally. And I think it's just going to be a very profound thing. So I mean that's something that I think will show up through making our products better over time. But -- and then as that works, there will potentially be a market opportunity down the road. But I mean, for now and this year, we're really -- I think this is -- I don't think you're going to see this year like an AI engineer that is extremely widely deployed, changing all of development. I think this is going to be the year where that really starts to become possible and lays the groundwork for a much more dramatic change in '26 and beyond. I don't know yes, that's kind of it.
Susan Li: Brian, I'm happy to take your second question about custom silicon. So first of all, we expect that we are continuing to purchase third-party silicon from leading providers in the industry. And we are certainly committed to those long-standing partnerships, but we're also very invested in developing our own custom silicon for unique workloads, where off-the-shelf silicon isn't necessarily optimal and specifically, because we're able to optimize the full stack to achieve greater compute efficiency and performance per cost and power because our workloads might require a different mix of memory versus network, bandwidth versus compute and so we can optimize that really to the specific needs of our different types of workloads. Right now, the in-house MTIA program is focused on supporting our core ranking and recommendation inference workloads. We started adopting MTIA in the first half of 2024 for core ranking and recommendations inference. We'll continue ramping adoption for those workloads over the course of 2025 as we use it for both incremental capacity and to replace some GPU-based servers when they reach the end of their useful lives. Next year, we're hoping to expand MTIA to support some of our core AI training workloads and over time, some of our Gen AI use cases.
Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.
Eric Sheridan: Thank you so much for taking the question. Maybe I can go back to your comments on open source. Can you help us understand how your views continue to evolve with respect to the competitive dynamic around your approach with open source versus others in the industry? And how your approach to open source could possibly bend the cost curve and improve return on capital for AI over the medium to long-term? Thanks so much.
Mark Zuckerberg: Yes. I mean on open source, I think the best analogy for us is what we did with open compute, where we weren't first to building the system. So then by the time that we got around to building it, it wasn't really a big advantage to have it be proprietary. So we shared it. And then a lot of the industry adopted what we were doing, contributed innovations back to it. By standardizing it on it, that meant that a bunch of supply chain standardized on building it, which made prices more efficient for everyone. I think what we see here is as Llama becomes more used, it's more likely, for example, that silicon providers and others -- other APIs and developer platforms will optimize their work more for that and basically drive down the costs of using it and drive improvements that we can, in some cases, use too. So I think that the strategy will continue to be effective, and yes, I mean, I continue to be optimistic about this. I think it's kind of -- I think it's working. I also just think in light of some of the recent news, the new competitor DeepSeek from China, I think it also just puts -- it's one of the things that we're talking about is there's going to be an open source standard globally. And I think for our kind of national advantage, it's important that it's an American standard. So we take that seriously, and we want to build the AI system that people around the world are using and I think that if anything, some of the recent news has only strengthened our conviction that this is the right thing for us to be focused on.
Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please go ahead.
Mark Shmulik: Yes, thank you for taking my questions. Mark, I appreciate we may get an answer this year. But looking out, as you kind of track the progress of smart glasses, Orion and so forth, do you view that as a better form factor to get the most out of the Meta AI assistance you highlighted in your opening remarks? Or is it more complementary to kind of the in-app experience in the way you've seen people use it today? And then, Susan, the last few quarters, we've kind of seen pricing growth is the dominant driver of ad revenue growth. Given the efforts you've highlighted around driving deeper, more commercial engagement and better advertiser ROI, how do we just think about the contribution of the formula for ad revenue growth going forward? Thank you.
Mark Zuckerberg: Yes. I mean, I can talk about glasses. I mean it's -- yes, I mean, I've said for a while that I think that glasses are the ideal form factor for an AI device, because you can let an AI assistant on your glasses see what you see and hear what you hear, which gives it the context to be able to understand everything that's going on in your life that you would want to talk to it about and get context on. So -- but look, I mean, I think the glasses are going to be a very important computing platform in the future. When phones became the primary computing platform, it's not like computers went away. I think we'll have phones for some time. But there are a lot of people in the world who have glasses. It's kind of hard for me to imagine that a decade or more from now, all the glasses aren't going to basically be AI glasses, as well as a lot of people who don't wear glasses today, finding that to be a useful thing. So I'm incredibly optimistic about this. And like I shared last year, I think one of the big surprises last year was I previously thought that glasses weren't going to become a major form factor until we got these -- the full kind of holographic displays that we started showing in the prototype for Orion. But now I think it's pretty clear that AI is actually going to drive at least as much of the value as the holographic AR is. So that's a cause to be excited. But look, the Ray-Ban Metas were hit. We still don't know what the long-term trajectory for this is going to be. And I think we're going to learn a lot this year. So I think that this is a really important year for that.
Susan Li: And I can take the second question on pricing growth. So first of all, what I would say is over the long term, we think we have continued opportunity to drive revenue growth across both pricing and impression growth, so both sort of supply and demand dimensions. When we look at pricing, our reported growth can be influenced by different factors such as supply because of the auction dynamics by the mix shift of the different types of surfaces where ads show up. For example, services like video or lower monetization efficiency, relatively speaking. And then, of course, broader macro factors. But we generally expect that we are going to be able to deliver ongoing ad performance improvements through a lot of the ongoing work that we're doing across our monetization road map and that will have the sort of effect of benefiting pricing overall. And part of what I think is kind of important to think about here when we think about price growth is we really -- the average price per ad as we reported, is really blending, it's an output metric. It's blending a lot of things that are happening, including what our advertiser is bidding for, what are their bids for those things? What is the average cost of their actions. So given that there are so many different objectives that advertisers can optimize for that have different values, it's a very complex metric that tries to distill that into one thing. Overall, we are seeing healthy cost per action trends for advertisers for whatever is the action that they are optimizing for. And we believe we'll continue to get better at driving conversions for advertisers. And when we do, that will have the effect of continuing to lift CPMs over time, because we're delivering more conversions per impression served, resulting in higher value impressions.
Operator: Your next question comes from the line of Justin Post with Bank of America. Please go ahead.
Justin Post: Great, thanks. Maybe one for Mark and one for Susan. Mark, you mentioned political changes in the U.S. and better positioning maybe for U.S. companies abroad. But how do you think about it in the U.S. as far as usage and advertiser adoption, you got rid of fact checking. So do you think the content could change? Could it appeal to more users? Will that impact advertising at all? And then Susan, on Meta AI, I know people are pretty excited about the use case, but also thinking about the revenue case. How do you think about monetizing that? Could it be CPC ads? Or how are you thinking about that? Thank you.
Mark Zuckerberg: The question was about fact checking and our content policies. I mean, look, I think we're trying to build the service that we think is the best for people. I believe in free expression for quite a while. People don't want to see misinformation, but you need to build an effective system that gives people more context. And I think what we found over time is that the community note system, I think, is just going to be more effective than the system that we had before. And I'm not afraid to admit when someone does something that's better than us. I think it's sort of our job to go and just do best work and implement the best systems. So I think that there's been a lot of people who have read this announcement is if we somehow don't care about adding context to things that are on our platform that are misinformation, that's not right. I actually think that the community note system, like what X has had for a while is actually just more effective than what we were doing before. And I think our product is going to get better because of it.
Susan Li: I would add to that, just to say, we also haven't seen any noticeable impact from our content policy changes on advertiser spend. So we're continuing to see strong advertiser demand. Again, particularly for AI-powered tools that are helping businesses maximize the value of their ad spend. So our commitment to brand safety is unchanged, and we expect that we will invest in our suite of tools to meet the needs of advertisers. On your second question in terms of monetizing Meta AI, our initial focus for Meta AI is really about building a great consumer experience, and that's frankly, where all of our energies are kind of directed to right now. There will, I think, be pretty clear monetization opportunities over time, including paid recommendations and including a premium offering, but really not where we are focused in terms of the development of Meta AI today.
Operator: Your next question comes from the line of Douglas Anmuth with JPMorgan. Please go ahead.
Douglas Anmuth: Thanks for taking the questions. One for Mark, one for Susan. Mark, just following up on open source as DeepSeek and other models potentially leverage Llama or others to train faster and cheaper. How does this impact in your view? And what could have been for the trajectory of investment required over a multiyear period? And then, Susan, just as we think about the $60 billion to $65 billion CapEx this year, does the composition change much from last year when you talked about servers as the largest part followed by data centers and networking equipment. And how should we think about that mix between like training and inference just following up on Jan's post this week? Thanks.
Mark Zuckerberg: I can start on the DeepSeek question. I think there's a number of novel things that they did that I think we're still digesting. And there are a number of things that they have advances that we will hope to implement in our systems. And that's part of the nature of how this works, whether it's a Chinese competitor or not. I kind of expect that every new company that has an advance -- that has a launch is going to have some new advances that the rest of the field learns from. And that's sort of how the technology industry goes. I don't know -- it's probably too early to really have a strong opinion on what this means for the trajectory around infrastructure and CapEx and things like that. There are a bunch of trends that are happening here all at once. There's already sort of a debate around how much of the compute infrastructure that we're using is going to go towards pretraining versus as you get more of these reasoning time models or reasoning models where you get more of the intelligence by putting more of the compute into inference, whether just will mix shift how we use our compute infrastructure towards that. That was already something that I think a lot of the other labs and ourselves were starting to think more about and already seemed pretty likely even before this, that -- like of all the compute that we're using, that the largest pieces aren't necessarily going to go towards pre-training. But that doesn't mean that you need less compute, because one of the new properties that's emerged is the ability to apply more compute at inference time in order to generate a higher level of intelligence and a higher quality of service, which means that as a company that has a strong business model to support this, I think that's generally an advantage that we're now going to be able to provide a higher quality of service than others, who don't necessarily have the business model to support it on a sustainable basis. The other thing is just that when we're building things like Meta AI, but also how we're implementing AI into all the feeds and ad products and things like that, we're just serving billions of people, which is different from, okay, you start to pretrain a model, and that model is sort of agnostic to how many people are using it, like at some level, it's going to be expensive for us to serve all of these people, because we are serving a lot of people. And so I'm not sure what the kind of net effect of all of this is. The field continues to move quickly. There's a lot to learn from releases from basically everyone who does something interesting, not just the ones over the last month. We'll continue to kind of incorporate that into what we do as well as making novel contributions to the field ourselves And I continue to think that investing very heavily in CapEx and infra is going to be a strategic advantage over time. It's possible that we'll learn otherwise at some point, but I just think it's way too early to call that. And at this point, I would bet that the ability to build out that kind of infrastructure is going to be a major advantage for both the quality of the service and being able to serve the scale that we want to.
Susan Li: I'm happy to add a little more color about our 2025 CapEx plans to your second question. So we certainly expect that 2025 CapEx is going to grow across all three of those components you described. Servers will be the biggest growth driver that remains the largest portion of our overall CapEx budget. We expect both growth in AI capacity as we support our gen AI efforts and continue to invest meaningfully in core AI, but we are also expecting growth in non-AI capacity as we invest in the core business, including to support a higher base of engagement and to refresh our existing servers. On the data center side, we're anticipating higher data center spend in 2025 to be driven by build-outs of our large training clusters and our higher power density data centers that are entering the core construction phase. We're expecting to use that capacity primarily for core AI and non-AI use cases. On the networking side, we expect networking spend to grow in ‘25 as we build higher-capacity networks to accommodate the growth in non-AI and core AI-related traffic along with our large Gen AI training clusters. We're also investing in fiber to handle future cross-region training traffic. And then in terms of the breakdown for core versus Gen AI use cases, we're expecting total infrastructure spend within each of Gen AI, non-AI and core AI to increase in '25 with the majority of our CapEx directed to our core business with some caveat that, that is -- that's not easy to measure perfectly as the data centers we're building can support AI or non-AI workloads and the GPU-based servers, we procure for gen AI can be repurposed for core AI use cases and so on and so forth. But overall, I would reiterate what Mark said. We are committed to building leading foundation models and applications. We expect that we're going to make big investments to support our training and inference objectives, and we don't know exactly where we are in the cycle of that yet.
Operator: Your next question comes from the line of Ron Josey with Citigroup. Please go ahead.
Ron Josey: Hey, thanks for taking the question. Mark, I want to get back to your comment on getting back to the OG Facebook, and I want to understand a little bit more on the use cases and how that could expand? Video is clearly a benefit. Local marketplace groups have all been positive. So any insights on the OG Facebook? And then back to Meta AI, given the adoption we're seeing on the 600-plus MAUs, just how does the user experience evolved to? What are people doing with Meta AI? Thank you.
Mark Zuckerberg: Okay. So for Facebook, a lot of people use Facebook every day, and it's an important part of their lives. And I think that there are a lot of opportunities to make it way more culturally influential than it is today. And I think that, that's sort of a fun and interesting goal that will take our product development in some interesting directions that we maybe have a focus on it as much over the last several years. So I don't know that I have anything much more specific on this other than that this is going to be one of my focus areas for this year. I mean, I think it's an investment area and something I'm going to spend some time on it. It might mean that in the near-term, we make some trade-offs to kind of focus on some product areas of what we're doing ahead of just kind of maximizing business results in the near term on it. But overall, I'm really excited about doing some exciting stuff here. And I'm not going to get into many specifics now, but we'll get -- we'll follow up on this over the next, I don't know, call it, a year as we start rolling it out and I think some of this will kind of get back to how Facebook was originally used back in the day. So I think it will be fun.
Susan Li: I'm happy to share a little bit more about Meta AI and what people are doing with it. We are in a phase where we are really learning a lot from the way that people engage with Meta AI. So from an app perspective, WhatsApp continues to see the strongest Meta AI usage across our family of apps. People there are using it most frequently for information seeking and educational queries along with emotional support use cases. Most of the WhatsApp engagement is in one-on-one threads, though we see some usage in group messaging. And on Facebook, which is the second largest driver of Meta AI engagement, we're seeing strong engagement from our feed deep dives integration that lets people ask Meta AI questions about the content that is recommended to that. So across, I would say, all query types, we continue to see signs that Meta AI is helping people leverage our apps for new use cases. We talked about information gathering, social interaction and communication. Lots of people use it for humor and casual conversation. They use it for writing and editing research recommendations. And as we look forward to 2025 in our Meta AI road map, we are really focused on doing more to make it feel more personalized. So I would say some of the most exciting features we're working on, including improving sort of the memory dimension of the Meta AI experience. We'll be able to remember certain details that people share in one-on-one chats, for example, and use those details to personalize its responses and then really increasing its ability to deliver great content recommendations and enhance really what makes Facebook and Instagram, so valuable for people today.
Operator: Your next question comes from the line of Ken Gawrelski with Wells Fargo. Please go ahead.
Ken Gawrelski: Thank you very much. Two for me, please. First, could you talk a little bit -- I know you talked a little bit on the capital intensity side and the recent developments, and it's hard to see it's hard to tell yet where things are going? But maybe you could just talk a little bit more near term, '25, the CapEx budget you laid out or the CapEx forecast. Could you talk a little bit about the constraints you're seeing or where you're seeing constraints, either internally resources planning or externally and any one -- any parts of the ecosystem? And then on the second one, I'm curious, as you think about your needs for hiring and we just think about -- we know you gave the OpEx guide for this year. But as we think about future needs for hiring, could you just give us a sense of how we should think about that? You announced the performance-related reductions earlier this -- for early this year. Could you just talk about how we should be thinking about that '26, '27 and beyond? Thank you.
Susan Li: Sure. I'm happy to take both of those. So on your first question on just where do we see constraints in our ability to execute against our CapEx plans. Obviously, we are staying on top of supply availability. That is certainly one of the factors that will influence our CapEx spend in 2025, but we don't really have any updates to share on supply availability right now. We are planning to significantly ramp up deployment of GPUs in 2025, and we'll continue to engage with our vendors and invest in our own silicon to meet those needs. When you asked how to think about capital intensity, we're not really -- as both Mark and I alluded to in our prior comments, I think it is really too early to determine what long-run capital intensity is going to look like. There are so many different factors. The pace of advancement in underlying models, how efficient can they be? What is the adoption and use case of our Gen AI products, what performance gains come from next-generation hardware innovations, both our own and third-party and then ultimately, what monetization or other efficiency gains our AI investments unlock. So again, I think we are sort of early in the journey here, and we don't have -- I would say we don't have kind of anything to share about long-run capital intensity yet. Your second question was about thinking about hiring needs. So it's a good segue after infrastructure, employee compensation is the next largest driver of expense growth in 2025. And here, growth in employee comp and headcount more broadly is primarily driven by those areas that I mentioned, infrastructure monetization, generative AI, Reality Labs and regulation and compliance. And those generally are more technical organizations. That means that it is a higher cost base relative to business functions where we are also expecting to keep headcount growth constrained. And I would say we are -- we're focused on running the company efficiently. But at the same time, it is -- we feel like we're in a critical period in terms of making sure that we are investing to win, and we want to make sure that we staff those priority areas in a way that really positions us to best do that.
Kenneth Dorell: Krista, we have time for one last question.
Operator: And that question comes from the line of Ross Sandler with Barclays. Please go ahead.
Ross Sandler: Yes. One for Mark, on agents. So we all saw OpenAI's operator demo last week. So Mark, as the industry moves from chat to agentic behavior and more commercial intent moves into these AI products? I guess how are you thinking about monetization potential for Meta AI? And then how might Llama 4 reasoning help drive some of these new agentic experiences for Meta AI? Thank you.
Mark Zuckerberg: Yes. So I guess a couple of things that I'd say on this. One is when you're thinking about agents and reasoning, a lot of this is about being able to perform multistep tasks. So right now, the way that a lot of these systems work as you kind of say something and then it responds and it's almost chat like. But I think that the direction that it's going is you're going to be able to give it an intent or a task and it's going to be able to go off and use sort of an arbitrary amount of compute as much as you want to use on it to be able to do a task. Some of the tasks might be pretty simple for people go buy a specific thing. Some of them might be really hard, like go write an app or optimize this code and like really make it as good as possible. And that type of thing, I think, is just going to start becoming more and more prevalent over the next a year or two. So I think it's very exciting. It's sort of we'll feel in some ways like the current products are just getting smarter and others, it will feel like sort of a new form factor, because it won't be as much like chat. But it's sort of another generation of these products. So I think it's just in general, there's a lot to build and be excited about. I guess my note of caution or just my kind of periodic reminder on our product development process, if you will, is we build these product. We try to scale them to reach usually 1 billion people or more. And it's at that point once they're at scale that we really start focusing on monetization. So sometimes we'll experiment with monetization before, we're running some experiments with Threads now, for example. But we typically don't really ramp these things up or see them as meaningfully contributing to the business until we reach quite a big scale. So the thing that I think is going to be meaningful this year is the kind of getting of the AI product to scale. Last year was sort of the introduction and starting to get to be used. This year my kind of expectation and hope is that we will be at a sufficient scale and have sufficient kind of flywheel of people using it and improvement from that, that this will have a durable advantage. But that doesn't mean that it's going to be a major contributor to the business. This year the improvements of the business are going to be taking the AI methods and applying them to advertising and recommendations and feeds and things like that. So the actual business opportunity for Meta AI and AI studio and business agents and people interacting with these AIs remains outside of '25 for the most part. And I think that's an important thing for us to communicate and for people to internalize as you're thinking about our prospects here. But nonetheless, we've run a process like this many times. We built a product. We make it good. We scale it to be large. We build out the business around it. That's what we do. I'm very optimistic, but it's going to take some time.
Kenneth Dorell: Great. Thank you, everyone, for joining us today. We appreciate your time, and we look forward to speaking with you again soon.
Operator: This concludes today's conference call. Thank you for your participation, and you may now disconnect.",2025-01-29
META,2025,1,2025-Q1-META,"Operator: Good afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta First Quarter Earnings Conference Call. All lines have been placed on mute to prevent any background noise. After the speakers' remarks, there will be a question-and-answer session. [Operator Instructions] And this call will be recorded. Thank you very much. Kenneth Dorell, Meta's Director of Investor Relations, you may begin.
Kenneth Dorell: Thank you. Good afternoon, and welcome to Meta's first quarter 2025 earnings conference call. Joining me today to discuss our results are Mark Zuckerberg, CEO; and Susan Li, CFO. Our remarks today will include forward-looking statements, which are based on assumptions as of today. Actual results may differ materially as a result of various factors, including those set forth in today's earnings press release and in our Annual Report on Form 10-K filed with the SEC. We undertake no obligation to update any forward-looking statement. During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.atmeta.com. And now I'd like to turn the call over to Mark.
Mark Zuckerberg: All right. Thanks, Ken. Thanks, everyone, for joining today. We've had a strong start to the year. Our community keeps growing with more than 3.4 billion people now using at least one of our apps each day. Our business is also performing very well, and I think we're well-positioned to navigate the macroeconomic uncertainty. The major theme right now, of course, is how AI is transforming everything we do and, as we continue to increase our investments and focus more for our resources on AI, probably useful today to lay out the five major opportunities that we are focused on. Those are improved advertising, more engaging experiences, business engaging experiences, business messaging, Meta AI and AI devices. And these are each long-term investments that are downstream from us building general intelligence and leading AI models and infrastructure. Even with our significant investments, we don't need to succeed in all of these areas to have a good ROI. But if we do, then I think that we will be wildly happy with the investments that we are making. The first opportunity is improved advertising. Our goal is to make it so that any business can basically tell us what objective they're trying to achieve like selling something or getting a new customer and how much they're willing to pay for each result, and then we just do the rest. Businesses used to have to generate their own ad creative and define what audiences they wanted to reach, but AI has already made us better at targeting and finding the audiences that will be interested in their products than many businesses are themselves, and that keeps improving. And now AI is generating better creative options for many businesses as well. I think that this is really redefining what advertising is into an AI agent that delivers measurable business results at scale. And if we deliver on this vision, then over the coming years, I think that the increased productivity from AI will make advertising a meaningfully larger share of global GDP than it is today. In just the last quarter, we are testing a new ads recommendation model for reels, which has already increased conversion rates by 5%, and we're seeing 30% more advertisers are using AI creative tools in the last quarter as well. The second opportunity is more engaging experiences. This will come in two forms, better recommendations for existing content types and better new types of content. In the last six months, improvements to our recommendation systems have led to a 7% increase in time spent on Facebook, a 6% increase on Instagram, and 35% on Threads. Threads now also has more than 350 million monthly actives and continues to be on track to become our next major social app. In addition to better recommendations for existing content types, AI is also enabling the creation of better content as well. Some of this will be helping people produce better content to share themselves. Some of this will be AI generating content directly for people that is personalized for them. Some of this will be in existing formats like photos and videos, and some of it will be increasingly interactive. I've often talked about this long-term trend of content becoming richer over time. Our feeds started mostly with text and then became mostly photos, we all got mobile phones with cameras, and then became mostly video when mobile networks became fast enough to handle that well. We are now in the video era, but I don't think that this is the end of the line. In the near future, I think that we're going to have content in our feeds that you can interact within that, it will interact back with you rather than you just watching it. Over the long-term, as AI unlocks more productivity in the economy, I also expect that people will spend more of their time on engaging experiences across all of these apps. The third opportunity is business messaging. Right now the vast majority of our business is advertising and feeds on Facebook and Instagram. But WhatsApp now has more than 3 billion monthly actives with more than 100 million people in the U.S. and growing quickly there. Messenger is also used by more than a billion people each month, and there are now as many messages sent each day on Instagram as there are on Messenger. So business messaging should be the next pillar of our business. In countries like Thailand and Vietnam, where there is a low cost of labor, we see many businesses conduct commerce through our messaging apps. There's actually so much business through messaging that those countries are both in our Top 10 or 11 by revenue, even though they're ranked in the 30s in global GDP. This phenomenon hasn't yet spread to developed countries, because the cost of labor is too high, to make this a profitable model before AI, but AI should solve this. So in the next few years, I expect that, just like every business today has an email address, social media account and website, they'll also have an AI business agent that can do customer support and sales, and they should be able to set that up very easily given all the context that they've already put into our business platforms. And we're going to have more to share on upcoming calls about our progress in this area. The fourth opportunity is Meta AI. Across our apps, there are now almost a billion monthly actives using Meta AI. Our focus for this year is deepening the experience and making AI the leading personal AI with an emphasis on personalization, voice conversations, and entertainment. I think that we're all going to have an AI that we talk to throughout the day, while we're browsing content on our phones, and eventually, as we're going through our days with glasses. And I think that this is going to be one of the most important and valuable services that has ever been created. In addition to building Meta AI into our apps, we just released our first Meta AI standalone app. It is personalized, so you can talk to it about interests that you've shown while browsing reels or different content across our apps. And we built a social feed into it so you can discover entertaining ways that others are using Meta AI, and initial feedback on the app has been good so far. Over time, I expect that the business opportunity for Meta AI to follow our normal product development playbook. First, we build and scale the product, and then once it is at scale, then we focus on revenue. In this case, I think that there will be a large opportunity to show product recommendations or ads, as well as a premium service for people who want to unlock more compute for additional functionality or intelligence. But I expect that we're going to be largely focused on scaling and deepening engagement for at least the next year, before we'll really be ready to start building out the business here. The fifth opportunity is AI devices, which is increasingly how we are thinking about our work on the next-generation of computing platforms. Glasses are the ideal form factor for both AI and the Metaverse. They enable you to let an AI see what you see, hear what you hear, and talk to you throughout the day, and they let you blend the physical and digital worlds together with holograms. More than a billion people worldwide wear glasses today. And it seems highly likely that these will become AI glasses over the next five to 10-years. Building the devices that people use to experience our services, lets us deliver the highest quality AI and social experiences, and this will serve as an amplifier on all of the opportunities I've mentioned so far, as well as unlocking some new opportunities as well. Ray-Ban Meta AI Glasses have tripled in sales in the last year, and the people who have them are using them a lot. We've got some exciting new launches with our partner, EssilorLuxottica, later this year, as well that should expand that category and add some new technological capabilities to the glasses. On Quest, we are also seeing deeper engagement as Quest 3S makes VR accessible to more people, and more people are creating experiences in horizon with AI tools. Now, everything that I've talked about today is built on top of our AI models and our infrastructure. We released the first Llama 4 models earlier this month. They are some of the most intelligent, best multimodal, lowest latency, and most efficient models that anyone has built. We have more models on the way, including the massive Llama 4 behemoth model. Overall, we are focused on building full general intelligence. All of the opportunities that I've discussed today are downstream of delivering general intelligence and doing so efficiently. The pace of progress across the industry and the opportunities ahead for us are staggering. I want to make sure that we're working aggressively and efficiently, and I also want to make sure that we are building out the leading infrastructure and teams that we need to achieve our goals. So to that end, we are accelerating some of our efforts to bring capacity online more quickly this year, as well as some longer-term projects that will give us the flexibility to add capacity in the coming years as well. And that has increased our planned investment for this year. More broadly, this has been a good start to what I expect will continue to be an intense year. We've got a lot more exciting work in the pipeline that I'm looking forward to sharing soon. I continue to think that this year is going to be a pivotal moment for our industry, and I'm grateful for everyone who is working so hard at the Company to deliver all this amazing technology and new experiences. As always, thank you all for being on this journey with us, `and now, Susan.
Susan Li: Thanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis unless otherwise noted. Q1 total revenue was $42.3 billion, up 16% or 19% on a constant currency basis. Q1 total expenses were $24.8 billion, up 9% compared to last year. In terms of the specific line items, cost of revenue increased 14%, driven primarily by higher infrastructure costs and payments to partners, partially offset by a benefit from the previously announced extension of server useful lives. R&D increased 22%, mostly due to higher employee compensation and infrastructure costs. Marketing and sales increased 8%, driven mainly by an increase in professional services related to our ongoing platform integrity efforts. G&A decreased 34%, driven primarily by lower legal-related costs. We ended Q1 with over 76,800 employees, up 4% quarter-over-quarter. First quarter operating income was $17.6 billion, representing a 41% operating margin. Our tax rate for the quarter was 9%, as we recognized excess tax benefits from share-based compensation due to the increase in our share price versus prior periods. Net expenditures, including principal payments on finance leases, were $13.7 billion, driven by investments in servers, data centers, and network infrastructure. Free cash flow was $10.3 billion. We repurchased $13.4 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders, ending the quarter with $70.2 billion in cash and marketable securities, and $28.8 billion in debt. Moving now to our segment results. I'll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, and we estimate more than 3.4 billion people used at least one of our Family of Apps on a daily basis in March. Q1 total Family of Apps revenue was $41.9 billion, up 16% year-over-year. Q1 Family of Apps' ad revenue was $41.4 billion, up 16% or 20% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year-over-year growth. On a user geography basis, ad revenue growth was strongest in Rest of World and North America at 19% and 18%, respectively. Europe and Asia-Pacific grew 14% and 12%. In Q1, the total number of ad impressions served across our services increased 5%, and the average price per ad increased 10%. Impression growth was mainly driven by Asia-Pacific. Pricing growth benefited from increased advertiser demand, in part driven by improved ad performance. This was partially offset by impression growth, particularly from lower monetizing regions and surfaces. Family of Apps' other revenue was $510 million, up 34%, driven mostly by business messaging revenue growth from our WhatsApp Business platform, as well as Meta Verified subscriptions. We continue to direct the majority of our investments toward the development and operation of our Family of Apps. In Q1, Family of Apps' expenses were $20.1 billion, representing 81% of our overall expenses. Family of Apps' expenses were up 10%, mainly due to growth in employee compensation and infrastructure costs, which were partially offset by lower legal-related expenses. Family of Apps' operating income was $21.8 billion, representing a 52% operating margin. Within our Reality Labs segment, Q1 revenue was $412 million, down 6% year-over-year due to lower Meta Quest sales, which were partially offset by increased sales of RayBan Meta AI glasses. Reality Labs' expenses were $4.6 billion, up 8% year-over-year, driven primarily by higher employee compensation. Reality Labs' operating loss was $4.2 billion. Turning now to the business outlook. There are two primary factors that drive our revenue performance our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we're focused both on enhancing our core Family of Apps today and building the next generation of devices and experiences through Reality Labs. I'll start with our Family of Apps. In the first quarter, we saw strong growth in video consumption across both Facebook and Instagram, particularly in the U.S., where video time spent grew double-digits year-over-year. This growth continues to be driven primarily by ongoing enhancements to our recommendation systems, and we see opportunities to deliver further gains this year. We're also progressing on longer-term efforts to develop innovative new approaches to recommendations. A big focus of this work will be on developing increasingly efficient recommendation systems, so that we can continue scaling up the complexity and compute used to train our models, while avoiding diminishing returns. There are promising techniques we're working on that will incorporate the innovations from LLM model architectures to achieve this. Another area that is showing early promise is integrating LLM technology into our content recommendation systems. For example, we're finding that LLM's ability to understand a piece of content more deeply than traditional recommendation systems can help better identify, what is interesting to someone about a piece of content leading to better recommendations. We began testing using Llama and Threads recommendation systems at the end of last year, given the app's text-based content, and have already seen a 4% lift in time spent from the first launch. It remains early here, but a big focus this year will be on exploring how we can deploy this for other content types, including photos and videos. We also expect this to be complementary to Meta AI, as it can provide more relevant responses to people's queries by better understanding their interests and preferences through their interactions across Facebook, Instagram, and Threads. Earlier this year, we began testing the ability for Meta AI to better personalize its responses by remembering certain details from people's prior queries and considering what that person engages with on our apps. We are already seeing this lead to deeper engagement with people we've rolled it out to, and it is now built into Meta AI across Facebook, Instagram, Messenger, and our new standalone Meta AI app in the U.S. and Canada. We're also continuing to focus on helping people connect over content. In Q1, we launched a new experience on Instagram in the U.S., that consists of a feed of content your friends have left a note on or liked, and we're seeing good results. We also just launched Blend, which is an opt-in experience in direct messages that enables you to blend your reels algorithm with your friends to spark conversations over each other's interests. These features all lean into Instagram's position at the intersection of entertainment and social connection. WhatsApp remains at its core a private messaging app, but it has evolved to also become a place people come to get updates from accounts they are connected to or follow. Today, there are tens of billions of views of status posts on WhatsApp each day, and we continue to invest in the Updates tab, as a place people can go to do more. Creators remain another big focus for us, and we're investing in tools to help them produce the best original content on our platforms. Last week, we launched our standalone Edits app, which supports the full creative process for video creators from inspiration and creation to performance insights. Edits has an ultra-high resolution short-form video camera and includes generative AI tools that enable people to remove the background of any video or animate still images, with more features coming soon. Moving to Reality Labs, we're seeing very strong traction with RayBan Meta AI glasses with over 4 times as many monthly actives as a year ago, and the number of people using voice commands is growing even faster as people use it to answer questions and control their glasses. This month, we fully rolled out live translations on RayBan Meta AI glasses to all markets for English, French, Italian, and Spanish. Now, when you are speaking to someone in one of these languages, you'll hear what they say in your preferred language through the glasses in real time. Now to the second driver of our revenue performance, increasing monetization efficiency. The first part of this work is optimizing the level of ads within organic engagement. We continue to optimize ad supply across each service to better deliver ads at the time and place they are most relevant to people. We are also starting to introduce ads on unmonetized surfaces like Threads, which we opened up to all eligible advertisers this month to reach people in over 30 different markets to start, including the U.S. As we do for any newly monetized surface, we expect to gradually ramp ad supply as we optimize the ad formats and ensure they feel native to the app. We don't expect Threads to be a meaningful driver of overall impression or revenue growth in 2025. The second part of increasing monetization efficiency is improving marketing performance. We're continuing to improve our ad systems by developing new modeling technologies to more efficiently predict the right ad to show. In Q1, we introduced our new Generative Ads Recommendation Model, or GEM for ads ranking. This model uses a new architecture we developed that is twice as efficient at improving ad performance for a given amount of data and compute. This efficiency gain enabled us to significantly scale up the amount of compute we use for model training with GEM trained on thousands of GPUs, our largest cluster for ads training to date. We began testing the new model for ads recommendations on Facebook Reels earlier this year and have seen up to a 5% increase in ad conversions. We're now rolling it out to additional services across our apps. On the ads product side, we're seeing continued momentum with our Advantage+ suite of AI-powered solutions. We've been encouraged by the initial tests of our streamlined campaign creation flow for sales, app, and lead campaigns, which starts with Advantage+ turned on from the beginning for advertisers. In April, we rolled this out to more advertisers and expect to complete the global rollout later this year. We're also seeing strong adoption of Advantage+ creative. This week, we are broadening access of video expansion to Facebook Reels for all eligible advertisers, enabling them to automatically adjust the aspect ratio of their existing videos by generating new pixels in each frame to optimize their ads for full-screen surfaces. We also rolled out Image Generation to all eligible advertisers, and this quarter, we plan to continue testing a new virtual try-on feature that uses Gen AI to place clothing on virtual models, helping customers visualize how an item may look and fit. Last, we continue to evolve our ads platform to drive results that are optimized for each business's objectives and the way they measure value. One example of this is our incremental attribution feature, which enables advertisers to optimize for driving incremental conversions or conversions we believe would not have occurred without an ad being shown. We're seeing strong results in testing so far with advertisers using incremental attribution in tests, seeing an average 46% lift in incremental conversions compared to their business-as-usual approach. We expect to make this available to all advertisers in the coming weeks. Next, I would like to discuss our approach to capital allocation. Our primary focus remains investing capital back into the business, with infrastructure and talent being our top priorities. Starting with headcount, our hiring continues to be targeted at technical roles within our company priorities. In the first quarter, the significant majority of the roughly 2,800 employees we added were to support our priorities of monetization, infrastructure, generative AI, regulation and compliance, and Reality Labs. On infrastructure, we have two primary focuses to meet the growing compute needs of our services and AI initiatives. The first way is by significantly scaling up our infrastructure footprint. Our CapEx growth this year is going toward both generative AI and core business needs, with the majority of overall CapEx supporting the core. We expect the significant infrastructure footprint we are building will not only help us meet the demands of our business in the near term, but also provide us an advantage in the quality and scale of AI services we can deliver. We continue to build this capacity in a way that grants us maximum flexibility in how and when we deploy it to ensure we have the agility to react to how the technology and industry develop in the coming years. The second way we're meeting our compute needs is by increasing the efficiency of our workloads. In fact, many of the innovations coming out of our ranking work are focused on increasing the efficiency of our systems. This emphasis on efficiency is helping us deliver consistently strong returns from our core AI initiatives. For example, we shared on the Q3 2024 call that improvements to our AI-driven feed and video recommendations drove a roughly 8% lift in time spent on Facebook and a 6% lift on Instagram over the first nine months of last year. Since then, we've been able to deliver similar gains in just six months’ time with improvements to our AI recommendations delivering 7% and 6% time spent gains on Facebook and Instagram, respectively. Before moving to our financial guidance, I want to acknowledge the dynamic macro environment and note that our range reflects the potential for a wider set of outcomes. We continue to feel good about the fundamental drivers of revenue growth and believe the past work we've done to streamline our operations and cost profile puts us in a strong position to navigate a variety of outcomes. Moving to our financial outlook. We expect second quarter of 2025 total revenue to be in the range of $42.5 billion to $45.5 billion. Our guidance assumes foreign currency is an approximately 1% tailwind to year-over-year total revenue growth based on current exchange rates. Turning now to the expense outlook. We expect full year 2025 total expenses to be in the range of $113 billion to $118 billion, lowered from our prior outlook of $114 billion to $119 billion. Turning now to the CapEx outlook. We anticipate our full year 2025 capital expenditures, including principal payments on finance leases, will be in the range of $64 billion to $72 billion, increased from our prior outlook of $60 billion to $65 billion. This updated outlook reflects additional data center investments to support our AI efforts as well as an increase in the expected cost of infrastructure hardware. The majority of our CapEx in 2025 will continue to be directed to our core business. On to tax. Absent any changes to our tax landscape, we expect our full-year 2025 tax rate to be in the range of 12% to 15%. In addition, we continue to monitor an active regulatory landscape, including legal and regulatory headwinds in the EU and the US, that could significantly impact our business and our financial results. The European Commission recently announced its decision that our subscription for no ads model is not compliant with the DMA. Based on feedback from the European Commission in connection with the DMA, we expect we will need to make some modifications to our model, which could result in a materially worse user experience for European users and a significant impact to our European business and revenue as early as the third quarter of 2025. We will appeal the Commission's DMA decision, but any modifications to our model may be imposed before or during the appeal process. In closing, this was another solid quarter for our business. We believe the investments we're making across our company priorities will position us well in the coming years to continue delivering engaging services for our community, compelling results for advertisers, and strong business performance. With that, Krista, let's open up the call for questions.
Operator: Thank you. We will now open the lines for a question-and-answer session. [Operator Instructions] And your first question comes from the line of Brian Nowak with Morgan Stanley. Please go ahead.
Brian Nowak: Great. Thanks for taking my questions. I have two. The first one is on Llama. Mark, can you -- the LLM landscape continues to sort of evolve and be somewhat competitive. Can you sort of talk us through some of the key areas of advancement you are most focused on and excited about as we sort of think about behemoth and next versions of Llama to come? And then the second one on Meta AI, almost a billion users globally. Any help on sort of how you're seeing US traction there and the types of recurring user behaviors that you're seeing in the early Meta AI use cases? Thanks.
Mark Zuckerberg: Sure. I can talk about the LLMs. On the Meta AI usage, I'm not sure if we have more stats to share on that now. Yes, it's -- I mean, I'll defer to Susan on if there's anything that we're ready on that. On the LLM, yes, there's a lot of progress being made in a lot of different dimensions. And the reason why we want to build this out is, one is that we think it's important that for kind of how critical this is for our business that we sort of have control of our own destiny and are not depending on another company for something so critical. But two, we want to make sure that we can shape the development to be optimized for our infrastructure and the use cases that we want. So to that end, Llama 4, the shape of the model with 17 billion parameters per expert, was designed specifically for the infrastructure that we have in order to provide low latency experience to be voice optimized. One of the key things if you're having a voice conversation with AI is it needs to be low latency. So that way, when you're having a conversation with it, there is no large gap between when you stop speaking and it starts. So everything from the shape of the model to the research that we're doing to the techniques that go into it are kind of fit into that. Similarly, another thing that we focused on was context window length. And in some of our models, we have really -- we're industry-leading on context window length, and part of the reason why we think that that's important is because we're very focused on providing a personalized experience. And there are different ways that you can put personalized -- personalization context into an LLM, but one of the ways to do it is to include some of that context in the context window and having a long context window that can incorporate a lot of the background that the person has shared across our apps is one way to do that. So that's like -- it kind of is giving you a flavor of the products that we're trying to build and then some specific technical architecture decisions and research prioritization that we basically have made in order to deliver the specific experience that we're going for. I could go on and add a lot more. The reason -- I think it's also very important to deliver big models like Behemoth, not because we're going to end up serving them in production, but because of the technique of distilling from larger models, right? The Llama 4 models that we've published so far and the ones that we're using internally and some of the ones that we'll build in the future are basically distilled from the Behemoth model in order to get the 90%, 95% of the intelligence of the large model in a form factor that is much lower latency and much more efficient. So these things are all very important. Obviously, we wouldn't be able to do that kind of distillation from other closed models. So that kind of gives you a flavor for how we're thinking about the development of this. And then, of course, the models and the infrastructure that we're building out power all of the opportunities that I mentioned before.
Susan Li: Brian, I'm happy to answer your second question about Meta AI. The top use case right now for Meta AI from a query perspective is really around information gathering as people are using it to search for and understand and analyze information, followed by social interactions from -- ranging from casual chatting to more in-depth discussion or debate. We also see people use it for writing assistance, interacting with visual content, seeking help. And we see Meta -- people engage with Meta AI from several different entry points. WhatsApp continues to see the strongest Meta AI usage across our family of apps. Most of that WhatsApp engagement is in one-on-one Threads, followed by Facebook, which is the second largest driver of Meta AI engagement, where we're seeing strong engagement from our Feed deep-dives integration that lets people ask Meta AI questions about the content that's recommended to them. And we're obviously excited about the launch of the Meta AI standalone app.
Operator: Your next question comes from the line of Eric Sheridan with Goldman Sachs. Please go ahead.
Eric Sheridan: Thanks so much for taking the question. Maybe following up on Brian's question and coming at it from a different angle, and appreciate the color on the use cases you're seeing today for Meta AI. How would you suspect those use cases evolve with a standalone app? Can you bring us into a little bit the decision process to do a standalone app, what that might change in terms of utility, frequency, or scale relative to what you see inside Family of Apps today? And how do you think about positioning Meta AI as a standalone app against the competitive landscape today of other standalone sorts of consumer AI apps? Thank you.
Mark Zuckerberg: Yes, I can talk about that. We're going to focus on both integrating it into our Family of Apps in more ways and building a standalone experience. I think some people want faster access to it or a more built-out feature set than you can build into an app like WhatsApp, so the standalone app will be valuable for that. I also think that the standalone app is going to be particularly important in the United States because WhatsApp, as Susan said, is the largest surface that people use Meta AI in, which makes sense if you want to text an AI, having that be closely integrated and a good experience in the messaging app that you use makes a lot of sense. But we're -- while we have more than 100 million people use WhatsApp in the United States, it -- we're clearly not the primary messaging app in the United States at this point, iMessage. We hope to become the leader over time, but we're in a different position there than we are in most of the rest of the world on WhatsApp. So I think that the Meta AI app as a standalone is going to be particularly important in the United States to establishing leadership in -- as the main personal AI that people use. But we're going to keep on advancing the experiences across the board in all of these different areas.
Operator: Your next question comes from the line of Justin Post with Bank of America. Please go ahead.
Justin Post: Great. Thank you. A couple of questions. Just on the guide in the second quarter, there are reports of potential supply issues in e-commerce. How you thought about that in the guide, and maybe how you're thinking about it for the back half? And then on a bigger picture question, your CapEx spend is now on close to some hyperscalers with very big client bases? Just help us conceptualize the kind of ecosystem you're building with your CapEx. I know you gave a lot of help on the intro, but maybe the ROI works without direct enterprise spend to drive revenues. How you're thinking about that? Thank you.
Susan Li: Thanks, Justin. On the Q2 guide, there is uncertainty, obviously, and how the macro environment will evolve over time and how that could impact different segments of our business. Our Q2 revenue outlook aims to factor that in and partly -- that's partly why the $3 billion range reflects the potential for a wider range of outcomes. Specifically, we have seen some reduced spend in the US from Asia-based e-commerce exporters, which we believe is in anticipation of the de minimis exemption going away on May 2nd. A portion of that spend has been redirected to other markets, but overall spend for those advertisers is below the levels prior to April. But our Q2 outlook reflects the trends we're seeing so far in April, which have generally been healthy. So it's very early and hard to know how things will play out over the quarter, and certainly harder to know that for the rest of the year. Your second question is about why we're investing more in CapEx. And we really believe that our ability to build world-class infrastructure gives us a meaningful advantage in both developing the leading AI technology and services over the coming years, and there are a lot of opportunities also for us to improve our core business by putting more compute against our ads and recommendation work. So even with the capacity that we're bringing online in 2025, we are having a hard time meeting the demand that teams have for compute resources across the company. So we are going to continually invest meaningfully here across our infrastructure footprint, but we are also really looking to build this capacity in a way that gives us the maximum flexibility in how and when we deploy it over the coming years. So we can respond to how the market and technology develop.
Operator: Your next question comes from the line of Doug Anmuth with JPMorgan. Please go ahead.
Doug Anmuth: Thanks for taking the questions. I just wanted to follow up on CapEx and infrastructure spending. Just on the higher range for CapEx, can you just help us understand how much of that is tied to the additional data center investments versus the increased hardware costs, and really what's driving those higher hardware costs? And then separately, there have been some articles suggesting that you've been looking to partner to share some of the costs of the AI infrastructure build-out. Can you just help us understand your thought process there and some of the pros and cons of going alone versus partnering? Thanks.
Susan Li: Thanks, Doug. So our increased CapEx outlook reflects both of those updates, the increased data center spend this year as we have made some adjustments to flex our build strategy that will enable us to really stand up capacity more quickly, both in '25 and '26. We haven't broken down sort of the exact drivers. The higher cost we expect to incur for infrastructure hardware this year really comes from suppliers who source from countries around the world, and there's just a lot of uncertainty around this given the ongoing trade discussions. And so that is both reflected in the wider range that we are giving, and we're also working on our end on mitigations by optimizing our supply chain and our outlook is really trying to reflect our best understanding of the potential impact this year across all of that uncertainty. On the second part of your question, we are -- we are pleased to have partners investing alongside us and bringing Llama to market like AWS and Azure, who are helping us host Llama. We're always looking for opportunities to continue deepening or expanding those partnerships, but we are funding the infrastructure that is being used to train Llama, and we don't have any expectation that will change at this point.
Operator: Your next question comes from the line of Mark Shmulik with Bernstein. Please go ahead.
Mark Shmulik: Yes, thanks for taking the questions. Mark, in your conversation last night with Satya, I think you both discussed a bit around kind of the portion of code being written internally by AI. Kind of back to some of your previous comments around this being a year where we might see AI kind of the place of a mid-level engineer. With the world evolving so quickly, can you share some places where you've seen strong traction there? And are we progressing kind of faster, slower as you expected towards this milestone? And then, Susan, with the expense guidance coming down just a touch, how should we think about just the overall cadence of expected spending, really as it relates to kind of core business performance and just the realities of the day-to-day world we're living in? Thank you.
Mark Zuckerberg: I can talk about the coding agent work. I don't think that there's been any real change in our prediction for the timing of this. So I'd say, it's basically still on track for something around a mid-level engineer, kind of starting to become possible sometime this year, scaling into next year. So I'd expect that by the middle to end of next year, AI coding agents are going to be doing a substantial part of AI research and development. So, we're focused on that. Internally, we're also very focused on building AI agents or systems that can help, run different experiments to increase recommendations across our other AI products, like the ones that do recommendations across our feeds and things like that. So I think that if it works should just accelerate our progress in those areas. That's the basic bet that we're making.
Susan Li: On your second question about our lowered expense outlook, really, we are four months into the year the lowered outlook reflects more refined forecasts, including updated expectations for both employee compensation as well as some other non-headcount-related operating expenses this year. And that's partially offset by higher expected infrastructure costs related to our increased CapEx outlook as well as higher expected Reality Labs cost of goods sold. And we've maintained our $5 billion range just given the more dynamic operating environment that we're in. And what I would say is our investment posture today reflects the significant opportunities that we see across each of the Company and priorities that we're investing in this year. We will obviously continue evaluating depending on how macro conditions more broadly evolve. But we really feel like these are big strategic priorities for us and are critical for us to continue investing in. And in fact, I think one of the aims of our efficiency work over the last two years was to put us in a stronger financial position, so that we can continue investing in key priorities through tougher financial cycles.
Operator: Your next question comes from the line of Ross Sandler with Barclays. Please go ahead.
Ross Sandler: Great. Mark, yesterday in one of your many kind of podcast or keynote presentations, you had mentioned that like a bunch of projects that your teams want to or aspire to do are kind of bottlenecked by the AI capacity, which Susan just talked about earlier, and that even some of the testing that the ad ranking team wants to run is just getting kind of delayed. So I guess looking out either this year, next year, or whatever, when do you kind of see some of this constraint being eased back? And more broadly, we're kind of three years past the IDFA impact to your business. So, where do you -- where do you think we are in terms of just the overall improvements to the ad ranking system, the ROI that you guys are able to deliver, and like what inning are we in on that in your opinion? Thank you very much.
Susan Li: I can take a shot at both of those, and Mark, you can obviously chime in. On the first question, the cap -- the capacity landscape we are in is pretty dynamic, both in terms of the many moving parts in terms of us bringing capacity online, but also in terms of the demand from different product groups in our company, whether they are in the Gen AI teams or whether they're doing more of the core AI work around ranking and recommendation. So both the supply and demand are quite fluid and so we don't have a sort of fixed answer in terms of when we expect that we will sort of have enough supply to meet all demand, but that's something that we are working very hard to alleviate and it's part of why we accelerated bringing more data center space online this year and also we're very focused on increasing the efficiency of our workloads over the course of the year. On your second question about ads performance ads ranking. We have invested for many years and continue to invest in driving ad performance improvements. Year-over-year conversion growth remains strong, and in fact, we continue to see conversions grow at a faster rate than ad impressions in Q1. So, reflecting increased conversion rates. And ads ranking and modeling improvements are a big driver of overall performance gains. We have a lot of innovations in model architecture in both the ads retrieval and ranking stages of the ads delivery process to serve more relevant ads to people. We talked about the introduction of the new GEM ads recommendation model in Q1, and we have talked about some of the prior model architecture improvements like Lattice and Andromeda in past quarters. For us, we really believe first and foremost that advertising is a relative performance game, and that's especially important for us, because the vast majority of our business is direct response advertising. So we feel good about how the prior investments are paying off, and we continue to invest in a lot of different work to constantly improve our ads ranking and recommendations performance.
Operator: Your next question comes from the line of Kenneth Gawrelski with Wells Fargo. Please go ahead.
Kenneth Gawrelski: Thank you so much. Two for me, please. First, maybe, Mark. How should we think about the timing of AI capabilities necessary to drive WhatsApp for business adoption in higher cost -- higher labor cost labor markets? What is Meta doing to accelerate that adoption? And do you see this as mostly incremental to SME ad spend that you're already capturing? And then first, Susan, one, please. What does the revised CapEx outlook for this year for '25 mean about future years? Does it mean anything, or you talked about this being an acceleration in your revised outlook statement. Should we think about this as a new starting point for -- to think about '26 and beyond? Or should we just start fresh in '26 and think about the needs and capacity at that point? Thank you.
Susan Li: I'm happy to take -- I'll go ahead and take both of those, and Mark, you should feel free to chime in wherever you would like. So Mark talked a little bit about our general vision that every business will soon have an AI that is an expert on their business for their customers to talk to in the same way that today they've got email and websites, social media presences, et cetera. We are currently testing business AIs with a limited set of businesses in the U.S. and a few additional countries on WhatsApp, Messenger, and on -- ads on Facebook and Instagram. We've been starting with small businesses and focusing first on helping them sell their goods and services with business AIs. But ultimately, we are working on tools to support businesses at every stage of the customer funnel, from lead generation to order management and customer service, and a core area that we're addressing right now is really the ability for businesses to customize and control the agent to achieve the outcome that they want. So we've launched a new agent management experience and dashboard that makes it easier for businesses to train their AI based on existing information on their website or WhatsApp profile, or their Instagram and Facebook pages, and we're starting with the ability for businesses to activate AI in their chats with customers. We are also testing business AIs on Facebook and Instagram ads that you can ask about product and return policies, or assist you in making a purchase within our in-app browser. So again, the ultimate vision is to build an experience that serves customers across all of these different services and apps. No matter where you engage with the business AI, it should be one agent that recalls your history and your preferences and we're hearing encouraging feedback is particularly that adopting these AIs are saving the businesses that we're testing with a lot of time and helping to determine which conversations make sense for them to spend more time on. And then your second question right was about 2026 CapEx. You know, infrastructure, as I alluded to earlier, just is a very dynamic planning area given the continued advances in AI, and also for us, the fact that we continue to find a lot of good use cases to put capacity toward in our core AI ranking and recommendations work. So I would say it's too early to discuss plans beyond 2025.
Operator: Your next question comes from the line of Youssef Squali with Truist Securities. Please go ahead.
Youssef Squali: Great. Thank you guys for taking the question. So Mark, in a world where we now have maybe five to 10 chatbots, including Meta AI, on our smartphones doing virtually the same thing. Do you think this is a market much like Search, where the winner takes most, or is it likely to be much more fragmented? But in either case, what would you say are the top two or three competitive advantages of Meta AI? And then, Susan, on the EU decision connection with the DMA, what kind of modifications will you need to make to the apps? And can you maybe just help us gauge the potential financial fallout, understanding that it may still obviously be too early? Thank you.
Mark Zuckerberg: Yes. On Meta AI, I mean, I think that there are going to be a number of different agents that people use, just like people use different apps for different things. I'm not sure that people are going to use multiple agents for the same exact things, but I'd imagine that something that is more focused on kind of enterprise productivity might be different from something that is somewhat more optimized for personal productivity and that might be somewhat different from something that is optimized for entertainment and social connectivity. So I know there will be -- there will be different experiences. One of the trends that I think we're starting to see now is personalization across the -- across these. Right now, if the experience is unpersonalized, then you can kind of just go to different apps and get reasonably similar answers to different questions, but once an AI starts getting to know you and what you care about in context and can build up memory from the conversations that you've had with it over time, I think that will start to become somewhat more of a differentiator. That's one thing that we think will matter. And then, of course, there's all the different modalities, being able to not just answer questions about in text, but being able to do voice and multimodal and be able to produce images and videos and understand all those things and have good conversations about that I think is going to be important overall. So yes, I mean I think Meta AI is well-positioned, but we have a lot of work to do in order to make it the leading personal AI.
Susan Li: And Youssef, on your second question, it is really too early to speak about what those changes could be because we are in the process of engaging with the European Commission. I think maybe the most useful sort of metric I could give you is just that our advertising revenue in the European economic area in Switzerland, which would be the geographies impacted here, was 16% of our worldwide total revenue in 2024. Again, we are continuing to engage actively with the European Commission further on this. So we hope to have more clarity by next quarter's call.
Kenneth Dorell: Krista, we have time for one last question.
Operator: Your last question comes from the line of Mark Mahaney with Evercore ISI. Please go ahead.
Mark Mahaney: Thanks. I'll just throw in two. I think you called out the China-based retailers as one sort of potentially soft advertising vertical. Anything else you'd call out? And I would just suggest autos, is that an area of any softness? And then on the Reality Labs and on the losses associated with Reality Labs, they've been very consistent, whatever, $4 billion a quarter for quite some time. Is there -- is there light at the end of the tunnel? Is there a reason to think? Is there a factor that would occur that would cause those losses to come down? And when would that be, but maybe more importantly, what is going to cause those losses to come down? Thank you very much.
Susan Li: Mark, let me take your first question about other verticals. We generally saw healthy growth in most verticals in Q1. We did see some weakness in gaming and politics. So, year-over-year growth in gaming was negative in Q1, as we lapped a period of strong spend from China-based advertisers that were promoting a larger volume of game titles in Q1 of 2024. And then year-over-year growth in the government and politics vertical dropped sharply as expected with the conclusion of U.S. elections and but that continues to just be a very small vertical overall. And then your second question on Reality Labs. Yes.
Mark Zuckerberg: I mean, we're basically focused on doing the work more efficiently, but as the AI glasses have really taken off, I've talked about this on a number of calls, there are more investments that I think make sense to make around making sure that we can distribute this and grow it very quickly. I mean, some of the -- if you look at the -- some of the leading consumer electronics products of other categories, by the time they get to their third generation, they're often selling 10 million units and scaling from there and I'm not sure if we're going to do exactly that, but I think that that's like the ballpark of the opportunity that we have and that's something that I think we're kind of focused on scaling to that and then scaling beyond that for the generations after that. So, I think some of the effort that we're doing is going to -- we're going to get more efficient in some parts of the work that we do, but then as a bunch of the products start to hit and start to grow even bigger than the number that I just said is just sort of like the sort of a near-term milestone, then I think we'll continue scaling in terms of distribution and then at some point, just like the other products that we build-out, we will feel like we're at a sufficient scale that we're going to primarily focus on making sure that, we're monetizing and building an efficient business around it. But that's kind of where we're at on it. We're definitely focused on doing the work more efficiently, but also very optimistic about what we're seeing in the results, especially on the AI glasses side.
Kenneth Dorell: Great. Thank you, everyone, for joining us today. Excuse me, and we look forward to speaking to you again soon.",2025-04-30
