ticker,year,quarter,transcriptID,transcript,date
AMD,2024,1,2024-Q1-AMD,"Operator: Greetings, and welcome to the AMD First Quarter 2024 Conference Call. [Operator Instructions] As a reminder, this conference is being recorded. 
 It is now my pleasure to introduce your host, Mitch Haws, Vice President, Investor Relations. Thank you. Mitch, you may begin. 
Mitchell Haws: Thank you, and welcome to AMD's First Quarter 2024 Financial Results Conference Call. By now, you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations page of amd.com. We will refer primarily to non-GAAP financial measures during today's call, and the full non-GAAP to GAAP reconciliations are available in today's press release and the slides posted on our website. 
 Participants on today's call are Dr. Lisa Su, our Chair and Chief Executive Officer; and Jean Hu, our Executive Vice President, Chief Financial Officer and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Mark Papermaster, Executive Vice President and Chief Technology Officer, will attend the TD Cowen Technology, Media and Telecom Conference on May 29; and Jean Hu, Executive Vice President, Chief Financial Officer and Treasurer, will attend the JPMorgan Global Media and Communications Conference on Tuesday, May 21; the Bank of America Global Technology Conference on Wednesday, June 5; and the Jefferies Nasdaq Investor Conference on Tuesday, June 11. 
 Today's discussion contains forward-looking statements based on current beliefs, assumptions and expectations, speak only as of today and as such, involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on the factors that could cause actual results to differ materially. 
 With that, I will hand the call over to Lisa. 
Lisa Su: Thanks, Mitch, and good afternoon to all those listening today. This is an incredibly exciting time for the industry as the widespread deployment of AI is driving demand for significantly more compute across a broad range of markets. Under this backdrop, we are executing very well as we ramp our data center business and enable AI capabilities across our product portfolio. 
 Looking at the first quarter, revenue increased to $5.5 billion. We expanded gross margin by more than 2 percentage points and increased profitability as Data Center and Client segment sales each grew by more than 80% year-over-year. 
 Data Center segment revenue grew 80% year-over-year and 2% sequentially to a record $2.3 billion. The substantial year-over-year growth was driven by the strong ramp of AMD Instinct MI300X GPU shipments and a double-digit percentage increase in server CPU sales. We believe we gained server CPU revenue share in the seasonally down first quarter, led by growth in enterprise adoption and expanded cloud deployments. 
 In cloud, while the overall demand environment remain mixed, hyperscalers continued adopting fourth-gen EPYC processors to power more of their internal workloads and public instances. There are now nearly 900 AMD-powered public instances available globally as Amazon, Microsoft and Google all increased their fourth-gen EPYC processor offerings with new instances and regional deployments. 
 In the enterprise, we have seen signs of improving demand as CIOs need to add more general purpose and AI compute capacity while maintaining the physical footprint and power needs of their current infrastructure. This scenario aligns perfectly with the value proposition of our EPYC processors. 
 Given our high core count and energy efficiency, we can deliver the same amount of compute with 45% fewer servers compared to the competition, cutting initial CapEx by up to half and lowering annual OpEx by more than 40%. As a result, enterprise adoption of EPYC CPUs is accelerating, highlighted by deployments with large enterprises, including American Airlines, DBS, Emirates Bank, Shell and STMicro. 
 We're also building momentum with AMD-powered solutions powering the most popular ERP and database applications. As one example of the latest generation of Oracle Exadata, the leading database solution used by 76 of the Fortune 100, is now powered exclusively by fourth-gen EPYC processors. Looking ahead, we're very excited about our next-gen Turin family of EPYC processors featuring our Zen 5 core. We're widely sampling Turin and the silicon is looking great. 
 In the cloud, the significant performance and efficiency increases of Turin position us well to capture an even larger share of both first and third-party workloads. In addition, there are 30% more Turin platforms in development from our server partners compared to fourth-gen EPYC platforms, increasing our enterprise SAM with new solutions optimized for additional workloads. Turin remains on track to launch later this year. 
 Turning to our broader Data Center portfolio. We delivered our second straight quarter of record data center GPU revenue as MI300 became the fastest-ramping product in AMD history, passing $1 billion in total sales in less than 2 quarters. In cloud, MI300x production deployments expanded at Microsoft, Meta and Oracle to power Generative AI training and inferencing for both internal workloads and a broad set of public offerings. 
 For the enterprise, we're working very closely with Dell, HPE, Lenovo, Super Micro and others as multiple MI300X platforms enter volume production this quarter. In addition, we have more than 100 enterprise and AI customers actively developing or OpenAI MI300X. 
 On the AI software front, we made excellent progress adding upstream support for AMD hardware in the open AI Triton compiler, making it even easier to develop highly performant AI software for AMD platforms. 
 We also released a major update to our ROCm software stack that expand support for open source libraries, including vLLM, and frameworks, including JAKs, adds new features like video decode and significantly increases generative AI performance by integrating advanced attention algorithm support for sparsity and FPA. 
 Our partners are seeing very strong performance in their AI workloads. As we jointly optimize for their models, MI300X GPUs are delivering leadership inferencing performance and substantial TCO advantages compared to H100. For instance, several of our partners are seeing significant increases in tokens per second when running their flagship LLMs on MI300x compared to H100. 
 We're also continuing to enable the broad ecosystem required to power the next generation of AI systems, including as a founding member of the Ultra Ethernet Consortium, working to optimize the widely adopted Ethernet protocol to run AI workloads at data center scale. 
 MI300 demand continues to strengthen. And based on our expanding customer engagements, we now expect data center GPU revenue to exceed $4 billion in 2024, up from the $3.5 billion we guided in January. Longer term, we are increasingly working closer with our cloud and enterprise customers as we expand and accelerate our AI hardware and software road maps and grow our data center GPU footprint. 
 Turning to our Client segment. Revenue was $1.4 billion, an increase of 85% year-over-year, driven by strong demand for our latest-generation Ryzen mobile and desktop processors with OEMs and in the channel. Client segment revenue declined 6% sequentially. 
 We saw strong demand for our latest-generation Ryzen processors in the first quarter. Ryzen desktop CPU sales grew by a strong double-digit percentage year-over-year, and Ryzen mobile CPU sales nearly doubled year-over-year as new Ryzen 8040 notebook designs from Acer, Asus, HP, Lenovo and others ramped. 
 We expanded our portfolio of leadership enterprise PC offerings with the launch of our Ryzen Pro 8000 processors earlier this month. Ryzen Pro 8040 mobile CPUs delivered industry-leading performance in battery life for commercial notebooks. And our Ryzen Pro 8000 series desktop CPUs are the first processor to offer dedicated, on-chip AI accelerators in commercial desktop PCs. 
 We see clear opportunities to gain additional commercial PC share based on the performance and efficiency advantages of our Ryzen Pro portfolio and an expanded set of AMD-powered commercial PCs from our OEM partners. Looking forward, we believe the market is on track to return to annual growth in 2024, driven by the start of an enterprise refresh cycle and AI PC adoption. 
 We see AI as the biggest inflection point in PC since the Internet, with the ability to deliver unprecedented productivity and usability gains. We're working very closely with Microsoft and a broad ecosystem of partners to enable the next generation of AI experiences, powered by Ryzen processors, with more than 150 ISVs on track to be developing for AMD AI PCs by the end of the year. 
 We will also take the next major step in our AI PC road map later this year with the launch of our next-generation Ryzen mobile processors codenamed Strix. Customer interest in Strix is very high based on the significant performance and energy efficiency uplifts we are delivering. 
 Design win momentum for premium notebooks is outpacing prior generations as Strix enables next-generation AI experiences in laptops that are thinner, lighter and faster than ever before. We're excited about the growth opportunities for the PC market. And based on the strength of our Ryzen CPU portfolio, we expect to grow revenue share this year. 
 Now turning to our Gaming segment. Revenue declined 48% year-over-year and 33% sequentially to $922 million. First quarter semi-custom SoC sales declined in line with our projections as we are now in the fifth year of the console cycle. In Gaming Graphics, revenue declined year-over-year and sequentially. We expanded our Radeon 7000 Series family with the global launch of our Radeon RX 7900 GRE and also introduced our driver-based AMD fluid motion frames technology that can provide large performance increases in thousands of games. 
 Turning to our Embedded segment. Revenue decreased 46% year-over-year and 20% sequentially to $846 million as customers remain focused on normalizing their inventory levels. We launched our Spartan UltraScale+ FPGA family with high I/O counts, power efficiency and state-of-the-art security features, and we're seeing a strong pipeline of growth for our cost-optimized embedded portfolio across multiple markets. 
 Given the current embedded market conditions, we're now expecting second quarter embedded segment revenue to be flat sequentially, with a gradual recovery in the second half of the year. Longer term, we see AI at the edge as a large growth opportunity that will drive increased demand for compute across a wide range of devices. To address this demand, we announced our second generation of Versal adaptive SoCs that deliver a 3x increase in AI tops per watt and a 10x greater scaler compute performance compared to our prior generation of industry-leading adaptive SoCs. 
 Versal Gen 2 adaptive SoCs are the only solution that combine multiple compute engines to handle AI preprocessing, inferencing and post processing on a single chip, enabling customers to rapidly add highly performant and efficient AI capabilities to a broad range of products. We were pleased to be joined at our launch by Subaru, who announced they adopted Versal AI Edge series Gen 2 devices to power the next generation of their EyeSight ADAS system. 
 Embedded Design win momentum remains very strong as customers adopt our full portfolio of FPGAs, CPUs, GPUs and adaptive SoCs to address a larger portion of their compute needs. In summary, we executed well in the first quarter, setting us up to deliver strong annual revenue growth and expanded gross margin, driven by growing adoption of our Instinct, EPYC and Ryzen product portfolios. 
 Our priorities for 2024 are very clear: accelerate our Data Center growth by ramping Instinct GPU production and gaining share with our EPYC processors; launch our next-generation Zen 5 PC and server processors that extend our leadership performance; and expand our adaptive computing portfolio with differentiated solutions. 
 Looking further ahead, AI represents an unprecedented opportunity for AMD. While there has been significant growth in AI infrastructure build-outs, we are still in the very early stages of what we believe is going to be a period of sustained growth, driven by an insatiable demand for both high-performance AI and general purpose compute. 
 We have expanded our investments across the company to capture this large growth opportunity, from rapidly expanding our AI software stack to accelerating our AI hardware road maps, increasing our go-to-market activities and partnering closely with the largest AI companies to co-optimize solutions for their most important workloads. We are very excited about the trajectory of the business and the significant growth opportunities ahead. 
 Now I'd like to turn the call over to Jean to provide some additional color on our first quarter results. Jean? 
Jean Hu: Thank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the second quarter of fiscal 2024. We delivered strong year-over-year revenue growth in our Data Center and Client segments in the fourth quarter and grew 230 basis points of gross margin expansion. For the first quarter of 2024, revenue was $5.5 billion, up 2% year-over-year as revenue growth in the Data Center and the Client segment was partially offset by lower revenue in our Gaming and Embedded segment. 
 Revenue declined 11% sequentially as higher Data Center revenue resulting from the ramp of our AMD Instinct GPUs was offset by lower Gaming and Embedded segment revenues. Gross margin was 52%, up 230 basis points year-over-year, driven by higher revenue contribution from the Data Center and Client segment, partially offset by lower Embedded and Gaming segment revenue contribution. 
 Operating expenses were $1.7 billion, an increase of 10% year-over-year, as we continued investing aggressively in R&D and marketing activities to address the significant AI growth opportunities ahead of us. Operating income was $1.1 billion, representing a 21% operating margin. Taxes, interest expense and other was $120 million. For the fourth quarter of 2024, diluted earnings per share was $0.62, an increase of 3% year-over-year. 
 Now turning to our Reportable segment, starting with the Data Center. Data Center delivered record quarterly segment revenue of $2.3 billion, up 80%, a $1 billion increase year-over-year. Data Center accounted for more than 40% of total revenue, primarily led by the ramp of AMD Instinct GPUs from both cloud and enterprise customers and a strong double-digit percentage growth in our server process revenue as a result of growth across our sample products. 
 On a sequential basis, revenue increased 2%, driven by the ramp of our AMD Instinct GPUs, partially offset by seasonal decline in server CPU sales. Data Center segment operating income was $541 million or 23% of revenue compared to $148 million or 11% a year ago. Operating income was up 266% year-over-year due to operating leverage even as we significantly increased our investment in R&D. 
 Client segment revenue was $1.4 billion, up 85% year-over-year, driven primarily by Ryzen 8000 series processors. On a sequential basis, Client revenue declined 6%. Client segment operating income was $86 million or 6% of revenue compared to an operating loss of $172 million a year ago, driven by higher revenue. 
 Gaming segment revenue was $922 million, down 48% year-over-year and down 33% sequentially due to a decrease in semi customer and Radeon GPU sales. Gaming segment operating income was $151 million or 16% of revenue compared to $314 million or 18% a year ago. 
 Embedded segment revenue was $846 million, down 46% year-over-year and 20% sequentially as customers continue to manage their inventory levels. Embedded segment operating income was $342 million or 41% of revenue compared to $798 million or 51% a year ago. 
 Turning to the balance sheet and cash flow. During the quarter, we generated $521 million in cash from operations, and free cash flow was $379 million. Inventory increased sequentially by $301 million to $4.7 billion, primarily to support the continued ramp of data center and client products in advanced process node. 
 At the end of the quarter, cash, cash equivalent and short-term investment was $6 billion. As a reminder, we have $750 million of debt maturing this June. Given our ample liquidity, we plan to retire that utilizing existing cash. 
 Now turning to our second quarter 2024 outlook. We expect revenue to be approximately $5.7 billion, plus or minus $300 million. Sequentially, we expect Data Center segment revenue to increase by double-digit percentage, primarily driven by the Data Center GPU ramp; client segment revenue to increase; embedded segment revenue to be flat; and in the Gaming segment, based on current demand signals, revenue to decline by significant double-digit percentage. 
 Year-over-year, we expect our Data Center and Client segment revenue to be up significantly, driven by the strength of our product portfolio; the Embedded and the Gaming segment revenue to decline by a significant double-digit percentage. In addition, we expect second quarter non-GAAP gross margin to be approximately 53%. Non-GAAP operating expenses to be approximately $1.8 billion. Non-GAAP effective tax rate to be 13% and the diluted share count is expected to be approximately 1.64 billion shares. 
 In closing, we started the year strong. We made significant progress on our strategic priorities, delivering year-over-year revenue growth in our Data Center and the Client segment and expanded the gross margin. Looking ahead, we believe the investments we are making will position us very well to address the large AI opportunities ahead. 
 With that, I'll turn it back to Mitch for the Q&A session. 
Mitchell Haws: Thank you, Jean. Paul, we're happy to poll the audience for questions. 
Operator: [Operator Instructions] Our first question is from Toshiya Hari with Goldman Sachs. 
Toshiya Hari: Lisa, my first question is on the MI300. You're taking up the full year outlook from $3.5 billion to $4 billion. I'm curious what's driving that incremental $500 million in revenue? Is it new customers? Is it additional bookings from existing customers? Is it more cloud? Is it more enterprise? If you can sort of provide color there, that would be helpful. 
 And then on the supply side, there's been headlines or chatter that CoWoS and/or HBM could be a pretty severe constraining factor for you guys. If you can speak to how you're handling the supply side of the equation, that would be helpful, too. And then I have a quick follow-up. 
Lisa Su: Great. Thank you, Toshiya, for the question. Look, the MI300 ramp is going really well. If we look at just what's happened over the last 90 days, we've been working very closely with our customers to qualify MI300 in their production data centers, both from a hardware standpoint, software standpoint. So far, things are going quite well. 
 And what we see now is just greater visibility to both current customers as well as new customers committing to MI300. So that gives us the confidence to go from $3.5 billion to $4 billion. And I view this as very much -- it's a very dynamic market, and there are lots of customers. We said on the -- in the prepared remarks that we have over 100 customers that we're engaged with in both development as well as deployment. So overall, the ramp is going really well. 
 As it relates to the supply chain, actually, I would say, I'm very pleased with how supply has ramped. It is absolutely the fastest product ramp that we have done. It's a very complex product, chiplets, CoWoS, 3D integration, HBM. And so far, it's gone extremely well. We've gotten great support from our partners. And so I would say, even in the quarter that we just finished, we actually did a little bit better than expected when we first started the quarter. 
 I think Q2 will be another significant ramp. And we're going to ramp supply every quarter this year. So I think the supply chain is going well. We are tight on supply. So there's no question in the near term that if we had more supply, we have demand for that product, and we're going to continue to work on those elements as we go through the year. But I think both on the demand side and the supply side, I'm very pleased with how the ramp is going. 
Toshiya Hari: And then as my follow-up, I was hoping you could speak to your Data Center GPU road map beyond the MI300. The other concern that we hear is your nearest competitor has been pretty transparent with their road map, and that extends into '25 and oftentimes '26. So -- and maybe this isn't the right venue for you to give too much, but beyond the MI300, how should we think about your road map and your ability to compete in Data Center? 
Lisa Su: Yes, sure. So look, Toshiya, when we start with the road map, I mean, we always think about it as a multiyear, multigenerational road map. So we have the follow-ons to MI300 as well as the next, next generations well in development. I think what is true is we're getting much closer to our top AI customers. They're actually giving us significant feedback on the road map and what we need to meet their needs. 
 Our chiplet architecture is actually very flexible. And so that allows us to actually make changes to the road map as necessary. So we're very confident in our ability to continue to be very competitive. Frankly, I think we're going to get more competitive. Right now, I think MI300x is in a sweet spot for inference, very, very strong inference performance. 
 I see as we bring in additional products later this year into 2025, that, that will continue to be a strong spot for us. And then we're also enhancing our training performance and our software road map to go along with it. So more details to come in the coming months, but we have a strong road map that goes through the next couple of years, and it is informed by just a lot of learning in working with our top customers. 
Operator: Our next question is from Ross Seymore with Deutsche Bank. 
Ross Seymore: The non-AI side of the Data Center business, it sounds like the enterprise side has some good traction even though the sequential drop happened seasonally, Lisa. But I was just wondering what's implied in your second quarter guidance for the Data Center CPU side of things? And generally speaking, how are you seeing that whole kind of GPU versus CPU crowding out dynamic playing out for the rest of 2024? 
Lisa Su: Yes, sure, Ross, thanks for the question. I think the -- our EPYC business has actually performed pretty well. The market is a bit mixed. I think some of the cloud guys are still working through sort of their optimizations. I think it's different by customer. We did see here in the first quarter, actually, some very nice early signs in the enterprise space, sort of large customers starting refresh programs. The value proposition of Genoa is very, very strong, and we're seeing that pull through across the enterprise. 
 In the second quarter, we expect overall Data Center to be up strong double digits. And then within that, we expect server to be up as well. And as we go into the second half of the year, I think there are a couple of drivers for us. 
 We do expect some improvement in the overall market conditions for the server business. But we also have our Turin launch in the second half of the year that will also, we believe, extend our leadership position within the server market. So overall, I think the business is performing well, and we believe that we're continuing to be very well positioned to gain share throughout the year. 
Ross Seymore: And I guess as my follow-up, just switching over to the Client side. I noted you guided it up sequentially. Any sort of magnitude around that for the second quarter? And perhaps, more importantly, when you talk about the whole AI PC side of things, do you believe that's more of a units driver for you, an SAP driver, or will it be both? 
Lisa Su: Yes. So I think, again, I think we're pretty excited about the AI PC, both opportunity in, let's call it, the near term and even more so in the medium term. I think the client business is performing well, both on the channel and on the MNC side. We expect clients to be up sequentially in the second quarter. 
 And as we go into the second half of the year, to your question about units versus ASPs, I think we expect some increase in units as well as ASPs. The AI PC products, when we look at the Strix products, they're really well-suited for the premium segments of the market. And I think that's where you're going to see some of the AI PC content strongest in the beginning. And then as we go into 2025, you would see it more across the rest of the portfolio. 
Operator: Our next question is from Matt Ramsay with TD Cowen. 
Matthew Ramsay: Lisa, I have sort of a longer-term question and then a shorter-term follow-up one. I guess the -- one of the questions that I've been getting from folks a lot is, obviously, your primary competitor has announced, I guess, a multiyear road map. And we continue to hear more and more from other folks about internal ASIC programs at some of your primary customers, whether they be for inference or training or both. 
 I guess it'd be really helpful if you could just talk to us about how your conversations go with those customers, how committed they are to your long-term road map, multigeneration, as you described it, how they juxtapose doing investments of their internal silicon versus using a merchant supplier like yourselves and maybe what advantages the experience across a large footprint of customers can give your company that those guys doing internal ASICs might not get? 
Lisa Su: Yes. Sure, Matt. Thanks for the question. So look, I think one of the things that we see and we've said is that the TAM for AI compute is growing extremely quickly. And we see that continuing to be the case in all conversations. We had highlighted a TAM of let's call it, $400 billion in 2027. I think some people thought that was aggressive at the time. But the overall AI compute needs, as we talk to customers is very, very strong. And you've seen that in some of the announcements even recently with some of the largest cloud guys. 
 From my view, there are several aspects of it. First of all, we have great relationships with all of sort of the top AI companies. And the idea there is we want to innovate together. When you look at these large language models and everything that you need for training and inferencing there, although -- there will be many solutions. I don't think there's just one solution that will fit all. The GPU is still the preferred architecture, especially as the algorithms and the models are continuing to evolve over time. And that favors our architecture and also our ability to really optimize CPU with GPU. 
 So from my standpoint, I think we're very happy with the partnerships that we have. I think this is a huge opportunity for all of us to really innovate together. And we see that there's a very strong commitment to working together over multiple years going forward. And that's, I think, a testament to some of the work that we've done in the past, and that very much is what happened with the EPYC road map as well. 
Matthew Ramsay: Lisa, as my follow-up, a little bit shorter term. And I guess, having followed the company super closely for a long time, I think there's been -- there's always been noise in the system from whether the stock price is $2 a share or $200. There's been kind of always consistent noise one way or the other, but the last 1.5 months has been extreme in that sense. 
 And so I wanted to just -- I got random reports by inbox about changes in demand from some of your MI300 customers or planned demand for consuming your product. I think you answered earlier about the supply situation and how you're working with your partners there. But has there been any change from the customers that you're in ramp with now or that you soon will be of what their intention is for demand? Or in fact, has that maybe strengthened rather than gone down in recent periods because I keep getting questions about it? 
Lisa Su: Sure, Matt. Look, I think I might have said it earlier, but maybe I'll repeat it again. I think the demand side is actually really strong. And what we see with our customers and what we are tracking very closely is customers moving from, let's call it, initial POCs to pilots to full-scale production to deployment across multiple workloads. And we're moving through that sequence very well. I feel very good about the deployments and ramps that we have ongoing right now. 
 And I also feel very good about new customers who are sort of earlier on in that process. So from a demand standpoint, we continue to build backlog as well as build engagements going forward. And similarly, on the supply standpoint, we're continuing to build supply momentum. But from a speed of ramp standpoint, I'm actually really pleased with the progress. 
Operator: Our next question is from Aaron Rakers with Wells Fargo. 
Aaron Rakers: I apologize if I missed this earlier, but I know last quarter, you talked about having a -- securing enough capacity to support significant upside to the ramp of the MI300. I know that you upped your guide now to $4 billion. I'm curious how you would characterize the supply relative to that context offered last quarter as we think about that new kind of target for? Would you characterize it as still having supply capacity upside potential? 
Lisa Su: Yes, Aaron. So we've said before that our goal is to ensure that we have supply that exceeds the current guidance, and that is true. So as we've upped our guidance from $3.5 billion to $4 billion, we still -- we have supply visibility significantly beyond that. 
Aaron Rakers: Yes. Okay. And then as a quick follow-up, going back to an earlier question on server demand, more traditional server. As you see the ramp of maybe share opportunities in more traditional enterprise, I'm curious how you would characterize the growth that you expect to see a more traditional server CPU market as we move through '24 or even longer term, how you'd characterize that growth trend? 
Lisa Su: Yes. I think, Aaron, what I would say is there are -- the need for refresh of, let's call it, older equipment is certainly there. So we see a refresh cycle coming. We also see AI head nodes as another place where we see growth in, let's call it, the more traditional SSD market. Our sweet spot is really in the highest performance, sort of high core count, energy efficiency space, and that is playing out well. 
 And we're also -- we've traditionally been very strong in, let's call it, cloud first-party workloads, and that is now extending to cloud third-party workloads, where we see enterprises who are, let's call it, in more of a hybrid environment, adopting AMD both in the cloud and on-prem. So I think, overall, we see it as a continued good progression for us with the server business going through 2024 and beyond. 
Operator: Our next question is from Vivek Arya with Bank of America Securities. 
Vivek Arya: Lisa, I just wanted to go back to the supply question and the $4 billion outlook for this year. I think at some point, there was a suggestion that the $4 billion number, right, that there are still supply constraints. But I think at a different point, you said that you have supply visibility significantly beyond that. 
 Given that we are almost at the middle of the year, I would have thought that you would have much better visibility about the back half. So is the $4 billion number a supply-constrained number, or is it a demand-constrained number? Or alternatively, if you could give us some sense of what the exit rate of your GPU sales could be. I think on the last call, $1.5 billion was suggested. Could it be a lot more than that in terms of your exit rate of MI for this year? 
Lisa Su: Yes. Vivek, let me try to make sure that we answered this question clearly. From a full year standpoint, our $4 billion number is not supply capped -- I'm sorry, yes, it's not supply capped. It is -- we do have supply capability above that. It is more back half weighted. So if you're looking at sort of the near term, I would say, for example, in the second quarter, we do have more demand than we have supply right now, and we're continuing to work on pulling in some of that supply. 
 By the way, I think this is an overall industry issue. This is not at all related to AMD. I think overall, AI demand has exceeded anyone's expectations in 2024. So you've heard it from the memory guys. You've heard it from the foundry guys. We're all ramping capacity as we go through the year. 
 And as it relates to visibility, we do have good visibility into what's happening. As I said, we have great customer engagements that are going forward. My goal is to make sure that we pass all of the milestones as we're ramping products. And as we pass those milestones, we put that into the overall full year guidance for AI. 
 But in terms of how customer progression, things are going, they're actually going quite well. And we continue to bring new customers on, and we continue to expand workloads with our current customers. And so hopefully, that clarifies the question, Vivek. 
Vivek Arya: Maybe one, not on MI, but maybe on the Embedded business. I think you sound a bit more measured about Q2 and the second half rebound, which is similar to what we have heard from a lot of the auto industrial peers. But where are you in the inventory clearing cycle? And if Embedded has a somewhat more measured rebound in the back half, what implication does that have on gross margin expansion? Can we continue to expect, I don't know, 100 basis points a quarter in terms of gross margin expansion because of the Data Center mix? Or just any puts and takes of Embedded and then what it means for gross margins in the back half? 
Jean Hu: Vivek, thank you for the question. I think the Embedded business declined a little bit more than expected, really due to the weaker demand in some of the markets, very specifically, communication has been weak. And some pockets of industrial and automotive, as you mentioned, it's actually quite consistent with the peers. 
 Second half, we do think the first half is the bottom of Embedded business and will start to see gradual recovery in the second half. And going back to your gross margin question is, when you look at our gross margin expansion in both Q1 and the guide at Q2, the primary driver is the strong performance on the Data Center side. The Data Center will continue to ramp in second half. I think that will continue to be the major driver of gross margin expansion in second half. Of course, if Embedded is doing better, we'll have a more tailwind in the second half. 
Operator: Our next question is from Timothy Arcuri with UBS. 
Timothy Arcuri: I also wanted to ask about your data center GPU road map. The customers that we talk to say that they're engaged, not just because of MI300, but really because of what's coming. And it seems like there's a big demand shift to rack scale systems that try to optimize performance per square foot given some of the data center and power constraints. So can you just talk about how important systems are going to be in your road map? And do you have all the pieces you need as the market shifts to rack scale systems? 
Lisa Su: Yes, sure, Timothy. Thanks for the question. For sure, look, our customers are engaged in the multigenerational conversation. So we're definitely going out over the next couple of years. And as it relates to the overall system integration, it is quite important. It is something that we're working very closely with our customers and partners on. That's a significant investment in networking, working with a number of networking partners as well to make sure that the scale-out capability is there. 
 And to your question of do we have the pieces? We do absolutely have the pieces, I think the work that we've always done with our Infinity Fabric as well as with our Pensando acquisition that's brought in a lot of networking expertise. And then we're working across the networking ecosystem with key partners like Broadcom and Cisco and Arista, who are with us at our AI data center event in December. 
 So our work right now in future generations is not just specifying a GPU, it is specifying, let's call it, full system reference designs. And that's something that will be quite important going forward. 
Timothy Arcuri: And then just as a quick follow-up. I know this year it looks like it's going to be pretty back-half loaded in your server CPU business, just like it was last year. I know you kind of held our hands at about this time last year sort of on what the full year could look like and how back-end loaded it could be. 
 So I kind of wonder, could you give us some milestones in terms of how much server CPU could grow this year, how back-end loaded it could be? Is it like up 30% this year for your server CPU business year-over-year? Is that a reasonable bogey? I just wonder if you can kind of give us any guidance on that piece of the business? 
Lisa Su: Yes. I mean, I think, Tim, I think the best way to say it is our Data Center segment is on a very, very strong ramp as we go through the back half of the year. Server CPUs, certainly, Data Center GPUs, for sure. So I don't know that we're going to get into specifics, but I could say, in general, you should expect overall at the segment level to be very strong double digits. 
Operator: Our next question is from Joe Moore with Morgan Stanley. 
Joseph Moore: I wonder if you could address the profitability of MI300. I know you said a couple of quarters ago that it would eventually be above corporate average, but it would take you a few quarters to get there. Can you talk about where you are in that? 
Jean Hu: Yes. Thank you, Joe. Our team has done an incredible job to ramp MI300. As you probably know, it's a very complex product, and we are still at the first year of the ramp, both from yield, the testing time and the process improvement, those things are still ongoing. We do think over time, the gross margin should be accretive to corporate average. 
Joseph Moore: Great. And then as a separate follow-up. On the Turin transition on server, I know when you had transitioned in generally, you said it could take a little while, that there were significant platform shifts and things like that. Turin seems to be much more kind of ecosystem compatible. How quickly do you think you might see that product ramp within our server portfolio? 
Lisa Su: Yes. Joe, I think from what we see, look, think Turin is the same platform so that does make it an easier ramp. I do think that Genoa and Turin will coexist for some amount of time because customers are deciding when they're going to bring out their new platforms. We expect Turin to give us access to a broader set of workloads. So our SAM actually expands with Turin, both in enterprise and cloud. And from our experience, I think you'll see a faster transition than, for example, when we went from Milan to Genoa. 
Operator: Our next question is from Stacy Rasgon with Bernstein Research. 
Stacy Rasgon: For my first one, I wanted to address the MI300 ramp into Q2. So you said you've done $1 billion, give or take, in cumulative sales, which puts it at maybe, I don't know, maybe $600 million in Q1. You're guiding total revenues up about $225 million into Q2, but you've got Client up, you've got traditional Data Center up, you've got Embedded flat. Gaming is going to be down, but I'd hazard a guess that the client and traditional Data Center offset it, if not more. Does the MI300 ramp into Q2? Is it more or less than the total corporate ramp that you've got built into guidance right now that you're expecting? 
Jean Hu: Stacy, thanks for the question. You always ask a math question. So I think, in general, it is more. The Data Center GPU ramp, it will be more than the overall company's $200-some million ramp. 
Stacy Rasgon: Okay. So that means Gaming must be down like a lot, right, if client [indiscernible] 
Jean Hu: Yes, yes, you're right. Gaming is down similar zip code like  Q1. 
Stacy Rasgon: Got it. Got it. That's helpful. 
Jean Hu: So maybe -- yes, maybe let me give you some color about the Gaming business, right? If you look at the Gaming, the demand has been quite weak, that's quite very well-known and also their inventory level. So based on the visibility we have, the first half, both Q1, Q2, we guided down sequentially more than 30%. We actually think the second half will be lower than first half. 
 That's basically how we're looking at this year for the Gaming business. And at the same time, Gaming's gross margin is lower than our company average. So overall, will help the mix on the gross margin side. That's just some color on the Gaming side. But you're right, Q2 Gaming is down a lot. 
Stacy Rasgon: Got it. That's helpful. For my second question, I wanted to look at the near-term Data Center profitability. So operating profit was down 19% sequentially on 2% revenue growth. Is that just the margins of the GPUs filtering in relative to the CPUs? And I know you said GPUs would eventually be above corporate average. Are they below the CPU average? I mean they clearly are, I guess, in the near term, but are they going to stay that way? 
Jean Hu: Yes. I think you're right. It's -- the GPU gross margin right now is below the Data Center gross margin level, I think there are 2 reasons. Actually, the major reason is we actually increased the investment quite significantly to, as Lisa mentioned, to expand and accelerating our road map in the AI side. That's one of the major drivers for the operating income coming down slightly. 
 On the gross margin side, going back to your question, we said in the past, and we continue to believe the case is, Data Center GPU gross margin over time will be accretive to corporate average. But it will take a while to get to the Server level for gross margin. 
Operator: Our next question is from Harlan Sur with JPMorgan. 
Harlan Sur: On your Data Center GPU segment and the faster time to production shipments, given you just upped your full year GPU outlook, how much of it is faster bring up of your customers' frameworks driven by your latest ROCm software platform and maybe stronger collaboration with your customers' engineers just to get them to call faster? And how much of it is just a more aggressive build-out plan by customers versus their prior expectations given what appears to be a pretty strong urgency for them to move forward with their important AI initiatives? 
Lisa Su: Yes. Harlan, thank you for the question. What it really is, is both us and our customers feeling confident in broadening the ramp? Because if you think about it, first of all, the ROCm stock has done really well. And the work that we're doing is hand in hand with our customers to optimize their key models. And it was important to get sort of verification and validation that everything would run well, and we've now passed some important milestones in that area. .
 And then I think the other thing is, as you said, there is a huge demand for more AI compute. And so our ability to participate in that and help customers get that up and running is great. So I think, overall, as we look at it, this ramp has been very, very aggressive as you think about where we were just a quarter ago. Each of these are pretty complex bring ups. And I'm very happy with how they've gone. And by the way, we're only sitting here in April. So there's still a lot of 2024 to go, and there's a great customer momentum in the process. 
Harlan Sur: Yes, absolutely. Just going back, just kind of rewinding back to the March quarter. So similar to the PC Client business, right, which declined at the low end of the seasonal range, if I make certain assumptions around your Data Center GPU business, x that out of Data Center, it looks like your Server CPU business was also down at the lower end of the seasonal range. By my math, it was down like 5%, 6% sequentially. Is that right? 
 And that's less than half the decline of your competitor. And if so, like what drove the less-than-seasonal declines? I assume some of it was share gains. It sounds like Enterprise was also better. Looks like you guys did drive a little bit more cloud instance adoption, but anything else that drove to a slightly better seasonal pattern in March for Data Center? Server? 
Jean Hu: Yes. Harlan, this is Jean. I think the Server business has been performing really well. Year-over-year, it actually increased a very strong double digit. I think, sequentially, it is more seasonal, but we feel pretty good about continue gaining share there. 
Lisa Su: Yes. And if I'd just add, Harlan, to your question, we did see strength in enterprise in the first quarter. And I think that has -- that offset perhaps some of the normal seasonality. 
Operator: Our next question is from Tom O'Malley with Barclays. 
Thomas O'Malley: I just wanted to ask on the competitive environment. Obviously, on the CPU side, you had a competitor talk about launching a high core count product in the coming quarter, kind of ramping now and more so into Q3. You've seen really good pricing tailwinds as a function of the higher core capital. Can you talk about what you're seeing in that market? Do you think that there's any risk for more aggressive pricing, which would impact your ASP ramp for the rest of the year? 
Lisa Su: Yes. When we look at our server CPU sort of ASPs, they're actually very stable. I think we -- again, we tend to be indexed towards the higher core counts. Overall, I would say, the pricing environment is stable. This is about sort of TCO for sort of the customer environment and sort of our performance and our performance per watt, our leadership. And that usually translates into TCO advantage for our customers. 
Thomas O'Malley: Helpful. And then just a broader question to follow up here. So I think you got asked earlier about the importance of systems. But on your end, how important is the Open Ethernet Consortium to you being able to move forward to systems? I know that, today, you obviously have some internal assets and then you can partner with others. But is there a way that you could be competitive before there is an industry standard on the Ethernet side? And can you talk about when you think the timing of that kind of consortium comes to market and enables you to maybe accelerate that road map? 
Lisa Su: Yes. I think it's very important to say we are very supportive of the open ecosystem. We're very supportive of the Ultra Ethernet Consortium. But I don't believe that, that is a limiter to our ability to build large-scale systems. I think Ethernet is something that many in the industry feel will be the long-term answer for networking in these systems, and we have a lot of work that we're doing with internally as well as with our customers and partners to enable that. 
Operator: Our last question is from Harsh Kumar with Piper Sandler. 
Harsh Kumar: Lisa, I had two. One is for you and one perhaps for Jean. So we recently hosted a very large custom GPU company for a call. And they talked about kind of mega data centers coming up in the near to midterm, talking about nodes potentially in the 100,000-plus range and maybe up to 1 million. So as we look out at these kinds of data centers, from an architectural standpoint, it's not a situation where winner takes all, where if somebody gets in, they kind of get all the sockets? 
 Or will there reliance where your chip perhaps or your board can be placed right next to somebody else's board maybe on a separate line? Just help us understand how something like that would play out if there's a  chance for more than 1 competitor to play in such a large data center? 
Lisa Su: Yes. So I'll talk maybe a little bit more at the strategic level. I think as we look at sort of how AI shapes up over the next few years, there are customers who would be looking at very large training environments and perhaps that's what you're talking about. I think our view of that is, number one, we view that as a very attractive area for AMD. It's an area where we believe we have the technology to be very competitive there. 
 And I think the desire would be to have optionality in terms of how you build those out. So obviously, a lot has to happen between here and there. But I think your overarching question of. Is it winner takes all? I don't think so. That being the case, we believe that AMD is very well positioned to play in those, let's call it, of very large scale systems. 
Harsh Kumar: That's wonderful. And then maybe a quick one for Jean. So Jean, I put everything into the model that you talked about for June, I get about more or less a $400 million rise in the June quarter over March. You mentioned that both MI300 and EPYC will grow. Curious if you could help us think about the relative sizing of those 2 segments within the growth? I'm getting -- the point I'm trying to make is I'm getting roughly about a $900 million number for MI300 for June. Is that -- am I in the ballpark? Or am I way off here? 
Jean Hu: Harsh, we're not going to guide a specific segment below the segment revenue. I think the most important thing is that we did say Data Center is going to grow double digit sequentially. I will leave it over there. Subsegment, there are a lot of details. 
Operator: There are no further questions at this time. I'd like to hand the floor back over to management for any closing comments. 
Mitchell Haws: Great. That concludes today's call. Thanks to all of you for joining us today. 
Lisa Su: Thanks. 
Operator: This concludes today's conference. You may disconnect your lines at this time. Thank you for your participation.",2024-04-30
AMD,2024,2,2024-Q2-AMD,"Operator: Greetings, and welcome to the AMD Second Quarter 2024 Conference Call. At this time, all participants are in a listen-only mode. A brief question-and-answer session will follow the formal presentation. [Operator Instructions] As a reminder, this conference is being recorded. It is now my pleasure to introduce to you Mitch Haws, Vice President Investor Relations. Thank you, Mitch. You may begin.
Mitch Haws : Thank you, and welcome to AMD's Second Quarter 2024 Financial Results Conference call. By now you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations page of amd.com. We will refer primarily to non-GAAP financial measures during today's call. The full non-GAAP to GAAP reconciliations are available in today's press release, and the slides posted on our website. Participants on today's conference call are Dr. Lisa Su, our Chair and Chief Executive Officer; and Jean Hu, our Executive Vice President, Chief Financial Officer, and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Dr. Lisa Su will attend the Goldman Sachs Technology Communicopia and Technology Conference on Monday, September 9th, and Mark Papermaster, Executive Vice President and Chief Technology Officer, will attend the Deutsche Bank Technology conference on Wednesday, August 28th. Today's discussion contains forward-looking statements based on current beliefs, assumptions, and expectations. Speak only as of today and as such, involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause action results to differ materially. With that, I'll hand the call over to Lisa.
Lisa Su : Thank you, Mitch, and good afternoon to all those listening today. We delivered strong second quarter financial results with revenue coming in above the midpoint of guidance and profitability increasing by a double-digit percentage driven by higher than expected sales of our Instinct, Ryzen, and EPYC processors. We continued accelerating our AI traction, as leading cloud and enterprise providers, expanded availability of Instinct MI300X solutions, and we also saw positive demand signals for general purpose compute in both our client and server processor businesses. As a result, second quarter revenue increased 9% year-over-year to $5.8 billion, as significantly higher sales of our data center and client processors more than offset declines in gaming and embedded product sales. We also expanded gross margin by more than 3 percentage points and grew EPS 19%, as data center product sales accounted for nearly 50% of overall sales in the quarter. Turning to the segments, data center segment revenue increased 115% year-over-year to a record $2.8 billion, driven by the steep ramp of Instinct MI300 GPU shipments and a strong double-digit percentage increase in EPYC CPU sales. Cloud adoption remains strong as hyperscalers deploy fourth-gen EPYC CPUs to power more of their internal workloads and public instances. We are seeing hyperscalers select EPYC processors to power a larger portion of their applications and workloads, displacing incumbent offerings across their infrastructure with AMD solutions that offer clear performance and efficiency advantages. The number of AMD-powered cloud instances available from the largest providers has increased 34% from a year ago to more than 900. We are seeing strong pull for these instances with both enterprise and cloud-first businesses. As an example, Netflix and Uber both recently selected fourth-gen EPYC Public Cloud instances as one of the key solutions to power their mission critical customer facing workloads. In the enterprise, sales were increased by a strong double-digit percentage sequentially. We closed multiple large wins in the quarter with financial services, technology, health care, retail, manufacturing, and transportation customers, including Adobe, Boeing, Industrial Light & Magic, Optiver, and Siemens. Importantly, more than one-third of our enterprise server wins in the first half of the year were with businesses deploying EPYC in their data centers for the first time, highlighting our success attracting new customers, while also continuing to expand our footprint with existing customers. Looking ahead, our next-generation Turin family, featuring our new Zen 5 core is looking very strong. Zen 5 is a grounds up new core design optimized for leadership performance and efficiency. Turin will extend our TCO leadership by offering up to 192 cores and 384 threads, support for the latest memory and I.O. Technologies, and the ability to drop into existing fourth-gen EPYC platforms. We publicly previewed Turin for the first time in June, demonstrating our significant performance advantages in multiple compute-intensive workloads. We also passed a major milestone in the second quarter as we started Turin production shipments to lead Cloud customers. Production is ramping now ahead of launch and we expect broad OEM and cloud availability later this year. Turning to our data center AI business, we delivered our third straight quarter of record data center GPU revenue with MI300 quarterly revenue exceeding $1 billion for the first time. Microsoft expanded their use of MI300X Accelerators to power GPT-4 Turbo and multiple co-pilot services including Microsoft 365 Chat, Word, and Teams. Microsoft also became the first large hyperscaler to announce general availability of public MI300X instances in the quarter. The new Azure VMs leverage the industry-leading compute performance and memory capacity of MI300X in conjunction with the latest ROCm software to deliver leadership-inferencing price performance when running the latest frontier models, including GPT-4. Hugging Face was one of the first customers to adopt the new Azure instances, enabling enterprise and AI customers to deploy hundreds of thousands of models on MI300X GPUs with one click. Our enterprise and Cloud AI customer pipeline grew in the quarter, and we are working very closely with our system and cloud partners to ramp availability of MI300 solutions to address growing customer demand. Dell, HPE, Lenovo, and Supermicro all have Instinct platforms in production, and multiple hyperscale and tier-2 cloud providers are on track to launch MI300 instances this quarter. On the AI software front, we made significant progress enhancing support and features across our software stack, making it easier to deploy high performance AI solutions on our platforms. We also continued to work with the open source community to enable customers to implement the latest AI algorithms. As an example, AMD support for Flash Attention 2 algorithm was upstreamed, providing out-of-the-box support for AMD hardware in the popular library that could increase training and inference performance on large transformer models. Our work with the model community also continued accelerating, highlighted by the launches of new models and frameworks with day one support for AMD hardware. At Computex, I was joined by the co-CEO of Stable Diffusion to announce that MI300 is the first GPU to support their latest SD 3.0 image generation LLM. Last week, we were proud to note that multiple partners used ROCm and MI300X to announce support for the latest Llama 3.1 models, including their 405 billion parameter version that is the industry's first frontier-level open source AI model. Llama 3.1 runs seamlessly on MI300 accelerators, and because of our leadership memory capacity, we're also able to run the FP16 version of the Llama 3.1 405B model in a single server, simplifying deployment and fine-tuning of the industry-leading model and providing significant TCO advantages. Earlier this month, we announced our agreement to acquire Silo AI, Europe's largest private AI lab with extensive experience developing tailored AI solutions for multiple enterprise and embedded customers, including Allianz, Ericsson, Finnair, Korber, Nokia, Philips, T-Mobile, and Unilever. The Silo team significantly expands our capability to service large enterprise customers looking to optimize their AI solutions for AMD hardware. Silo also brings deep expertise in large language model development, which will help accelerate optimization of AMD inference and training solutions. In addition to our acquisitions of Silo AI, [Sology] (ph), and Nod.ai, we have invested over $125 million across a dozen AI companies in the last 12 months to expand the AMD AI ecosystem, support partners, and advance leadership AMD computing platforms. Looking ahead from a roadmap perspective, we are accelerating and expanding our Instinct roadmap to deliver an annual cadence of AI accelerators, starting with the launch of MI325X later this year. MI325X leverages the same infrastructure as MI300 and extends our generative AI performance leadership by offering twice the memory capacity and 1.3 times more peak compute performance than competitive offerings. We plan to follow MI325X with the MI350 series in 2025 based on the new CDNA 4 architecture, which is on track to deliver a 35x increase in performance compared to CDNA 3. And our MI400 series powered by the CDNA “Next” architecture is making great progress in development and is scheduled to launch in 2026. Turning to our AI solutions work, Broadcom, Cisco, HP Enterprise, Intel, Google, Meta, and Microsoft all joined us to announce Ultra Accelerator Link, an industry standard technology to connect hundreds of AI accelerators that is based on AMD's proven infinity fabric technology. By combining UA-Link with the widely supported ultra-Ethernet consortium specification, the industry is coming together to establish a standardized approach for building the next generation of high-performance data centers, AI solutions at scale. In summary, customer response to our multi-year Instinct and ROCm roadmaps is overwhelmingly positive and we're very pleased with the momentum we are building. As a result, we now expect data center GPU revenue to exceed $4.5 billion in 2024, up from the $4 billion we guided in April. Turning to our client segment, revenue was $1.5 billion, an increase of 49% year-over-year driven by strong demand for our prior generation Ryzen processors and initial shipments of our next generation Zen 5 processors. In PC applications, Zen 5 delivers an average of 16% more instructions per clock than our industry leading previous generation of Ryzen processors. For desktops, our upcoming Ryzen 9000 series processors drop into existing AM5 motherboards and extends our performance and energy efficiency leadership across productivity, gaming, and content creation workloads. For notebooks, we announced our Ryzen AI 300 series that extends our industry-leading CPU and GPU performance and introduces the industry's fastest NPU with 50 tops of AI compute performance for Copilot Plus PCs. The first Ryzen AI 300 series notebooks went on sale over the weekend to strong reviews. And more than 100 Ryzen AI 300 series premium, gaming, and commercial platforms are on track to launch from Acer, ASUS, HP, Lenovo, and others over the coming quarters. Customer excitement for our new Ryzen processors is very strong, and we are well positioned for ongoing revenue share gains based on the strength of our leadership portfolio and design win momentum. Now turning to our gaming segment, revenue declined 59% year-over-year to $648 million as semi-custom SoC sales declined in-line with our projections. Semi-custom demand remains soft, as we are now in the fifth-year of the console cycle and we expect sales to be lower in the second half of the year compared to the first half. In gaming graphics, revenue increased year-over-year driven by improved sales of our Radeon 6000 and 7000 series GPUs in the channel. Turning to our embedded segment, revenue decreased 41% year-over-year to $861 million. The first quarter marked the bottom for our embedded segment revenue. Although second quarter revenue was flattish sequentially, we saw early signs of order patterns improving and expect embedded revenue to gradually recover in the second half of the year. Longer term we are building strong design win momentum for our expanded embedded portfolio. Design wins in the first half of the year increased by more than 40% from the prior year to greater than $7 billion, including multiple triple-digit million-dollar wins combining our adaptive and x86 compute products. We announced our Alveo V80 accelerators that deliver leadership capabilities in memory-intensive workloads and entered early access on next-generation Edge AI solutions with more than 30 key partners on our upcoming second-gen Versal adaptive SoCs. Last week, we also announced Victor Peng, President of AMD, would retire at the end of August. Victor has made significant contributions to Xilinx and AMD, including helping scale our embedded business and leading our cross-company AI strategy. On a personal note, Victor has been a great partner to me in sharing the success of our Xilinx acquisition and integration. On behalf of all of the AMD employees and board, I want to thank Victor for all of his contributions to AMD success and wish him all the best in his retirement. In summary, we delivered strong second quarter results and are well positioned to grow revenue significantly in the second half of the year, driven by our data center and client segments. Our data center GPU business is on a steep growth trajectory as shipments ramp across an expanding set of customers. We're also seeing strong demand for our next generation Zen 5 EPYC and Ryzen processors that deliver leadership performance and efficiency in both data center and client workloads. Looking ahead, the rapid advances in generative AI and development of more capable models are driving demand for more compute across all markets. Under this backdrop, we see strong growth opportunities over the coming years and are significantly increasing hardware, software and solutions investments with a laser focus on delivering an annual cadence of leadership data center GPU hardware, integrating industry leading AI capabilities across our entire product portfolio, enabling full stack software capabilities, amplifying our ROCm development with the scale and speed of the open source community and providing customers with turnkey solutions that accelerate the time to market for AMD based AI systems. We are excited about the unprecedented opportunities in front of us and are well positioned to drive our next phase of significant growth. Now I'd like to turn the call over to Jean to provide some additional color on our second quarter results. Jean?
Jean Hu : Thank you Lisa, and good afternoon everyone. I'll start with a review of our financial results and then provide our current outlook for the third quarter. We're very pleased with our overall second quarter financial results that came in above expectations. On a year-over-year basis, data center segment revenue more than doubled. Client segment revenue grow significantly, and we expand the gross margin by 340 basis points. For the second quarter of 2024, revenue was $5.8 billion, up 9% year-over-year, as revenue growth in the data center and the client segments was partially offset by lower revenue in our gaming and embedded segments. Revenue increases 7% sequentially, primarily driven by growth in the data center and the client segments revenue. Gross margin was 53%, up 340 basis points year-over-year, primarily driven by higher data center revenue. Operating expenses were $1.8 billion, an increase of 15% year-over-year, as we continue to invest in R&D to address the significant AI growth opportunities ahead of us and enhanced go-to-market activities. Operating income was $1.3 billion representing a 22% operating margin. Taxes, interest expense and other was $138 million. Diluted earnings per share was $0.69, an increase of 19% year-over-year. Now turning to our reportable segment. Starting with the data center. Data Center delivered record quarterly segment revenue of $2.8 billion, up 115%, a $1.5 billion increase in year-over-year. The Data Center segment accounted for nearly 50% of total revenue, led primarily by the steep ramp of AMD Instinct GPUs and strong double-digit percentage EPYC Server revenue growth. On a sequential basis, revenue increased 21%, driven primarily by strong momentum in AMD Instinct GPUs. Data center segment operating income was $743 million or 26% of revenue compared to $147 million or 11% a year ago. Operating income was up more than 5 times from the prior year, driven by higher revenue and operating leverage, even as we significantly increase our investment in R&D. Client segment revenue was $1.5 billion, up 49% year-over-year and 9% sequentially driven primarily by AMD Ryzen processor sales. Client segment operating income was $89 million or 6% of revenue compared to operating loss of $69 million a year ago. Gaming segment revenue was $648 million down 59% year-over-year and 30% sequentially. The decrease in revenue was primarily due to semi-customer inventory digestion and the lower end-market demand. Gaming segment operating income was $77 million, or 12% of revenue compared to $225 million or 14% a year ago. Embedded segment revenue was $861 million, down 41% year-over-year, as customers continue to normalize their inventory levels. On sequential basis, embedded segment revenue was up 2%. Embedded segment operating income was $345 million or 40% of revenue compared to $757 million or 52% a year ago. Turning to the balance sheet and the cash flow. During the quarter, we generated $593 million in cash from operations and the free cash flow was $439 million. Inventory increased sequentially by [$339 million] (ph) to $5 billion, primarily to support the continued ramp of a data center GPU product. At the end of the quarter, cash, cash equivalent, and short-term investments were $5.3 billion. In the second quarter, we returned $352 million to shareholders repurchasing 2.3 million shares, and we have $5.2 billion of authorization remaining. During the quarter, we retired $750 million of debt that matured this past June utilizing existing cash. Now turning to our third quarter, 2024 outlook. We expect revenue to be approximately $6.7 billion plus or minus $300 million. Sequentially, we expect revenue to grow approximately 15%, primarily driven by strong growth in the data center and the client segment. We expect embedded segment revenue to be up and the gaming segment to decline by double digit percentage. Year-over-year we expect revenue to grow approximately 16%, driven by the steep ramp of our AMD Instinct processors and strong server and client revenue growth to more than offset the declines in the gaming and embedded segments. In addition, we expect third quarter non-GAAP gross margin to be approximately 53.5%. Non-GAAP operating expenses to be approximately $1.9 billion. Non-GAAP effective tax rate to be 13%. And the diluted share count is expected to be approximately 1.64 billion shares. Also during the third quarter, we expect to close the acquisition of Silo AI for approximately $665 million in cash. In closing, we made significant progress during the quarter toward achieving our financial goals. We delivered record MI300 revenue that exceeded $1 billion and demonstrated solid traction with our next-gen Ryzen and EPYC product. We expanded gross margin significantly and drove earnings growth while increasing investment in AI. Looking forward, opportunities ahead of us are unprecedented, will remain focused on executing to our long-term growth strategy, while driving financial discipline and operational excellence. With that, I will turn it back to Mitch for the Q&A session.
Mitch Haws : Thank you, Jean. John, we're happy to poll the audience for questions.
Operator: Thank you, Mitch. We will now be conducting the question-and-answer session. [Operator Instructions] And the first question comes from the line of Ben Reitzes with Melius Research. Please proceed with your question.
Ben Reitzes: Hey, thanks a lot. Congratulations on these results. Lisa, I wanted to ask you about MI300, how you see it playing out sequentially for the rest of the year. I guess there is about $2.8 billion left to hit your annual target. So I'm wondering if you see things picking up in the fourth quarter and how that's going sequentially. And if you don't mind, I wanted to also ask about next year if you see potential for rapid growth. You're probably aware of some of the chatter out there, and I just was wondering if you are already seeing signs that you can grow significantly, given your road map for next year. Thank you so much.
Lisa Su: Yes. Great, Ben. Thanks for the question. So first of all on sort of MI300 and the customer evolution, we are very happy with how MI300 has progressed. When we started the year, I think the key point for us was to get our products into our customers' data centers, to have them qualify their workloads, to really ramp in production and then see what the production capabilities are especially performance and all of those things. And I can say now being sort of more than halfway through the year, we've seen great progress across the board. As we look into the second half of the year I think we would expect that MI300 revenue would continue to ramp in the third quarter and the fourth quarter. And we are continuing to expand both current deployments with our existing customers, as well as we have a large pipeline of customers that we are working through that are getting familiar with our architecture and software and all that stuff. So I’d say overall, very pleased with the progress, and really continuing right on track to what we expected from the capabilities of the product. As we go into next year, I mean one of the important things that we announced at Computex, was increasing and expanding our road map. I think we feel really good about our road map. We are on track to launch MI325 later this year. And then next year, our MI350 Series, which will be very competitive with Blackwell Solutions. And then we're well on our way to our CDNA Next as well. So I think, overall we remain quite bullish on the overall AI market. I think the market continues to need more compute. And we also feel very good that our hardware and software solutions are getting good traction, and we are continuing to expand that pipeline.
Ben Reitzes: Thank you.
Operator: And the next question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.
Aaron Rakers: Yeah, thanks for taking my question. And congrats on the quarter as well. I guess sticking on the Data Center side, as we look forward and you think about the full year, I'm curious of how you're currently thinking about the EPYC server CPU growth expectations as we go forward. And any kind of updated thoughts on your ability to kind of continue to gain share in the server market? Just kind of just update us on how you see the server market playing out over the next couple of quarters.
Lisa Su: Yes, sure Aaron. Thanks for the question. So we are very pleased with the progress that we've made with EPYC. I think a couple of things. First of all, in terms of competitive positioning and just the traction in the market, our fourth-gen EPYC between Zen 1 Bergamo is really doing very well. We've seen broad adoption across cloud, and then we've been very focused on enterprise as well as third-party cloud instances. And as I said in the prepared remarks, we are starting to see very nice traction in enterprise with both new customers as well as existing customers, and then for third-party cloud adoption, also a good pickup there as well. So I think overall, I think our EPYC portfolio has done well. Going into the second half of the year, I think we also feel good about it. There are a couple of positives there. We see -- first of all the market looks like it's improving, so we have seen some return to spending in both enterprise and cloud. And so I think those are positive market trends. And then in addition to that, we are in the process of launching Turin. So we started production here in the second quarter and we are on track to launch broadly in the second half of the year. We'll see some revenue of Turin in the second half of the year contributing as well. So overall, I think the server market and our ability to continue to grow share in the server market is one of the things that we see in the second half of the year.
Operator: And the next question comes from the line of Timothy Arcuri with UBS. Please proceed with your question.
Timothy Arcuri: Thanks a lot. Lisa, I wanted to ask about the Data Center GPU roadmap. As you said, 325 launching later this year, so I guess I had two questions. Does the greater than $4.5 billion, does that include any revenue from 325? And can you talk a little bit more about 350? Obviously, we are seeing a big rack scale or shift toward rack-scale systems for the competition's product. And I'm wondering if that's what 350 is going to look like. Is it going to have liquid cooling and is it going to have a rack scale aspect to it? Thanks.
Lisa Su: Yes, absolutely. So let me start with your original question. I mean, I think looking at 325X, we are on track to launch later this year. From a revenue standpoint there will be a small contribution in the fourth quarter but it really is still mostly the MI300 capabilities. And 325 will start in the fourth quarter and then ramp more in the first half of next year. And then as we look at the 350 Series, what we are seeing and the reason we call it a series is because there will be multiple SKUs in that series that we'll go through the range of, let's call it, air-cooled to liquid-cooled. In spending time with our customers. I think there are people who certainly want more rack level solutions, and we are certainly doing much more in terms of system-level integration for our products. You will see us invest more in system-level integration. But we also have many customers who want to use their current infrastructure. I think the beauty of the MI350 series is, it actually fits into the same infrastructure as the MI300 series. And so it would lend itself to, let's call it a pretty fast ramp if you've already invested in 300 or 325. So we see the range of options, and that's part of the expansion of the road map that we are planning.
Operator: And the next question comes from the line of Ross Seymore with Deutsche Bank. Please proceed with your question.
Ross Seymore: Hi, thanks for having me ask a question and congrats on the strong results. Well, Data Center is obviously very important. I just want to pivot to the Client side. Lisa, can you talk about the AI PC side of things? How you believe AMD is positioned? Are you seeing any competitive intensity changing with the emergence of ARM based systems? Just wanted to see how you are expecting that to roll out and what it means to second half seasonality.
Lisa Su: Yes. Sure, Ross. So first, we are very pleased with our Client business results. I think we have a very strong road map, so I'm very pleased with the road map. The Zen 5 based products, we're launching both notebook and desktop in the middle of this year. What we've seen is actually very positive feedback on the product. So we just actually launched the first Strix-based notebooks over the weekend. They went on sale. You may have seen some of the reviews. The reviews are very positive. Our view of this is the AI PC is an important add to the overall PC category. As we go into the second half of the year, I think we have better seasonality in general, and we think we can do, let us call it above-typical seasonality, given the strength of our product launches and when we are launching. And then into 2025, you're going to see AI PCs across sort of a larger set of price points which will also open up more opportunities. So overall, I’d say, the PC market is a good revenue growth opportunity for us. The business is performing well. The products are strong. And we are working very closely with both the ecosystem partners, as well as our OEM partners to have strong launches here into the second half of the year.
Ross Seymore: And is the ARM side changing anything or not really?
Lisa Su: Look, I think at this point the PC market is a big market and we are underrepresented in the market. I’d say that we take all of our competition very seriously. That being the case, I think our products are very well positioned.
Operator: And the next question comes from the line of Matt Ramsay with Cowen. Please proceed with your question.
Matt Ramsey: Thank you very much. Good afternoon. Lisa, I wanted to maybe draw a parallel between the Instinct portfolio that your company is rolling out now and what you guys did five or six years ago with EPYC. And I remember when the Naples product launched, there was a lot of, I’d say, reaction positively and negatively and sort of sentiment around where your road map might go to relatively small perturbations in what the volumes were, super early. But if I remember back to that, what was the most important was that was the toehold into the market for long-term engagement, both on the software side and the hardware side with your customers two, three, four generations forward. So is that an accurate parallel to where you guys are with MI300? And maybe you could talk about the level of engagement, the intensity of engagement, the breadth of it across the customer base with 350 and 400. Thanks.
Lisa Su: Yes, absolutely, Matt. So look as I said earlier, we are very pleased with the progress that we are making on the Instinct road map. This is absolutely a long-term play so absolutely, you are correct. It has a lot of parallels to the EPYC journey, where you really have to -- you gain more opportunities, broader workloads, larger deployments as you go from generation to generation. So we are playing the long game here. Our conversations with our customers, so I’d start with first, in the near-term, we had some very key milestones that we wanted to pass this year. And as I said, they related to getting hardware in volume in multiple hyperscalers, as well as large Tier 2 customers. We've done that. We've now seen our software in a lot of different environments, and it is matured substantially. ROCm is in very -- from a standpoint of features, functions, out-of-box performance, getting to performance with customers, we've gained a lot of confidence and learned a lot in that whole process. The networking aspects of building out the rack scale and the system-level items are areas that we are continuing to invest in. And then the point of having long-term conversations across multiple generations is also really important. So I think all of those things have progressed well. We view this as very good progress for MI300, but we have a lot more to do. And I think the various road maps will help us open up those opportunities over the next couple of years.
Matt Ramsey: Appreciated. Thank you.
Lisa Su: Thanks Matt.
Operator: And the next question comes from the line of Vivek Arya with Bank of America Securities. Please proceed with your question.
Vivek Arya: Thanks for taking my question. Lisa, there seems to be this ongoing industry debate about AI monetization and whether your customers are getting the right ROI on their CapEx. And today, they have these three options, right? They can buy GPUs from your largest competitor with all the software bells and whistles and incumbency or they can do custom chips or they can buy from AMD. So how do you think this plays out next year? Do you think your customers given all this concern around monetization, does it make them consolidate their CapEx around just the other two suppliers? How is your visibility going into next year, given this industry debate? And how will AMD continue to kind of carve a position between these two other competitive choices that are out there? Thank you.
Lisa Su: Yes, sure, Vivek. Well, I mean I think you talk to a lot of the same people that we talk to. I think the overall view on AI investment is we have to invest. I mean the industry has to invest. The potential of AI is so large to impact the way enterprises operate and all that stuff. So I think the investment cycle will continue to be strong. And then relative to the various choices for the size of the market, I firmly believe that there will be multiple solutions, whether you are talking about GPUs or you are talking about custom chips or ASICs, there will be multiple solutions. In our case, I think we've demonstrated a really strong road map and the ability to partner well with our customers. And from the standpoint of that deep engagement, hardware, software co-optimization is so important in that. And for large language models, GPUs are still the architecture of choice. So I think, the opportunity is very large. And I think our piece of that is really strong technology with strong partnerships with the key AI market makers.
Vivek Arya: Thank you Lisa.
Lisa Su: Thanks Vivek.
Operator: And the next question comes from the line of Joe Moore with Morgan Stanley. Please proceed with your question.
Joe Moore: Great. Thank you. I also wanted to ask about MI300. I wonder if you could talk about training versus inference. Do you have a sense -- I know that a lot of the initial focus was inference, but do you have traction on the training side? And any sense of what that split may look like over time?
Lisa Su: Yes, sure. Thanks for the question Joe. So as we said on MI300, there are lots of great characteristics about it. One of them is our memory bandwidth and memory capacity is leading the industry. From that standpoint, the early deployments have largely been inference in most cases, and we have seen fantastic performance from an inference standpoint. We also have customers that are doing training. We've also seen that from a training standpoint, we've optimized quite a bit our ROCm software stack, to make it easier for people to train on AMD. And I do expect that we'll continue to ramp training over time. As we go forward, I think you'll see -- the belief is that inference will be larger than training from a market standpoint. But from an AMD standpoint, I’d expect both inference and training to be growth opportunities for us.
Joe Moore : Great. Thank you.
Operator: And the next question comes from the line of Toshiya Hari with Goldman Sachs. Please proceed with your question.
Toshiya Hari: Hi, thank you so much for taking the question. I had a question on the MI300 as well. Curiously, if you are currently shipping to demand or if the updated annual forecast of $4.5 billion is in some shape or form supply constrained. I think last quarter you gave some comments on HBM and CoWoS. Curious if you could provide an update there. And then my Part B to my question is on profitability for MI300. I think in the past, you've talked about the business being accretive and improving further over time as you sort of work through the kinks, if you will. Has that view evolved or changed at all, given sort of the competitive intensity and your need to invest, whether it be through organic R&D or some of the acquisitions you've made? Or are you still confident that profit margins in the business continue to expand? Thank you.
Lisa Su: Yes. Sure, Toshiya. Thanks for the question. So on the supply side, let me make a couple of comments and then maybe I'll let Jean comment on sort of the trajectory for the business. So on the supply side, we made great progress in the second quarter. We ramped up supply significantly exceeding $1 billion in the quarter. I think the team has executed really well. We continue to see line of sight to continue increasing supply as we go through the second half of the year. But I will say that the overall supply chain is tight and will remain tight through 2025. So under that backdrop, we have great partnerships across the supply chain. We've been building additional capacity and capability there. And so we expect to continue to ramp as we go through the year. And we'll continue to work both supply as well as demand opportunities, and really that's accelerating our customer adoption overall, and we'll see how things play out as we go into the second half of this year.
Jean Hu: Yes. On your second question about the profitability, first our team has done a tremendous job to ramp the product MI300. It is a very complex product. So we ramped it successfully. At the same time, the team also started to implement operational optimization to continue to improve gross margin. So we continue to see the gross margin improvement. Over time, in the longer term, we do believe gross margin will be accretive to corporate average. From a profitability perspective, AMD always invests in platforms. If you look at our Data Center platform especially both the [Server] (ph) and the Data Center GPU side, we are ramping the revenue. The business model can leverage very significantly even from GPU side. Because the revenue ramp has been quite significant, the operating margin continued to expand. We definitely want to continue to invest as the opportunity is huge. At the same time, it is a profitable business already.
Toshiya Hari: Thank you very much.
Operator: And the next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed with your question.
Stacy Rasgon: Hi, guys. Thanks for taking my question. I wanted to dig into the Q3 guidance a little bit, if I could. So with Gaming down double digits, it probably means you've got close to $1 billion of growth revenue across Data Center, Client, and Embedded. I was wondering if you could give us some color on how that $1 billion-ish splits out across those three businesses. Like if I had 70% of it going to Data Center and 20% going to Client and 10% going to Embedded, like would that be like way off? Or how should we think about that apportioning out across the segment?
Lisa Su: Yes. Maybe Stacy, let me give you the following color. So the Gaming business is down double digit as you state. Think of it as the Data Center is the largest piece of it, client next. And then on the Embedded side think of it as single-digit sequential growth.
Stacy Rasgon: Got it. So I mean within that Data Center piece then, how does that split out? I mean, is the bulk of it [indiscernible] Instinct? Or is it sort of equally weighted between Instinct and EPYC? Or like again how does it -- again if you got, I don't know $400 million to $600 million of sequential Data Center growth or something like that, how does it split up?
Lisa Su: Yes. So again, without being that granular, we will see both -- certainly, the Instinct GPUs will grow and we'll see also very nice growth on the server side.
Operator: And the next question comes from the line of Harsh Kumar with Piper Sandler. Please proceed with your question.
Harsh Kumar: Hi, Lisa. From my rudimentary understanding, the large difference between your Instinct products and the adoption versus your nearest competitor is kind of rack level performance and that rack level infrastructure that you may be lacking. You talked a little bit about UALink. I was wondering if you could expand on that and give us some more color on when that might -- when that gap might be closed. Or is this a major step for the industry to close that gap? Just any color would be appreciated.
Lisa Su: Yes. So Harsh, overall, maybe if I take a step back and just talk about how the systems are evolving, there is no question that the systems are getting more complex, especially as you go into large training clusters, and our customers need help to put those together. And that includes the sort of Infinity Fabric-type solutions that are the basis for the UALink things as well as just general rack level system integration. I think what you should expect, Harsh is, first of all, we're very pleased with all of the partners that have come together for UALink. We think that's an important capability. But we have all of the pieces of this already within sort of the AMD umbrella with our Infinity Fabric, with the work with our networking capability through the acquisition of Pensando. And then you'll see us invest more in this area. So this is part of how we help customers get to market faster is by investing in all of the components, so the CPUs, the GPUs, the networking capability as well as system-level solutions.
Harsh Kumar: Thank you Lisa.
Lisa Su: Thanks Harsh.
Operator: And the next question comes from the line of Blayne Curtis with Jefferies. Please proceed with your question.
Blayne Curtis: Hi, good afternoon. Thanks for taking my question. I just want to ask another question on MI300. Just curious if you can kind of characterize the makeup of the customers in the first half. I know you had, end of last year, a government customer. Is there still a government contingency? And kind of the second part of it is really you've invested in all these software assets. Kind of curious the challenge of ramping the next wave of customers. I know there's been a lot of talk on some hardware challenges, memory issues and such, but then you're investing in software. I'm sure that's a big challenge, too. Just kind of curious what the biggest hurdle is for you to kind of get that next wave of customers ramp.
Lisa Su: Yes. So Blayne, a lot of pieces to that question, so let me try to address them. First, on your question about I think you are basically asking about the supercomputing piece. That was mainly Q4 and a bit in Q1. So if you think about our Q2 revenue, think about it as almost all AI. So it is MI300X, it's for large AI, hyperscalers as well as OEM customers going to enterprise and Tier 2 data centers. So that's the makeup of the customer set. And then in terms of the various pieces of what we're doing, I think first on your question about memory, I think there's a lot of noise in the system. I wouldn't really pay attention to all that noise in the system. I mean, this has been an incredible ramp. And I'm actually really proud of what the team has done in terms of just definitely fastest product ramp that we've ever done to $1 billion here in the -- over $1 billion in the second quarter, and then ramping each quarter in Q3 and Q4. In terms of memory, we have multiple suppliers that we've qualified on HBM3. And it is a tricky -- memory is a tricky business but I think we've done it very well and that's there. And then we are also qualifying HBM3E for future products with multiple memory suppliers as well. So to your overarching question of what are the things that we're doing, the exciting part of this is that the ROCm capability has really gotten substantially better because so many customers have been using it. And with that, what we look at is out of box performance, how long does it take a customer to get up and running on MI300? And we've seen, depending on the software that companies are using, particularly if you are based on some of the higher-level frameworks like PyTorch, et cetera, we can be out-of-the-box running very well in a very short amount of time, like let's call it, very small number of weeks. And that's great because that's expanding the overall portfolio. We’re going to continue to invest in software and that was one of the reasons that we did the Silo AI acquisition. It is a great acquisition for us, 300 scientists and engineers. These are engineers that have experience with AMD hardware and are very, very good at helping customers get up and running on AMD hardware. And that's -- so we view this as the opportunity to expand the customer base with talent like Silo AI, like Nod.ai which brought a lot of compiler talent. And then we continue to hire quite a bit organically. So I think Jean said earlier that we see leverage in the model, but we are going to continue to invest because this opportunity is huge, and we have all of the pieces. This is just about building out scale.
Blayne Curtis: Thanks so much.
Lisa Su: Thanks.
Operator: And the next question comes from the line of Tom O'Malley with Barclays. Please proceed with your question.
Tom O'Malley: Hi, Lisa. Thanks for taking my question. I'll give you a breather from the MI300 for a second, but just to focus on Client in the second half. No problem. Focused on Client in the second half, you kind of said above-seasonal for September, December. You're obviously launching a new notebook, desktop product, but you're also talking about AI PC. Could you just break down where you're seeing those above-seasonal trends? Is it the ASP uplift you're getting from the new products? Is it a unit assumption that's coming with AI PC? Just any kind of breakdown between those two and why you're seeing it a little bit better. Thank you.
Lisa Su: Sure, Tom. So I think you actually said it well. We are launching Zen 5 desktops and notebooks with volume ramping in the third quarter. And that’s the primary reason that we see above-seasonal. The AI PC element is certainly 1 element of that, but there is just the overall refresh. Usually, desktop launches going into a third quarter are good for us, and we feel that the products are very well positioned. So those are the primary reasons.
Operator: And our final question comes from the line of Chris Danely with Citi. Please proceed with your question.
Chris Danely: Again. Thanks for speaking me in. Just a question on gross margin. So if we look at your guidance, it seems like the incremental gross margin is dropping a little bit for Q3. Why is that happening? And then just a follow-up on another part of the gross margin angle. Have you changed your gross margin expectations for the MI300? Has the accretion point moved out a little bit?
Jean Hu: Yes, Chris, thanks for the question. I think, first we have made a lot of progress, as you mentioned, this year to expand our gross margin from 2023 at a 50 percentage point to, we actually guided 53.5% for Q3. The primary driver is really the faster Data Center business growth. If you look at the Data Center business as a percentage of revenue from 37% in Q4 last year to now close to 50%. That faster expansion really helped us with the gross margin. When you look at the second half we will continue to see Data Center to be the major driver of our top-line revenue growth, will help with the margin expansion. But there are some other puts and takes. I think Lisa mentioned the PC business actually is going to do better in second half, especially typically, seasonally, it tends to be more consumer-focused. So that really is a little bit different dynamics there. Secondly, I’d say, Embedded business, we are going to see Embedded business to be up sequentially each quarter. But the recovery, as we mentioned earlier, is more gradual. So when you look at the balance of the picture, that's why we see the gross margin -- the pace of the gross margin changed a little bit, but we do see continued gross margin expansion. As far as MI300, we are quite confident over the long-term, it will be accretive to our corporate average. We feel pretty good about the overall Data Center business to continue to be absolutely the driver of gross margin expansion.
Chris Danely: Thank you.
Operator: Thank you. I would like to turn the floor back over to Mitch for any closing comments.
Mitch Haws: Great. That concludes today's call. Thanks to all of you for joining us today.
Operator: And ladies and gentlemen, that does conclude today's teleconference. You may disconnect your lines at this time. Thank you for your participation.",2024-07-30
AMD,2024,3,2024-Q3-AMD,"Operator: Greetings, and welcome to the AMD Third Quarter 2024 Conference Call. At this time, all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. [Operator Instructions]. And as a reminder, this conference is being recorded. It is now my pleasure to introduce you, Mitch Haws, Vice President of Investor Relations. Thank you, Mitch. You may begin.
Mitch Haws: Thank you, and welcome to AMD's third quarter 2024 financial results conference call. By now, you should have had the opportunity to review a copy of our earnings press release and the accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations page of amd.com. We will refer primarily to non-GAAP financial measures during today's call. The full non-GAAP to GAAP reconciliations are available in today's press release and the slides posted on our website. Participants on today's conference call are Dr. Lisa Su, our Chair and Chief Executive Officer; and Jean Hu, our Executive Vice President, Chief Financial Officer and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Forrest Norrod, Executive Vice President and General Manager, Data Center Business Solutions, will attend the UBS Annual Technology Conference on Tuesday, December 3, and Jean Hu will attend the Barclays Global TMT Conference on Thursday, December 12. Today's discussion contains forward-looking statements based on current beliefs, assumptions and expectations, speak only as of today and as such, involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause actual results to differ materially. With that, I'll hand the call over to Lisa.
Dr. Lisa Su: Thank you, Mitch, and good afternoon to all those listening today. We delivered strong top- and bottom-line growth in the third quarter with revenue coming in above expectations, driven by record Instinct and EPYC product sales and robust demand for our Ryzen PC processors. Third quarter revenue increased 18% year-over-year to a record $6.8 billion as significantly higher Data Center and Client Processor sales more than offset declines in Gaming and Embedded product sales. We expanded gross margin by 2.5 percentage points and increased earnings per share by 31% year-over-year as Data Center segment revenue more than doubled. Turning to the segments. Data Center segment revenue increased 122% to a record $3.5 billion. We believe we gained server CPU share in the quarter as Enterprise wins accelerated. Cloud providers expanded their use of EPYC CPUs across their infrastructure, and we began the initial ramp of fifth-gen EPYC processors. EPYC has become the CPU of choice for the modern data center and our multi-generation product portfolio delivers leadership performance and significant TCO advantages across virtually every enterprise and cloud workload. In cloud, EPYC CPUs are deployed at scale to power many of the most important services, including Office 365, Facebook, Teams, Salesforce, SAP, Zoom, Uber, Netflix and many more. Meta alone has deployed more than 1.5 million EPYC CPUs across their global data center fleet to power their social media platforms. Cloudflare selected general X processors with our industry-leading 3D chiplet stacking technology to power their next-generation servers that support twice as many requests per second and deliver 60% higher performance per watt versus their prior generation. Public cloud instances increased 20% year-over-year to more than 950 as Microsoft, AWS and others launched or expanded their EPYC processor-powered offerings in the quarter. EPYC Instance adoption with Enterprise customers also grew in the quarter, highlighted by wins with Adobe, Boeing, Micron Nestle Slack, Synopsys, Tata and others. In the Enterprise, sales grew by a strong double-digit percentage year-over-year for the fifth straight quarter as EPYC CPU adoption accelerated and sell-through momentum grew. Dell, HPE, Lenovo and others have expanded the number of fourth-gen EPYC platforms they offer by 50% in the last year. There are now more than 200 different EPYC solutions available that are optimized for a broad range of enterprise and edge workloads. We are building strong momentum with large Enterprise customers, highlighted in the third quarter by wins with large technology, energy, financial services and automotive companies in the quarter, including Airbus, Daimler Truck, FedEx, HSBC, Siemens, Walgreens and others. We launched our next-generation Turin family earlier this month that delivers absolute performance and TCO leadership across both Enterprise scale up and Cloud-native scale-out workloads. Turin has already set more than 130 performance records for virtualization, database, AI, business applications and energy efficiency with the full EPYC portfolio accounting for more than 500 performance World Records. More than 130 fifth-gen EPYC enterprise platforms are in development from all the leading server OEMs and ODMs. These new servers complement existing fourth-gen EPYC platforms providing a top to bottom stack of platforms optimized for a broad range of business applications. In Cloud, Google and OCI announced plans to launch fifth-gen EPYC instances early next year, and we expect broad adoption with our largest cloud customers based on the significant performance and efficiency advantages of Turin. As an example, Oracle's Turin instances delivered 35% higher performance per core, 33% faster memory speeds and double the networking bandwidth delivering a level of compute performance and capability that is only possible with EPYC CPUs. Looking ahead, we are very well positioned for continued growth in share gains based on the strength of our broad EPYC portfolio and the momentum we have built with Cloud and Enterprise customers. We also took a major step in the quarter to advance the x86 architecture, forming an ecosystem advisory group with Intel, several industry luminaries and the largest cloud PC and enterprise leaders to accelerate innovation by driving consistency and compatibility across both the x86 instruction set and architectural interfaces and ensuring we evolve x86 as a compute platform of choice for developers and customers. Turning to our Data Center AI business, Data Center GPU revenue ramped as MI300X adoption expanded with cloud, OEM and AI customers. Microsoft and Meta expanded their use of MI 300X accelerators to power their internal workloads in the quarter. Microsoft is now using MI 300X broadly for multiple co-pilot services powered by the family of GPT 4 models. Meta announced they have optimized and broadly deployed MI 300X to power their inferencing infrastructure at scale, including using MI300X exclusively to serve all live traffic for the most demanding Llama 405B frontier model. We are also working closely with Meta to expand their Instinct deployments to other workloads where MI300X offers TCO advantages, including training. MI300X public cloud instance availability expanded in the quarter with Microsoft, Oracle Cloud and multiple AI specialized cloud providers now offering Instinct instances with leadership performance and TCO for many of the most widely used models. Instinct cloud instance adoption is strong with multiple start-ups and industry leaders adopting MI300 instances to power their models and services, including Essential AI, Fireworks AI, Luma AI and Databricks. On the AI software front, since launching MI300 10 months ago, we have expanded functionality at every layer of the ROCm stack and increase the number of models that run out of the box on Instinct accelerators to more than 1 million, enabling customers to get up and running as fast as possible with maximum out-of-the-box performance. With the release of ROCm 6.2 last quarter, MI300x inferencing performance has improved 2.4x since launch, and trading performance has increased 80%. We are working closely with a growing number of marquee Cloud and Enterprise customers to fine-tune their specific inferencing workloads for MI300 with many customers seeing 30% higher performance compared to competitive offerings, and we continue to expand our work with the open-source community, broadening support for key frameworks like JAX, libraries like vLLM and hardware-agnostic compilers like Triton. At our advancing AI event earlier this month, we were excited to be joined by the creators and leaders of some of the most important AI software technologies who have added foundational support for ROCm into Triton, the Llama Stack, SGLang, vLLM and TensorFlow and are working to enable broader open-source community work with Instinct platforms. With this growing support from the broader AI software ecosystem and the significant advances we have made in our software stack, ROCm now provides AI developers with a truly open software alternative that has been deployed and validated at scale. To expand our AI systems capabilities, we announced a definitive agreement to acquire ZT Systems, one of the leading providers of AI infrastructure to the world's largest hyperscale computing companies. The ZT team complements our silicon and software capabilities with critical systems expertise needed to deliver rack and cluster level solutions. With ZT we will be able to design and validate our next-gen AI silicon and systems in parallel, greatly accelerating time to deploy instant accelerators at data center scale. Customer feedback has been very positive as the ZT acquisition enabled hyperscale customers to rapidly deploy AMD AI infrastructure at scale and provides OEMs and ODMs with optimized board and module designs for a wide range of differentiated Enterprise solutions. On the regulatory front, we made good progress as we recently passed the HSR waiting period required for U.S. approval. We remain on track to close the acquisition in the first half of 2025. As a reminder, we plan to divest ZT's industry-leading U.S.-based data center infrastructure manufacturing business at the close of the transaction and are pleased that we have received significant interest from a number of parties to date. Looking ahead, we launched our next-gen MI325X GPU earlier this month that extends our memory capacity and bandwidth advantages and delivers up to 20% higher inferencing performance compared to H200 and competitive training performance. Customer and partner interest for MI325X is high. Production shipments are planned to start this quarter with widespread system availability from Dell, HP, Lenovo, Super Micro and others starting in the first quarter of 2025. Longer term, we have successfully accelerated our product development pace to deliver an annual cadence of new Instinct products. Our next-gen MI350-series silicon is looking very good and is on track to launch in the second half of 2025 with the largest generational increase in AI performance we have ever delivered. Development on our MI400 series based on the CDNA Next architecture is also progressing very well towards a 2026 launch. We have built significant momentum across our data center AI business with deployments increasing across an expanding set of Cloud, Enterprise and AI customers. As a result, we now expect Data Center GPU revenue to exceed $5 billion in 2024, up from $4.5 billion we guided in July and our expectation of $2 billion when we started the year. Turning to our Client segment. Revenue was $1.9 billion, an increase of 29% year-over-year, driven by strong demand for our latest generation Zen 5 notebook and desktop processors. Desktop channel sales grew by a significant double-digit percentage led by the launch of our Ryzen 9000 series processors that deliver leadership productivity, gaming and content creation performance. We are seeing strength across our Ryzen desktop portfolio and are on track to launch our next-gen Ryzen 9,000 X3D processors in November with leadership gaming performance. In mobile, Ryzen AI 300 Series sales ramped significantly from the prior quarter as Acer, HP, Lenovo, Asus and others announced new consumer and commercial notebooks with leadership compute and AI performance. We made good progress expanding our presence in the commercial PC market in the quarter, closing multiple large deals with AstraZeneca, Bayer, Mazda, Shell, Volkswagen and other Enterprise customers. We also launched our Ryzen AI Pro 300 Series family, the first CPUs with enterprise-class security, manageability and AI capabilities for CoPilot Plus PCs. HP and Lenovo are on track to more than triple the number of Ryzen AI Pro platforms they offer in 2024, and we expect to have more than 100 Ryzen AI Pro commercial platforms in market next year, positioning us well for share gains as businesses refresh the hundreds of millions of Windows 10 PCs that will no longer receive Microsoft technical support starting in 2025. Now turning to our Gaming segment. Revenue declined 69% year-over-year to $462 million. Semi-custom sales declined as Microsoft and Sony reduced channel inventory. Sony announced the PS5 Pro with significant increases in graphics and ray tracing performance and AI-driven upscaling, featuring a new AMD semi-custom SoC that extends our multigenerational partnership. In Gaming Graphics, revenue declined year-over-year as we prepare for a transition to our next-gen Radeon GPUs based on our RDNA 4 architecture. In addition to a strong increase in gaming performance, RDNA 4 delivers significantly higher ray tracing performance and adds new AI capabilities. We are on track to launch the first RDNA 4 GPUs in early 2025. Turning to our Embedded segment, third quarter revenue decreased 25% year-over-year to $927 million. Embedded demand continues recovering gradually, led by strength in test and emulation offset by ongoing softness in the industrial market. Momentum continues building for our differentiated Versal family of adaptive SoCs, led by strong demand for our Versal premium VP 1902, which is the world's largest adaptive SoC in FPGA that is powering multiple platforms for all three of the largest EDA vendors. Our Versal portfolio is also being adopted broadly across multiple aerospace customers. As one example, SpaceX recently launched their latest generation broadband satellites powered by Versal AI Core adaptive SoCs. To build on this momentum, we taped out Telluride last quarter, the first product in our second-gen Versal family that delivers up to 10x more compute and enables AI application acceleration on a single chip. Design win momentum is very strong across our portfolio, tracking to grow more than 20% year-over-year in 2024 and positioning us well to grow our embedded business faster than the overall market in the coming years. In summary, the business accelerated in the third quarter, and we expect strong demand for our Instinct EPYC and Ryzen processors to result in another quarter of significant year-over-year growth. Taking a step back, this month marks my 10th anniversary as AMD's CEO. In the last 10 years, we have successfully completed multiple arcs. First, by turning the Company around and setting the solid financial and operational foundation required for sustained growth. And then by transforming AMD into the high-performance and adaptive computing leader. While I'm incredibly proud of what we've accomplished, I'm even more excited about the unprecedented growth opportunities in front of us. Looking out over the next several years, we see significant growth opportunities across our Data Center, Client and Embedded businesses driven by the nearly insatiable demand for more compute. Each of these opportunities is amplified exponentially by the rapid adoption of AI, and -- which is enabling new experiences that will make high-performance computing and even more essential part of our daily lives. In the Data Center alone, we expect the AI accelerator TAM will grow at more than 60% annually to $500 billion in 2028. To put that in context, this is roughly equivalent to annual sales for the entire semiconductor industry in 2023. Beyond the Data Center, we are adding leadership AI capabilities across our product portfolio and partnering deeply with a broad ecosystem of partners to deliver differentiated AI solutions at scale. This is an incredibly exciting time for AMD as the breadth of our technology and product portfolios combined with our deep customer relationships and diversity of markets we address, provide us with a unique opportunity as we execute our next arc and make AMD the end-to-end AI leader. Now, I'd like to turn the call over to Jean to provide some additional color on our third quarter results. Jean?
Jean Hu: Thank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the fourth quarter of fiscal 2024. We are very pleased with our strong third quarter financial results. On a year-over-year basis, Data Center segment revenue more than doubled and the Client segment revenue grew 29%. We expanded gross margin by 250 basis points and drove earnings per share growth of 31%. For the third quarter of 2024, revenue was $6.8 billion, up 18% year-over-year and the revenue -- as revenue growth in our Data Center and Client segment was partially offset by lower revenue in our Gaming and Embedded segment. Revenue increased 17% sequentially, primarily driven by growth in our Data Center and Client segment. Gross margin was 54%, up 250 basis points year-over-year, primarily driven by higher data center segment revenue. Operating expenses were $1.96 billion, an increase of 15% year-over-year as we continue to invest in R&D and go-to-market activities. Operating income was $1.7 billion, representing a 25% operating margin. Taxes, interest expense and other was $211 million. Diluted earnings per share was $0.92, an increase of 31% year-over-year and 33% sequentially. Now turning to our reportable segments. Starting with the Data Center. Data Center delivered record quarterly segment revenue of $3.5 billion, up 122%, nearly a $2 billion increase year-over-year and an increase of 25% sequentially. Growth in revenue was led primarily by the strong ramp of AMD Instinct GPU shipment and growth in AMD EPYC CPU sales. The Data Center segment accounted for 52% of total revenue in the third quarter. Data Center segment operating income was $1 billion or 29% of revenue compared to $306 million or 19% a year ago. Data Center segment operating income more than tripled compared to the prior year, driven by higher revenue and operating leverage. Client segment revenue was $1.9 billion, up 29% year-over-year and 26% sequentially, driven primarily by strong demand for our Zen 5 AMD Ryzen processors. Client segment operating income was $276 million or 15% of revenue compared to operating income of $140 million a year ago or 10% of revenue, primarily driven by higher revenue, partially offset by higher operating expenses. Gaming segment revenue was $462 million, down 69% year-over-year and 29% sequentially, primarily due to a decrease in semi customer revenue. Gaming segment operating income was $12 million or 2% of revenue compared to $208 million or 14% a year ago. Embedded segment revenue was $927 million, down 25% year-over-year as customers continue to normalize their inventory levels. Revenue increased 8% sequentially as demand improved in several end markets. Embedded segment operating income was $372 million or 40% of revenue compared to $612 million or 49% a year ago. Turning to the balance sheet and the cash flow. During the quarter, we generated $628 million in cash from operations and the free cash flow was $496 million. Excluding certain nonrecurring payments related to acquisitions from operating cash flows, our free cash flow was $619 million. Inventory increased sequentially by $383 million to $5.4 billion, primarily to support the continued ramp of Data Center segment products. At the end of the quarter, cash, cash equivalents and short-term investment was $4.5 billion. In the third quarter, we returned $250 million of cash to shareholders, repurchasing 1.8 million shares, and we have $4.9 billion of authorization remaining. Now turning to our fourth quarter of 2024 outlook. We expect revenue to be approximately $7.5 billion, plus or minus $300 million, up 22% year-over-year, driven by strong growth in our Data Center and Client segment, more than offset decline in the Gaming and Embedded segments. We expect revenue to be up approximately 10% sequentially, driven primarily by growth across Data Center, Client and the Gaming segment. In addition, we expect fourth quarter non-GAAP gross margin to be approximately 54%. Non-GAAP operating expenses to be approximately $2.05 billion. Non-GAAP other net income to be $17 million, non-GAAP effective tax rate to be 13% and the diluted share count is expected to be approximately 1.64 billion shares. In closing, we're pleased with our strong execution in the third quarter. We delivered record revenue, along with the strong year-over-year expansion in gross margin and earnings per share growth. Looking ahead, we are very well positioned to deliver another record quarter of revenue in the fourth quarter, driven by continued momentum in our data center and client segments. Importantly, we are making a strategic investment at position AMD as the end-to-end AI infrastructure leader and drive long-term profitable growth. With that, I'll turn it back to Mitch for the Q&A session.
Mitch Haws: Thank you, Jean. Let's poll the audience for questions.
Operator: Thank you, Mitch. We will now be conducting a question-and-answer session. [Operator Instructions]. And the first question comes from the line of Toshiya Hari with Goldman Sachs. Please proceed with your question.
Toshiya Hari: My first one is on the Data Center GPU business. Lisa, you took up your '24 outlook by $500 million. Curious what drove the change there? And more importantly, as you look forward into calendar '25, I doubt you're going to give us quantitative guidance on this call. But conceptually, how are you thinking about growth in your Instinct between your large cloud customers and your Enterprise customers? And if you can speak to the possibility of adding new customers within cloud, again, specific to Instinct, that would be really helpful.
Dr. Lisa Su: Sure. Toshiya, thank you for the question. So first of all, we had a very strong quarter for the Data Center overall in Q3 and especially for the Instinct product portfolio. We actually completed some important customer milestones, and we were able to ramp a bit above our initial expectations. So, Data Center GPU was very strong in the third quarter, and we raised overall guidance for the year from exceeding $4.5 billion to exceeding $5 billion based on the completion of some of those customer milestones. So, we feel good about the trajectory as we go through the end of this year. And then to your overall question about 2025. At a high level, look, we feel very good about the market from everything that we see, talking to customers, there's significant investment in trying to build out the infrastructure required across all of the AI workloads. And then within that, our product portfolio is getting stronger with the annual cadence, launching 325 later this quarter and 355 in the second half of next year. And then in terms of customers, our customer engagements are actually broadening quite well. So -- and it's broadening in two ways. So certainly, cloud -- our largest Cloud customers are broadening the set of workloads that they're running on AMD Instinct. And we're also very engaged with a number of large cloud and Enterprise customers that are actively working with us and optimizing their workloads, and we would expect those would be good opportunities for us over the next couple of quarters as well.
Toshiya Hari: Great. And then a quick follow-up, maybe one for Jean on gross margin. You're guiding Q4 gross margin essentially flat sequentially, if you can walk through the puts and takes there, that would be really helpful. And then again, as you look forward into '25, you're kind of speaking to continued Data Center growth. One would think the Embedded business hopefully begins to recover. And then within some of your businesses like server CPU, I would expect Enterprise to grow perhaps faster off a low base. So, I do think you have a lot going for you from a gross margin standpoint. But are those points valid? And what should we be thinking about in terms of potential headwinds as well?
Jean Hu: Yes. Thank you for that question. First, we are very pleased with our Q3 gross margin performance. We delivered 53.6% and we are guiding approximately 54% in Q4. In general, when you look at 2024, our gross margin improvement has been primarily driven by the mix, especially Data Center business continue to be the strong growth driver of our business, it's accounting for more than 50% of our revenue mix, that helps us to improve gross margin. Going to 2025, we're not going to guide specifically. But as you mentioned, the outputs and takes that will help us going forward I would say first is, going forward, the largest growth driver is our Data Center business, both the CPU side, the GPU side, and you are absolutely right, we see our Enterprise Server business continue to expand. That will be a tailwind on gross margin side. And secondly, Embedded business is recovering and gradually, but that will also help us with our gross margin. At the same time, we are also seeing our client business expansion nicely. Client business today is more focused on consumer side, which tend to be below corporate average. That's something headwind we'll deal with. And lastly, I would say our team has done a great job to continue to improve operational efficiency. When we scale the Company next year, you can see we're going to benefit from economics of scale to continue to drive our operational efficiency to improve gross margin.
Operator: And the next question comes from the line of Aaron Rakers with Wells Fargo. Please proceed with your question.
Aaron Rakers: Yes. Thanks for taking the question. I'll do two as well. I guess maybe building on the latter point that you just made, I'm curious of how you would characterize your supply chain having evolved now talking about $5-plus billion. How do we think about what you've been doing on the supply side, given the lead times, the production cycles of these MI300 and MI325 GPUs as we look out into 2025? And I have another question.
Dr. Lisa Su: Sure, Aaron. So, look, I've been very happy with how our supply chain has ramped over the last number of quarters. Clearly, it's a tight supply environment, but we've done a great job getting -- ensuring that we have capacity across the entire supply chain. Again, that was part of the reason for the higher revenue in the third quarter around our Instinct business, just both customer demand as well supply chain improvement. And going into the next few quarters going into 2025, I think we expect that the environment will continue to be tight, but we've also planned for significant growth going into 2025. And so, we feel good about our overall supply chain capability.
Aaron Rakers: Yes. And then as a quick follow-up, when I look at the sequential guidance in revenue at the midpoint, let's call it about $680 million up sequentially. Could you help us frame how much of that is driven by Client versus the Data Center piece of the business?
Dr. Lisa Su: Sure, Aaron. So certainly, if you look at the sequential guide, the largest contributor is the Data Center business. And that is now such a large piece of our business, it's over 50% of our business in Q3, and it will continue to grow in Q4. Client segment, we also expect to perform well. I think we've done very well with our launches this year, both on the desktop Zen 5 launches as well as the notebook AI PC launches. So, we expect growth there. And then the other segments on a sequential basis, Gaming, Embedded would be more modest.
Operator: And the next question comes from the line of Ross Seymore with Deutsche Bank. Please proceed with your question.
Ross Seymore: Lisa, congrats on the 10-year anniversary. Jean, when you gave the segment guidance kind of playing off the last question, you didn't mention Embedded as being up. And then, Lisa, you just talked about it being up left. Just curious, I know it's kind of a muted recovery. But what's happening in the Embedded business implied in your fourth quarter guidance? And how are you thinking about 2025 just directionally?
Dr. Lisa Su: Sure, Ross. Let me start, and then maybe Jean can add. Look, we've seen some improvement in the Embedded business. You saw some improvement in the sequential in Q3. We expect some modest improvement in Q4. What we're seeing is really a mix across the different subsegments in Embedded. There are some segments that are stronger. So, our test and emulation business actually did very well. We're ramping our new Versal platform there. Aerospace and defense did well, also continues to be relatively strong. Communications has not seen much recovery. So, I would say that, that's still fairly muted. And industrial is also a little bit on the softer side. So, between all of those, we expect a little bit of growth into Q4, and let's call it, modest growth in 2025, but we're planning for it to be a little bit mixed amongst the segments, maybe, Jean, if you want to add?
Jean Hu: No, I think you covered.
Ross Seymore: Great. And I guess for my follow-up, just on the EPYC business. You've done incredibly well there, Lisa. Have you seen any kind of loosening up of the crowding out effect with the -- well, in your case, the Instinct side taking demand away from the EPYC side? It doesn't seem to have slowed you down much this year. You're still up by my math, maybe 33% or so. And how are you thinking about that kind of CPU versus GPU dynamic from a customer spend perspective as we look into '25?
Dr. Lisa Su: Yes. Sure. Let me talk a little bit about the Data Center CPU business. Look, we've been extremely pleased with the progress there. I think the market environment has certainly gotten better over the last couple of quarters. We've seen some of the large cloud customers now sort of adding to their data center capacity and refreshes. We've seen enterprises also start with some of their modernization activities. Within that sort of market environment, our product portfolio has done extremely well. So, here in the third quarter, the Zen 4 portfolio between Genoa and Bergamo was very strong. We saw the beginning ramp of our Zen 5 Turin capabilities. And then we also actually saw pretty good demand even on Zen 3 or our Milan family just given the performance of price ratios there. So overall, we have a very strong top to bottom stack, and we do see some strength in the overall server market, which adds to some of the AI opportunity that we have.
Operator: And the next question comes from the line of Ben Reitzes with Melius Research. Please proceed with your question.
Ben Reitzes: Yes. If I could stick to the pattern of two. I want to follow up a little bit on servers and thanks for the question. Going to next year, it seems like you're poised for more share gains. And I was just wondering there is a perception that GPUs are cannibalizing the servers. But what are you seeing specifically in Turin? Is it -- with this momentum that you're talking about, is it the right CPU for a GPU are hyperscalers in particular liking the fact you can consolidate and create more room for AI gear? What is the particular catalyst? And what that you're seeing out there with this upgrade?
Dr. Lisa Su: Sure, Ben. So, I think when I look at Turin and the environment going into 2025, Turin is actually very well optimized for sort of the broad set of server workloads or traditional CPU workloads, including both scale-up and scale-out workloads. So, I think that is very positive. We believe that there will be strong AI content on CPUs, and that helps Turin as well. It's also an important piece of the head node of any GPU configuration. So overall, I think those are all good catalyst for us. And primarily, we're at this point where we're expanding the workloads in general as we are working with our largest cloud customers, and we're making strong progress in Enterprise, which has been very important for us. The Enterprise sale takes longer. There's a significant amount of POC work and just making sure that CIOs are familiar with our offerings. But I think between our Zen 4, Zen 5 offerings now we really have a very broad portfolio that satisfies the vast majority of the traditional CPU workloads.
Ben Reitzes: Okay. And then I just want to follow up on the PC market. There's -- just you guys keep outperforming, but there's just general concerns that -- of consumer weakness. And I was just wondering what you're seeing in the 4Q and is there a risk of more than seasonal decline in the 1Q? Or do you feel like things will keep going unabated in the PC market for you guys, particularly?
Dr. Lisa Su: Well, we see a few things in the PC market. So, our business tends to be more consumer weighted. So, the second half of the year is usually stronger than the first half of the year. And this year, that's added to the fact that we have a couple of product launches. So, we launched our desktop products for -- with Zen 5 and our Ryzen 9000 series. And we also launched our AI PC next-generation Ryzen AI 300 products. So, I think the combination of those two have given us, let's call it, a stronger than the normal second half of the year. I would expect there will be seasonality going into the first half. That's typical in our business. I think the main point is, I mean, this is the strongest PC portfolio we've had sort of in our history, I think, across desktop and notebook. And as we go into 2025, I think there's generally some optimism about the PC market, let's call it, maybe growing mid-single digits. And within that, we have the AI PC catalyst as well as some of the Windows 10 sort of end of support coming in 2025 as catalysts. So, I think we feel good about the PC market in 2025, but we would expect some level of seasonality going into the first half of the year.
Operator: And the next question comes from the line of Joshua Buchalter with TD Cowen & Company. Please proceed with your question.
Joshua Buchalter: I'll keep it to one since I'm new here. On the Data Center GPU side, I realize everyone wants new customer announcements and 2025 guidance, but we're not going to get that, certainly not today. That maybe you could speak to how much of a runway you think exists at existing customers? And how much of a catalyst MI325X on CDNA3 and then MI355 on the new architecture can be to growing revenue and workload breadth internally and externally at these existing customers as we think about growth into next year at the Data Center GPU side?
Dr. Lisa Su: Yes. Sure, Joshua. Thanks for the question. So, look, maybe let me start again with this notion of we're very pleased with the progress that we've made in the Data Center GPU business. I mean, if you think about when we started the year, we were just launching MI300. We had talked about perhaps $2 billion of revenue in 2024. And as we've gone through the last few quarters, what we've done is we've successfully completed a number of customer milestones. And those customer milestones include things like ensuring that we are at scale in data centers, meeting all of the reliability requirements and so on and so forth as well as optimizing on specific workloads and ensuring that we have very, very performant -- out-of-the-box performance. So, I think we have gained a lot of confidence over the last couple of quarters, just seeing how the customers have ramped. I know everyone would like it to go faster. We think it's actually going really well. And being able to talk about exceeding $5 billion of revenue in 2024, I think we feel really good about that. Going into 2025, we feel great about the market. The market continues to be the place where there's a significant CapEx investment. We feel great about our product portfolio. It is getting stronger with everything that we've learned off of the MI300 ramp. And then in particular, on the software side, we have greatly increased our customer support, customer engagements, out-of-box performance, open-source ecosystem, all of those components that are necessary to ensure that customers can run at scale, at performance at a great TCO. So, all those together, I think we have a good opportunity to grow at our current customers with the number of workloads. You heard Meta talking at our event about expanding from inference on their large language models with Llama 3.1 to some training workloads. Microsoft has also been a very, very great partner with that. And then you should assume that we are working with all the large customers out there, and many of them are very deep engagements with us to continue to optimize their software to our hardware. So, those are the opportunities in front of us.
Joshua Buchalter: And congrats on an amazing decade at AMD.
Operator: And the next question comes from the line of Timothy Arcuri with UBS. Please proceed with your question.
Timothy Arcuri: I had a quick one and then a more intensive question. So, the first one is I wanted to ask about the September actuals for Data Center GPU. It seems like it was in the $1.5 billion range. And that would put December in kind of the $2 billion range. Is that about, right?
Dr. Lisa Su: So, it's a pretty granular question, Timothy. But maybe let me help you with this. We actually did better in the Data Center GPU business relative to our initial expectations. So, you would imagine that the business was actually greater than $1.5 billion. I mean we're actually seeing now our GPU business really approaching the scale of our CPU business.
Timothy Arcuri: Great. And then just kind of more broadly on the shape of next year. I mean you see that the market with these big customers, how do you see the shape of revenue off of that Q4 number? Can you continue to grow off that level? Or do you see some risk maybe of a pause next year? And I ask because MI355 is dropping into the existing infrastructure, and I think you did say you'll have a liquid cooled option, but you do hear about some customers wanting rack scale. So, I wonder if you worry a bit about there could be a pause before you get to rack scale in 2026.
Dr. Lisa Su: Yes. I guess I would put it like this. I mean, look, this business is -- there's a lot of activity going on, and we're spending time with customers as they're building out their data centers, some preferred air-cooled environments, liquid cooled environments, some want rack scale, some are perfectly happy to go into their existing data center infrastructure. So, there are lots of different variants. What I would say about 2025 is we feel very good about the growth opportunities I would say that it might be lumpy. In general, these are large customer acquisitions and it's not always predictable exactly which quarters you would expect the significant build out. But I think overall, we feel good about the trajectory into 2025. That's helpful.
Operator: The next question comes from the line of Joe Moore with Morgan Stanley. Please proceed with your question.
Joe Moore: I wonder if you could talk about the $5 billion of AI revenue, how that breaks down between training and inference, if you're able to assess that and just I know you sort of started off with most of the traction in inference, but you've seen some traction on the training side. Can you just talk about what that split looks like going forward as well?
Dr. Lisa Su: Sure, Joe. So certainly, from the $5 billion that we're talking about, the early traction has been primarily with inference just given the strength of the product portfolio. MI300 is like very, very well optimized for inference given the memory capacity and memory bandwidth capabilities. But we have had some training adoption, and we expect that, that will continue to grow as we go through the next few quarters. And so, as we -- let's call it fast forward a year, I would say we would have a fairly balanced portfolio between training and inference.
Operator: And the next question comes from the line of Vivek Arya with Bank of America Securities. Please proceed with your question.
Vivek Arya: I had two. So, Lisa, for the first one, how do you address this investor argument that MI is off to a great start, but spec-wise, remains kind of one year behind the industry leader, right? You're shipping something comparable to Hopper while they are starting to ship Blackwell next year when you are at MI350, they will be on Blackwell Ultra or Rubin. So how do you see AMD closing that gap? And can you really gain share until that gap is closed?
Dr. Lisa Su: Yes. Vivek, I actually don't see that. So maybe let me state it in another way. I think MI300, when we launched it was behind H100, H100 was in the market for a longer time. And we have with our accelerated road map actually closed a good part of that gap. I think MI325 is a great product. It's going to compete very well with H200 and the MI350 series will compete very well with Blackwell. In the overarching view of the world, frankly, the market -- the market continues to be constrained, particularly in the newer product generations. It takes a long time to go from, let's call it, shipping your first samples to actually ramping in volume production workloads. And I think one of the advantages that we have with the -- with our portfolio is that from a data center retrofit standpoint, it's actually a much easier ramp, just the infrastructure is the same. So, look, there are lots of opportunities across the set of AI workloads. We think this road map is actually strengthening over time, and that's the feedback that we're getting from our customers.
Vivek Arya: And for my follow-up, Lisa, back to the question on the PC market. So, it was up -- or the client was up 26% sequentially. I think you are guiding to some growth in Q4 as well. How do you see the state of the channel? And I ask that just because sell-through in Q3 was not that great. And I think Intel had guided down their Q3 to be flat or down. So just how much of the growth that you are seeing is because of ASPs? How much of this is units? And as you look out to 2025, do you think the ASP strength that we have seen this year, can that mix benefit continue for you in '25 also?
Dr. Lisa Su: Yes. Vivek, the way I would say it is our client business has a few factors that may be slightly different from the overall market. So let me start with our desktop channel. I think our share is very high in the desktop channel. And we've done very well there. So, we saw strength across that portfolio in Q3. We actually saw some of our highest sell-through, so it was a strong sell-through quarter. And obviously, it shows in the revenue results. I think on the notebook standpoint, our business tends to be more heavily consumer weighted and so that is more of a second half story. There is good momentum around AI PCs. I mean we've looked at some of the activation rates of our newest risen AI300 processors and the activation rates are good. It's still very early in the AI PC cycle, but we are seeing some good momentum there. So, I think we'll see both units up and the ASPs will depend a little bit on the mix between Consumer and Enterprise and Desktop and Notebooks. But my earlier comment about the Client segment, I think it is an opportunity for us. We are underrepresented in the Client segment. And we see an opportunity to grow both in consumer as well as Enterprise.
Operator: And the next question comes from the line of Harlan Sur with JPMorgan. Please proceed with your question.
Harlan Sur: Lisa, on your core EPYC business, you did start to see recovery in Enterprise last quarter. It was broad-based across many verticals. You've also got a growing share dynamic as well, right? And it sounds like that trend continued in the September quarter. Do you anticipate continued follow-through in terms of quarter-on-quarter growth this quarter for Enterprise? And then maybe what sort of Enterprise and general cloud demand trends are you seeing out of China?
Dr. Lisa Su: Sure. So, Harlan, thanks for the question. We did see positive growth momentum here in the third quarter in Enterprise. We are getting broader adoption and we're seeing that growth both in on-prem deployments as well as cloud third-party deployments. And so, we're very happy with sort of the adoption of our cloud instances when people are doing migrations, they're migrating from on-prem to cloud, they're migrating to AMD or they're migrating from older cloud instances to newer cloud instances. We're seeing migrations to AMD. So, I think that helps us in both the Enterprise segment as well as the Cloud segment. As we go forward into the fourth quarter, I think we are expecting another quarter of growth on a sequential basis for our Server business and strength in both Enterprise and Cloud. And I think as we think about our opportunities going forward, the Enterprise business is a place where we have been underrepresented. I think our portfolio has strengthened. So, the platforms that are being offered by the OEMs have broadened with not just Zen 4, but also with the Zen 5 portfolio launch. And so, I think those are opportunities for us in 2025.
Jean Hu: Yes. On your China question, we are underrepresented in China market in the service side. So as Lisa said, that's another opportunity for us to continue to gain share.
Operator: And the next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed with your question.
Stacy Rasgon: For the first one, I wanted to go back to what you said about the size of the Data Center GPUs in the quarter. You said it was approaching the size of your compute business which you put around what under $1.7 billion, maybe a little more. And number, is that right? And like if that is right, it implies that at $5 billion for the year, you'd actually be down in Q4. So, I'd probably got to be $5.2 billion or $5.3 billion for the full year, just to be flat sequentially and more than that to get growth. So, I guess the question is number one, is that the size of the business that you're talking about in Q3? And is that the kind of level of growth you're thinking into Q4? Like how should we think about that?
Dr. Lisa Su: Right, Stacy. So first, a couple of things. You have to remember that in our Data Center segment, we have some other revenue that is not CPUs and GPUs, right? We have some FPGAs and other things. But the question earlier was the revenue of $1.5 billion, and I said that it was greater than $1.5 billion. So, take that as a fundamental. And then as -- we talked about -- we didn't guide an exact number for the data center GPU. We said exceed $5 billion. And so, you should assume that it exceeds $5 billion.
Stacy Rasgon: Okay. For my follow-up, you talked a little bit about lumpiness next year, is there any kind of seasonality or something that I to be thinking about specifically into Q1 for Data Center GPU? I know you have like the MI300, I guess, ramping into production at that point. But should I be thinking about a seasonal -- like seasonality into Q1 given the general statement on lumpiness?
Dr. Lisa Su: I wasn't implying something about seasonality of the Data Center GPU business. I was implying more that if you think about the evolution of the business, it depends quite a bit on a specific number of customers. So, these are large customers that drive deployments. Like for example, the third quarter was a bit higher than we expected. That was driven by some additional customer demand, and we may see that type of lumpiness. So that was what I was implying. And we'll have to see how things evolve as we get into 2025.
Operator: We have time for two more questions. The next question comes from the line of Harsh Kumar with Piper Sandler. Please proceed with your question.
Harsh Kumar: Lisa, first of all, congratulations on your 10-year anniversary. I just looked at the 10-year chart, the stock is around $3, so a heck of a job here. And also, congratulations on $5 billion in Instinct revenues. So, I wanted to ask the first question. This is one we get from investors all the time. In the coming year, let's say, 2025, your key competitor will take most of the TAM of the AI market, the GPU market, rough count, they'll take in something like $50 billion, $60 billion, you'll get another $5 billion to $10 billion, call it. So, the question is, what do you think is the major hindrance? You've got chip level compatibility. So does it boil down to the fact that you're just earlier in the game. You've been doing this just 12 months in a serious manner? Or is there still a rack level of disparity? If you could just help us, think about what the hindrances are to you becoming a major player here.
Dr. Lisa Su: Yes. Sure, Harsh. Thanks for the question and for the comments. Maybe let me say, I view them as opportunities. If you remember, Harsh, and I think you do, our EPYC ramp from Zen 1, Zen 2, Zen 3, Zen 4 we had extremely good product even back in the Rome days, but it does take time to ensure that there is trust built, there is familiarity with the product that there are some differences, although we're both GPUs. There are some differences, obviously, in the software environment. And people want to get comfortable with the workload ramp. So, from a ramp standpoint, I'm actually very positive on the ramp rate. It's the fastest product ramp that I've seen overall. And my view is this is a multi-generational journey. We've always said that. We feel very good about the progress I think next year is going to be about expanding both customer set as well as workload. And as we get into the MI400 series, we think it's an exceptional product. So -- all in all, the ramp is going well, and we will continue to earn and -- earn the trust and the partnership of these large customers. What I will say is customers are very, very open to AMD. And we see that everywhere we go, everyone is giving us a very fair shot at earning their business, and that's what we intend to do.
Harsh Kumar: Very helpful. Lisa, from a follow-up, and maybe Jean can help out here. It's kind of well understood that your gross margin for MI300, MI325 will be below corporate margins. Could you help us maybe think of some framework on how those gross margins for Instinct might get to parity with your corporate business? I know you probably won't give us a revenue level or a time frame, but maybe you could help us frame in some manner that we could try and understand it.
Jean Hu: Yes. We are very pleased with our overall revenue ramp of our Data Center GPU business, and our team not only support the revenue ramp and continue to improve the gross margin. Overall, it's below corporate average. And when you think about it going into next year, of course, our top priority right now is to really focus on to address customer demand and provide the TCO benefit really increase significantly our market presence and drive substantial revenue growth. On the gross margin side, once we continue to ramp the revenue, we do think we'll have the opportunity to continue to improve gross margin. When you think about it, this is the data center business, over the -- in the longer run, longer term, it tends to be better than corporate average. We'll take some time to get there. But when you look at our Data Center segment performance, we more than doubled the revenue year-over-year, but we tripled the operating income year-over-year. So, I think that's how we are thinking about it is really to drive the long-term growth and get the market presence at the same time, drive gross margin up.
Operator: And our final question comes from the line of Thomas O'Malley with Barclays. Please proceed with your question.
Thomas James: Lisa, I just wanted to ask on mix the MI300 platform into Q4. Obviously, you're launching the MI325 series. Should we expect a significant contribution the new product in Q4? Or is this a situation in which it's launching late year and most of the impact is into Q1? I guess that's the first one. And then the second one is just if you look into next year, could you talk about where the end markets are and Embedded for Xilinx? You gave some color on Com and a little of industrial there. But just where we're at in terms of starting kind of Q4 and into Q1. Are there any that are outperforming, underperforming? Any color there would be helpful.
Dr. Lisa Su: Absolutely, Tom. So back to your first question in terms of the mix in Q4. We would expect the majority of the mix will still be on MI300. MI325 is going into production late in the quarter, and it will be more of a first quarter ramp. So that's that question. And then in terms of the Embedded business going to 2025, I would say that the trends that we see are similar to what I mentioned for the Q3, Q4 timing. We do expect that we're -- some of the markets will recover, we're expecting that it will be a gradual recovery. So, we see that. And the strength that we see is in some of the Test and Emulation segment, we see some strength, certainly in aerospace and defense. There was a little bit of recovery in automotive that we started to see. We're still waiting for comms and industrial. So, we'll get more visibility on that as we go through sort of the end of this year, but that's what we see currently.
Operator: And at this time, we have reached the end of the question-and-answer session. And now I'd like to turn the floor back over to Mitch Haws for any closing comments.
Mitch Haws: That concludes today's call. Thanks to all of you for joining us today.
Operator: And thank you. That does conclude today's teleconference. We thank you for your participation. You may disconnect your lines at this time.",2024-10-29
AMD,2024,4,2024-Q4-AMD,"Operator: Greetings, and welcome to the AMD Fourth Quarter and Full Year 2024 Conference Call. At this time all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. [Operator Instructions] And as a reminder, this conference is being recorded. It is now my pleasure to introduce to you Matt Ramsey, Vice President of Investor Relations. Thank you, Matt. You may begin.
Matt Ramsey: Thank you, and welcome to AMD's fourth quarter and full year 2024 financial results conference call. By now, you should have had the opportunity to review a copy of our earnings press release and accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations page of amd.com. We will refer primarily to non-GAAP financial measures during today's call. The full non-GAAP to GAAP reconciliations are available in today's press release and slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and Chief Executive Officer; and Jean Hu, our Executive Vice President and Chief Financial Officer and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Jean Hu will attend the Morgan Stanley Global TMT Conference on Monday, March 3. Today's discussion contains forward-looking statements based on our current beliefs, assumptions and expectations, speak only as of today and as such, involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause our actual results to differ materially. With that, I will hand the call over to Lisa. Lisa?
Lisa Su: Thank you, Matt, and good afternoon to all those listening today. 2024 was a transformative year for AMD. We successfully established our multi-billion dollar data center AI franchise. Launched a broad set of leadership products and gained significant server and PC market share. As a result, we delivered record annual revenue, grew net income 26% for the year and more than doubled free cash flow from 2023. Importantly, the data center segment contributed roughly 50% of annual revenue, as Instinct and EPYC processor adoption expanded significantly with cloud, enterprise and supercomputing customers. Looking at our financial results. Fourth quarter revenue increased 24% year-over-year to a record $7.7 billion, led by record quarterly data center and client segment revenue both of which grew by a significant double-digit percentage. On a full year basis, annual revenue grew 14% to $25.8 billion as data center revenue nearly doubled and client segment revenue grew 52%, more than offsetting declines in our Gaming and Embedded segments. Turning to the segments. Data center segment revenue increased 69% year-over-year to a record $3.9 billion. 2024 marks another major inflection point for our server business, as share gains accelerated, driven by the ramp of fifth-gen EPYC Turin and strong double-digit percentage year-over-year growth in fourth-gen EPYC sales. In cloud, we exited 2024 with well over 50% share at the majority of our largest hyperscale customers. Hyperscaler demand for EPYC CPUs was very strong, driven by expanded deployments powering both their internal compute infrastructure and online services. Public cloud demand was also very strong with a number of EPYC instances increasing 27% in 2024 to more than 1,000. AWS, Alibaba, Google, Microsoft and Tencent launched more than 100 AMD general purpose in AI instances in the fourth quarter alone. This includes new Azure instances powered by a custom-built EPYC processor with HBM memory that delivers leadership HPC performance based on offering 8x higher memory bandwidth compared to competitive offerings. We also built significant momentum with Forbes 2000 Global Businesses using EPYC in the cloud, as enterprise customers activated more than double the number of EPYC cloud instances from the prior quarter. This capped-off a strong year of growth as enterprise consumption of EPYC in the cloud nearly tripled from 2023. Turning to enterprise on-prem adoption. EPYC CPU sales grew by a strong double-digit percentage year-over-year, as sales grew increased, and we closed high-volume deployments with Akamai, Hitachi, LG, ServiceNow, Verizon, Visa and others. We are seeing growing enterprise pull based on the expanding number of EPYC platforms available and our increased go-to-market investments. Exiting 2024, there are more than 450 EPYC platforms available from the leading server OEMs and ODMs, including more than 120 Turin platforms that went into production in the fourth quarter from Cisco, Dell, HPE, Lenovo, Super Micro and others. Looking forward, Turin is clearly the best server processor in the world with more than 540 performance records across a broad range of industry standard benchmarks. At the same time, we are seeing sustained demand for both fourth and third gen-EPYC processors as our consistent road map execution has made AMD the dependable and safe choice. As a result, we see clear growth opportunities in 2025 across both cloud and enterprise based on our full portfolio of EPYC processors, optimized for leadership performance across the entire range of data center workloads and system price points. Turning to our data center AI business. 2024 was an outstanding year, as we accelerated our AI hardware road map to deliver an annual cadence of new Instinct accelerators, expanded our ROCm software suite with significant uplifts in inferencing and training performance, built strong customer relationships with key industry leaders and delivered greater than $5 billion of data center AI revenue for the year. Looking at the fourth quarter, MI300X production deployments expanded with our largest cloud partners. Meta exclusively used MI300X to serve their Llama 405B frontier model on meta.ai and added instinct GPUs to its OCP-compliant Grand Teton platform, designed for deep learning recommendation models and large-scale AI inferencing workloads. Microsoft is using MI300X to power multiple GPT 4-based Copilot services, and launched flagship instances that scale up to thousands of GPUs for AI training and inference and HPC workloads. IBM, Digital Ocean, [Vulture] (ph) and several other AI-focused CSPs have begun deploying AMD Instinct accelerators for new instances. IBM also announced plans to enable MI300X on their Watson X AI and data platform for training and deploying enterprise-ready generative AI applications. Instinct platforms are currently being deployed across more than a dozen CSPs globally, and we expect this number to grow in 2025. For enterprise customers, more than 25 MI300 series platforms are in production with the largest OEMs and ODMs. To simplify and accelerate enterprise adoption of AMD Instinct platforms, Dell began offering MI300X as a part of their AI factory solution suite and is providing multiple ready-to-deploy containers via the Dell Enterprise Hub on hugging face. HPC adoption also grew in the quarter. AMD now powers five of the 10 fastest and 15 of the 25 most energy efficient systems in the world, on the latest top 500 supercomputer list. Notably, the El Capitan system at Lawrence Livermore National Labs, debuted as the world's fastest supercomputer, using over 44,000 MI300 AI APUs to deliver more than 1.7 exaflops of compute performance. Earlier this month, the high-performance computer center at the University of Stuttgart, launched the Hunter supercomputer that also uses MI300A. Like El Capitan, Hunter will be used for both foundational scientific research and advanced AI projects, including training LOMs in 24 different European languages. On the AI software front, we made significant progress across all layers of the ROCm stack in 2024. Our strategy is to establish AMD ROCm as the industry's leading open software stack for AI, providing developers with greater choice and accelerating the pace of industry innovation. More than 1 million models on hugging face now run out of the box on AMD. And our platforms are supported in the leading frameworks like PyTorch and JAX, serving solutions like VLLM and compilers like OpenAI Triton. We have also successfully ramped large-scale production deployments with numerous customers using ROCm, including our lead hyperscale partners. We ended the year with the release of ROCm 6.3 that included multiple performance optimizations, including support for the latest flash attention algorithm that runs up to 3 times faster than prior versions and SG Lang run time that enabled day-zero support for state-of-the-art models like DeepSeek V3. As a result of these latest enhancements, MI300X inferencing performance has increased 2.7 times since launch. Looking forward, we're continuing to accelerate our software investments to improve the out-of-the-box experience for a growing number of customers adopting Instinct to power their diverse AI workloads. For example, in January we began delivering biweekly container releases that provide more frequent performance and feature updates and ready to deploy packages, and we continue adding resources dedicated to the open source community that enable us to build, test and launch new software enhancements at a faster pace. On the product front, we began volume production of MI325X in the fourth quarter. The production ramp is progressing very well to support new customer wins. MI325 is well-positioned in market, delivering significant performance and TCO advantages compared to competitive offerings. We have also made significant progress with a number of customers adopting AMD Instinct. For example, we recently closed several large wins with MI300 and MI325 at Lighthouse AI customers that are deploying instinct at scale across both their inferencing and training production environments for the first time. Looking ahead, our next-generation MI350 series featuring our CDNA 4 architecture is looking very strong. CDNA 4 will deliver the biggest generational leap in AI performance in our history, with a 35 times increase in AI compute performance compared to CDNA 3. The silicon has come up really well. We were running large-scale LLMs within 24 hours of receiving first silicon and validation work is progressing ahead of schedule. The customer feedback on MI350 series has been strong, driving deeper and broader customer engagements with both existing and net new hyperscale customers in preparation for at-scale MI350 deployments. Based on early silicon progress and the strong customer interest in the MI350 series, we now plan to sample lead customers this quarter and are on track to accelerate production shipments to mid-year. As we look forward into our multiyear AMD Instinct road map, I'm excited to share that MI400 series development is also progressing very well. The CDNA next architecture takes another major leap enabling powerful rackscale solutions that tightly integrate networking CPU and GPU capabilities at the silicon level to support Instinct solutions at data center scale. We designed CDNA next to deliver leadership AI and HPC flops while expanding our memory capacity and bandwidth advantages and supporting an open ecosystem of scale up and scale out networking products. We are seeing strong customer interest in the MI400 series for large-scale training and inference deployments and remain on track to launch in 2026. Turning to our acquisition of ZTE Systems. We passed key milestones in the quarter and received unconditional regulatory approvals in multiple jurisdictions, including Japan, Singapore and Taiwan. Cloud and OEM customer response to the acquisition has been very positive, as ZTE's Systems expertise can accelerate time to market for future Instinct accelerator platforms. We have also received significant interest in ZTE's manufacturing business. We expect to successfully divest ZTE's industry-leading U.S.-based data center infrastructure production capabilities, shortly after we closed the acquisition, which remains on track for the first half of the year. Turning to our client segment. Revenue increased 58% year-over-year to a record $2.3 billion. We gained client revenue share for the fourth straight quarter, driven by significantly higher demand for both Ryzen desktop and mobile processors. We had record desktop channel sell-out in the fourth quarter in multiple regions, as Ryzen dominated the best-selling CPU list at many retailers globally. Exceeding 70% share at Amazon, Newegg, [MineFactory] (ph) and numerous others over the holiday period. In mobile, we believe we had a record OEM PC sell-through share in the fourth quarter as Ryzen AI 300 Series notebooks ramp. In addition to growing share with our existing PC partners, we were very excited to announce a new strategic collaboration with Dell that marks the first time they will offer a full portfolio of commercial PCs powered by Ryzen Pro processors. The initial wave of Ryzen-powered Dell commercial notebooks is planned to launch this spring with the full portfolio ramping in the second half of the year, as we focus on growing commercial PC share. At CES, we expanded our Ryzen portfolio with the launch of 22 new mobile processors that deliver leadership compute, graphics and AI capabilities. Our Ryzen processor portfolio has never been stronger with leadership compute performance across the stack. For AI PCs, we are the only provider that offers a complete portfolio of CPUs, enabling Windows Copilot plus experiences on premium ultrathin, commercial, gaming and mainstream notebooks. Looking into 2025, we are planning for the PC TAM to grow by a mid-single-digit percentage year-on-year. Based on the breadth of our leadership client CPU portfolio and strong design win momentum, we believe we can grow client segment revenue well ahead of the market. Now turning to our Gaming segment. Revenue declined 59% year-over-year to $563 million. Semi-custom sales declined as expected as Microsoft and Sony focused on reducing channel inventory. Overall, this console generation has been very strong. Highlighted by cumulative unit shipments surpassing $100 million in the fourth quarter. Looking forward, we believe channel inventories have now normalized and semi-custom sales will return to more historical patterns in 2025. In Gaming Graphics, revenue declined year-over-year, as we accelerated channel sellout in preparation for the launch of our next-gen Radeon 9000 series GPUs. Our focus with this generation is to address the highest volume portion of the enthusiast gaming market with our new RDNA 4 architecture. RDNA 4 delivers significantly better rate tracing performance and add support for AI-powered upscaling technology that will bring high-quality 4K gaming to mainstream players when the first Radeon 9070 series GPUs go on sale in early March. Now turning to our Embedded segment. Fourth quarter revenue decreased 13% year-over-year to $923 million. The demand environment remains mixed, with the overall market recovering slower than expected as strength in aerospace and defense and test and emulation is offset by softness in the industrial and communications markets. We continue expanding our adaptive computing portfolio in the quarter with differentiated solutions for key markets. We launched our Versal RF series with industry-leading compute performance for aerospace and defense markets, introduced our Versal premium series Gen 2, as the industry's first adaptive compute devices supporting CXL 3.1 and PCI Gen 6 and began shipping our next-gen Alveo card with leadership performance for ultra-low latency trading. We believe we gained adaptive computing share in 2024 and are well-positioned for ongoing share gains based on our design win momentum. We closed a record $14 billion of design wins in 2024, up more than 25% year-over-year, as customer adoption of our industry-leading adaptive computing platforms expands and we won large new embedded processor designs. In summary, we ended 2024 with significant momentum, delivering record quarterly and full-year revenue. EPYC and Ryzen processor share gains grew throughout the year, and we are well-positioned to continue outgrowing the market based on having the strongest CPU portfolio in our history. We established our multibillion-dollar data center AI business and accelerated both our Instinct hardware and ROCm software road maps. For 2025, we expect the demand environment to strengthen across all of our businesses, driving strong growth in our data center and client businesses and modest increases in our gaming and Embedded businesses. Against this backdrop, we believe we can deliver strong double-digit percentage revenue and EPS growth year-over-year. Looking further ahead, the recent announcements of significant AI infrastructure investments like Stargate, and latest model breakthroughs from DeepSeek and the Allen Institute highlight the incredibly rapid pace of AI innovation across every layer of the stack, from silicon to algorithms to models, systems and applications. These are exactly the types of advances we want to see as the industry invests in increased compute capacity, while pushing the envelope on software innovation to make AI more accessible and enable breakthrough generative and agentic AI experiences that can run on virtually every digital device. All of these initiatives require massive amounts of new compute and create unprecedented growth opportunities for AMD across our businesses. AMD is the only provider with the breadth of products and software expertise needed to power AI from end-to-end across data center, edge and client devices. We have made outstanding progress building the foundational product, technology and customer relationships needed to capture a meaningful portion of this market. And we believe this places AMD on a steep long-term growth trajectory, led by the rapid scaling of our data center AI franchise for more than $5 billion of revenue in 2024 to tens of billions of dollars of annual revenue over the coming years. Now I'd like to turn the call over to Jean to provide some additional color on our fourth quarter and full year results. Jean?
Jean Hu: Thank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the first quarter of fiscal 2025. AMD executed very well in 2024, delivering record revenue of $25.8 billion, up 14%, driven by 94% growth in our data center segment and a 52% growth in our client segment, which more than offset headwinds in our gaming and embedded segments. We expanded gross margin by 300 basis points and achieved earnings per share growth of 25% while investing aggressively in AI to fuel our future growth. For the fourth quarter of 2024, Revenue was a record $7.7 billion, growing 24% year-over-year as strong revenue growth in the data center and client segment was partially offset by lower revenue in our gaming and embedded segments. Revenue was up 12% sequentially, primarily driven by the growth of client, data center and the gaming segments. Gross margin was 54%, up 330 basis points year-over-year due to a favorable shift in revenue mix with higher data center and client revenues lower gaming revenue, partially offset by the impact of lower embedded revenue. Operating expenses were $2.1 billion, an increase of 23% year-over-year, as we invest in R&D and marketing activities to address our significant growth opportunities. Operating income was a record of $2 billion, representing 26% operating margin. Taxes, interest and other was $249 million net expense. For the fourth quarter of 2024 diluted earnings per share was $1.09, an increase of 42% year-over-year, reflecting the significant operating leverage of our business model. Now turning to our reportable segment, starting with the data center segment. Revenue was a record of $3.9 billion, up 69% year-over-year driven by strong growth, both AMD Instinct GPU and the fourth and the fifth generation AMD EPYC CPU sales. Data Center segment operating income was $1.2 billion or 30% of revenue compared to $666 million or 29% a year ago. Client segment revenue was a record of $2.3 billion, up 58% year-over-year, driven by strong demand for AMD Ryzen processors. Client segment operating income was $446 million or 19% of revenue compared to operating income of $55 million or 4% of revenue a year ago, driven primarily by operating leverage due from higher revenue. Gaming segment revenue was $563 million, down 59% year-over-year, primarily due to a decrease in semi customer revenue. Gaming segment operating income was $50 million or 9% of revenue compared to $224 million or 16% a year ago. Embedded segment revenue was $923 million, down 13% year-over-year, as end market demand continues to be mixed. Embedded segment operating income was $362 million or 39% of revenue compared to $461 million or 44% a year ago. Turning to the balance sheet and cash flow. During the quarter, we generated $1.3 billion in cash from operations and a record $1.1 billion for free cash flow. Inventory increased sequentially by $360 million to $5.7 billion. In the end of the quarter, cash, cash equivalent and short-term investments were $5.1 billion. In the fourth quarter, we repurchased 1.8 million shares and returned 256 million to shareholders. For the year, we repurchased 5.9 million shares and returned 862 million to shareholders. We have a $4.7 billion remaining in our share repurchase authorization. Before I turn to our financial outlook, let me cover our financial segment reporting. Beginning with our first quarter fiscal year 2025 financial statement disclosures. We plan to combine the client and the gaming segment into one single reportable segment to align with how we manage the business. Therefore, reporting three segments: data center, client with gaming and the embedded. We'll continue to provide distinct revenue disclosures for our data center, client, gaming and embedded businesses, consistent with our current reporting. Now turning to our first quarter of 2025 outlook. We expect revenue to be approximately $7.1 billion plus or minus $300 million, up 30% year-over-year, driven by strong growth in our data center and the client business. More than offsetting a significant decline in our gaming business and a modest decline in our embedded business. We expect revenue to be down sequentially approximately 7%, driven primarily by seasonality across our businesses. In addition, we expect first quarter non-GAAP gross margin to be approximately 54%. Non-GAAP operating expenses to be approximately $2.1 billion. Non-GAAP other net income to be $24 million, non-GAAP effective tax rate to be 13% and the diluted share count is expected to be approximately 1.64 billion shares. In closing, 2024 was a strong year for AMD, demonstrating our disciplined execution to deliver revenue growth and expand earnings at a faster rate than revenue. All while investing in AI and the innovation to fuel long-term growth. Looking ahead, we will build on the momentum to drive double-digit percentage revenue growth and further accelerated earnings in 2025 and beyond. With that, I'll turn it back to Matt for the Q&A session.
Matt Ramsey: Thank you very much, Jean. We're now ready to start the Q&A session. As the operator pulls for questions, we remind each participant to please ask one question and a brief follow-up. Operator, please poll for questions. Thanks.
Operator: Thank you Matt. We will now be conducting a question-and-answer session. [Operator Instructions]. And the first question comes from the line of Aaron Rakers with Wells Fargo. Please proceed.
Aaron Rakers : Yeah. Thanks for taking the question. I guess I'll just ask it right out of the gate is, as we think about the GPU business, and I appreciate you talked about delivering north of $5 billion of revenue, which is extremely impressive in 2024. I'm curious if you -- how we should think about framing the GPU, the instinct business, as we think about 2025? And any kind of color you can provide us as far as kind of the progression of revenue, the pace of revenue first half versus second half as we think about some of the product cycle dynamics. Thank you.
Lisa Su : Sure, Aaron. Thanks for the question. So first of all, look we were very pleased with how we finished 2024 in terms of the data center GPU business. I think the ramp was steep as we went throughout the year, and the team executed well. Going into 2025, as I mentioned in the prepared remarks, we are actually very happy with the progress that we're making on both the hardware road maps and the software road maps. So on the hardware side, we launched MI325 at the end of the fourth quarter, started shipments then. We have new designs that have come on both MI300 and MI325 that we'll deploy in the first half of the year. And then the big news is on the MI350 series. So we had previously stated that we thought we would launch that in the second half of the year. And frankly, that bring-up has come up better than we expected, and there is very strong customer demand for that. So we are actually going to pull that production ramp into the middle of the year, which improves our relative competitiveness. So as it relates to how data center -- so the overall data center business will grow strong double digits certainly, both the server product line as well as the data center GPU product line will grow strong double digits. And from the shape of the revenue you would expect that the second half would be stronger than the first half, just given MI350 will be a catalyst for the data center GPU business. But overall, I think we are very pleased with the trajectory of the data center business in both 2024 and then going into full year 2025.
Aaron Rakers : Yes. Thank you very much. And as a quick follow-up, just thinking about the guidance overall relative to that down 7% sequential I know you mentioned seasonality across the business segments. Are you assuming that you are down sequentially in data center in total in 1Q? And how do I frame that relative to seasonality? Thank you.
Lisa Su: Yes, sure, Aaron. So let me give you some more color on the Q1 guide. So Q1 guide was down 7% sequentially, as Jean mentioned. And the way that breaks out in each of the segments assume that data center would be down just about that average, so the corporate average. We would expect the client business and the embedded business to be down more than that. Just given where seasonality is for those businesses. And then we would expect gaming business will be down a little less than that. And that's a little atypical from a seasonality standpoint, but we are coming-off of a year when there was a lot of let’s call it, inventory normalization. And now that inventory has normalized, we would expect that, that would be down a little bit less than the corporate average.
Operator: And the next question comes from the line of Timothy Arcuri with UBS. Please proceed with your question.
Timothy Arcuri : Thanks a lot. I wanted to ask about the server CPU business. Jean, I think you have said in the past that core count is going to grow mid-to-high teens. And as long as your competitor is not super aggressive on pricing that your business should grow roughly that much as well. Are you expecting or are you already seeing them become a little more aggressive on pricing as they attempt to shore up their share. It sounds like they're getting a bit more aggressive on pricing. So wondering if you still think that the server CPU business can grow in line with that core kind of mid-to-high teens.
Jean Hu : Yes. First, we always assume server CPU is a very competitive market but we currently have the best lineup portfolio from not only Turin generation, but Genoa and then even Milan, we provide the best TCO for our customers based on the product portfolio. So overall, we are actually quite confident about continuing to drive the server CPU businesses not only growing from a unit perspective, ASP perspective and continue to gain share.
Timothy Arcuri : Thanks a lot. And then, Jean can you just give us a sense of where data center GPU came in for December? I'm thinking it's probably in the $2 billion range. And then is it assumed to be down, flat or up, would you be willing to give a number for March? Thanks.
Jean Hu : Yes. I think the way to look at our Q4 performance is our data center business overall did really well. actually is consistent with our expectations. Of course, when we look at the server and the data center GPU, server did better than data center GPU. But overall, it's very consistent with our performance.
Lisa Su : Yes. Maybe I'll just add, Tim, on your question as to what you would expect as we go into 2025. I think you should assume that the first half of 2025 data center segment will be consistent with the second half of '24. And that's true for both businesses on the server side as well as the data center GPU side.
Operator: And the next question comes from the line of Vivek Arya with Bank of America Securities. Please proceed with your question.
Vivek Arya : Thanks for taking my question. Lisa, a few questions on the data center GPU business. I think last year, AMD was very explicit about setting and beating or meeting expectations. This year, you have not set a specific forecast, and I'm curious what has changed. And then if I go back to your Analyst Day in December, I think at that time, you are sort of long-term 60% CAGR. Is it fair to assume that you can grow at that for '25, right, versus the $5 billion plus that you did last year. So just contrast the two years and then whether AMD can grow at that 60% trendline.
Lisa Su : Sure. So Vivek, thanks for the question. I think what we look at is certainly for the first year of the data center GPU business, we wanted to give some clear progression as it was going. The business is now at scale, actually now at over $5 billion. And as we go into 2025, I think our guidance will be more at the segment level with some color as to some qualitative color as to what's going on between the two businesses. And relative to your question about long-term growth rates, you are absolutely right. I mean I believe that the demand for AI compute is strong. And we've talked about a data center accelerator TAM upwards of $500 billion by the time we get out to 2028. I think all of the recent data points would suggest that there is a strong demand out there. Without guiding for a specific number in 2025, one of the comments that we made is we see this business growing to tens of billions, as we go through the next couple of years. And that gives you a view of the confidence that we have in the business and particularly our road map is getting stronger with each generation, right? So MI300 was a great start. MI350 series is stronger and addresses a broader set of workloads including both inference, as well as training. And then as we get into MI400 series, we see significant traction and excitement around what we can do there with rackscale designs, and address the innovation that's going on there. So yes, we are bullish on the long-term, and we'll certainly give you progress as we go through each quarter in 2025.
Vivek Arya : Thank you, Lisa. And for my follow-up, I would love your perspective on the news from DeepSeek recently, right? And there are kind of two parts to that. One is once you heard the news, do you think that should make us more confident or more conservative about the semiconductor opportunity going forward? Like is there something so disruptive in what they have done, that reduces the overall market opportunity. And then within that, have your views about GPU versus ASIC how that share develops over the next few years? Have those evolved in any way at all? Thank you.
Lisa Su : Yes. Great. Thanks for the question, Vivek. Yes, it's been a pretty exciting first few weeks of the year. I think the DeepSeek announcements, Allen Institute as well as some of the Stargate announcements, talk about just how much the rate and pace of innovation that's happening in the AI world. So specifically relative to DeepSeek. Look, we think that innovation on the models and the algorithms is good for AI adoption. The fact that there are new ways to bring about training and inference capabilities with less infrastructure actually is a good thing because it allows us to continue to deploy AI compute and broader application space and more adoption. I think from our standpoint, we also like very much the fact that – we are big believers in open source. And from that standpoint, having open source models, looking at the rate and pace of adoption there, I think is pretty amazing. And that is how we expect things to go. So to the overall question, of how should we feel about it. I mean, we feel bullish about the overall cycle. And similarly, on some of the infrastructure investments that were announced with open AI and Stargate and building out, let's call it, massive infrastructure for next-generation AI. I think all of those say that AI is certainly on the very steep part of the curve. And as a result we should expect a lot more innovation. And then on the ASIC point, let me address that because I think that is also a place where there is a good amount of discussion. I've always been a believer in you need the right compute for the right workload. And so with AI, given the diversity of workloads, large models, media models, small models, training, inference when you are talking about broad foundational models or very specific models, you're going to need all types of compute. And that includes CPUs, GPUs, ASICs and FPGAs. Relative to our $500 billion plus TAM going out in time, we've always had ASIC as a piece of that. But my belief is, given how much change there is still going on in AI algorithms that ASICs will still be the smaller part of that TAM because it is a more, call it, specific workload optimized, whereas GPUs will enable significant programmability and adjustments to all of these algorithm changes. But when I look at the AMD portfolio, it really is across all of those pieces. So CPUs, GPUs. And we are also involved in a number of ASIC conversations, as well as customers want to really have an overall compute partner.
Operator: And the next question comes from the line of Joshua Buchalter with TD Cowen. Please proceed with your question.
Joshua Buchalter: Hi, guys. Thanks for taking my question. Obviously, it was good to see MI355X pulled into midyear. But I wanted to clarify, you said first half '25 data center GPU likely consistent with second half '24, and I was wondering if you could speak to whether or not the shape of the first half changed over the last few months and is potentially related to this pulled in time line, it could be a potential air pocket ahead of that launch? Or this was sort of consistent with how you saw things playing out as MI350 and MI325X ramps more fully? Thank you.
Lisa Su : Yes. Thanks for the question, Joshua. No, I would say from our standpoint, we've gotten incrementally more positive on the 2025 data center GPU ramp. I think MI350 series was in second half always, but pulling it into midyear is an incremental positive. And from a first half, second half statement, as I mentioned, we have some new important AI design wins that are going to be deployed with and MI300 and MI325 in the first half of the year. But with MI350 series, we end up with more content. I mean it is a more powerful GPU, ASPs go up, and you would expect larger deployments that include training and inference in that time frame. So the shape is similar to what we would have expected before.
Joshua Buchalter: Thank you. And believe it or not, I could ask a question on client. Obviously, the growth number in the fourth quarter, I mean, it was certainly higher than our model. Could you clarify the drivers of the strength across desktop, notebook and enterprise? And how we should think about 1Q, and in particular, to put it bluntly, I mean are you worried at all about inventory buildup, given how much your client revenue has outperformed the broader PC market in the second half of the year? Thank you.
Lisa Su : Yes. Thanks for the question. Our client business performed really well throughout 2024 and Q4 was a very strong quarter. There are a couple of reasons for that. So we should go through that. We don't believe there is some substantial inventory buildup. We actually think that what we're seeing is very strong adoption of our new products. So on the desktop side, we saw our highest sell-out in many years, as we went through the holiday season, launching our new gaming CPUs, frankly, they have been constrained in the market, and we've continued shipping very strongly through the month of January as we are catching up with some demand there. So desktop business was very strong. And on the notebook side, we also saw a number of our OEM partners launching new AI PCs with the slew of new bulk mobile part numbers that we announced at CES. We have our strongest PC portfolio on the mobile side with top to bottom Copilot+ PC compatible products, and those are playing very well into the market. So I think Q4 was strong. I know that there was some commentary about whether there were pull-ins relative to tariffs. We didn't see that in the fourth quarter. I think, as I said, we saw strong sellout. Going into the first quarter, we do expect seasonality in there. But the part of our business that is performing better than seasonality is the desktop portion of the business. And the mobile portion of the business is, let's call it, more typical seasonality. But overall, I think we are very bullish on our prospects to grow clients in 2025. Just given all of the drivers from product portfolio to some of the market dynamics, as well as our new commercial PCs portfolio.
Operator: The next question comes from the line of Harlan Sur with JPMorgan. Please proceed with your question.
Harlan Sur : Hi, good afternoon. Thanks for taking my question. For the fourth quarter, did your overall server CPU business grow double digits sequentially. And as a follow-on to that, I think Q4 was the sixth consecutive quarter of double-digit year-over-year increases for your on-prem service solutions. On a sequential basis, I know you guys did start to see recovery in enterprise in the second quarter of last year, I think it was strongly up sequentially in the third quarter, a pretty broad base. Did enterprise service grow sequentially in Q4? And Lisa how do you see the share prospects in this segment as you step into 2025?
Lisa Su : Yes, Harlan, thanks for the question. So I think as Jean mentioned earlier, so in the fourth quarter, we did see a sequential double-digit growth in our server business. We saw that in both cloud and enterprise. I think the server business has been performing extremely well. We are continuing to grow our cloud footprint with more workloads, as we have the strength of the churn portfolio in addition to Genoa and Milan. And then to your question on enterprise, I do believe we are seeing some strong traction in the enterprise. I think what's helping us there is, frankly, we've invested a lot more in go-to-market and the go-to-market investments are paying-off. The enterprise sales cycle is often a 6-month to 9-month sales cycle. But as we've invested more resources in it throughout 2024, we've seen that convert into a significant number of new POCs that are now converting into volume deployments. And as we go through into 2025, from a competitiveness standpoint, we have a very strong portfolio across every price point, every core count, every workload. So I think, we see a strong 2025 for [server GPUs] (ph).
Harlan Sur : I appreciate that. Networking is a very critical part of the AI infrastructure becoming even more important. There seems to be this misconception that AMD is behind the curve here, you you're keeping pace kind of leveraging the incumbent Ethernet technology, strong installed ecosystem. You guys are spearheading the UltraNET Ethernet Consortium. You've got your Infinity Fabric technology for scale-up connectivity does you continue to drive customer adoption of your overall AI platforms. What's the feedback been like on your AI networking architectures? And any networking-related innovations the team is going to be bringing to the market this year?
Lisa Su : Yes. Thanks, Harlan, for that question. No question. Networking is an extremely important part of the AI solution, and it's an area that we have been investing and spending quite a bit of effort with our customers and our partners jointly. The way to think about it is that our networking proof points are actually increasing as we are going from MI300 to MI325 to MI350 to MI400. So in each of those points, we are increasing with a number of proof points. I think people want to see more clusters of ours. Certainly, on inference, we've shown great performance and total cost of ownership. We are now also have a number of training systems that we are putting on board. And the important part there is the networking. We have worked very closely with our partners on Ethernet. We believe that this is the right technology for the future. In addition to third-party networking solutions, we are also with our Pensando team developing our own in-house AI NIC that Forrest mentioned at our Q4 advancing AI event. And as we look forward, working with our customers, we are actually standing up full rack solutions at both the MI350 level as well as in the MI400 series. So I think the net of it is we believe that, yes, it is absolutely very important. And in addition to all of the hardware and software work, the system level scaling is super important and we are on track to deliver that with our road map.
Operator: And the next question comes from the line of Blayne Curtis with Jefferies. Please proceed with your question.
Blayne Curtis: Hi, thanks for taking my question. Lisa, I just want to follow up the data center GPU business, obviously, very strongly year-over-year, but it seems for your commentary kind of the sequential growth kind of slows for the next kind of three quarters. So I just want to understand the why. Obviously, you have some new products coming. So maybe it's just the shift to the new products. I also want to just ping your brain on in terms of when you look at the ASIC story lines, there tends to be kind of a shift to focus on training versus inference. So just your perspective, I know a lot of your workloads initially were inference. Are you seeing any shift in terms of the demand from your customers between training inference as well?
Lisa Su : Yes. Sure, Blayne. Look, the way I would say it is, we saw a tremendous growth as we build up the data center GPU business throughout 2024. So I think what we're seeing is we are continuing to do new deployments. We're continuing to bring on new customers. Clearly, we are going through a little bit of a product transition time frame in the first-half of the year. But the key is bringing in the MI350 series was very, very important for us and for the customer set. So the fact that, that hardware has come on clean. And we've learned a lot from the initial deployments of MI300, I think, is very positive. And this is as we might expect, given the overall landscape of deployments. And then to the second part of your question, as it relates to ASICs, I really haven't seen a big shift at all in the conversation. I will say that the conversation as it relates to AMD, is kind of the following. People like the work that we've done in inference. But certainly, our customers want to see us as a strong training solution. And that's consistent with what we've said, right? We've said that we have like a step-wise road map to really show each one of those solutions. On the software side, we've invested significantly more in some of those sort of the trading libraries. We talked -- Harlan's question earlier about networking. And then this is about just getting into data centers and ramping up tens of thousands of GPUs. So from my standpoint, I think we are making very good progress there. And I just want to reiterate on the ASIC side, look, I think ASICs are a part of the solution, but there -- I want to remind everyone, they are also a very strong part of the AMD sort of toolbox. So we've done semi-custom solutions for a long-time. We are very involved in a number of ASIC discussions with our customers as well. And what they like to do is, they'd like to take our baseline IP and really innovate on top of that. And that's what I think differentiates our capability is that we do have all of the building blocks of CPUs, GPUs, as well as all of the networking technologies that you would need to put the solutions together.
Matt Ramsey: Operator, I think we have time for two more callers, please.
Operator: Okay. The next question comes from the line of Stacy Rasgon with Bernstein Research. Please proceed.
Stacy Rasgon: Hi, guys. Thanks for taking my questions. I want to ask this a little more explicitly. So you said your server business was up strong double digits sequentially in Q4. My math suggests that could have even meant that the GPU business was down sequentially. And given your guidance for I guess, flattish GPUs in the first half of '25 versus second half of '24. Again, does the math not suggest that you'd be down sequentially both in Q1 and in Q2 to feel like -- Am I doing something wrong with my math? Or like what am I missing here?
Lisa Su : Yes. perhaps Stacy, maybe let me help give you a little bit of color there. I don't think we said strong double-digits. I think we said double digits. So that perhaps is the -- so data center segment was up 9% sequentially. Server was a bit more than that. Data center GPU was a little less than that. I think for some of the models that are out there, you might be a little bit light in the Q3 data center GPU number. So there might be some adjustments that need to be done there. But I think your suggestion would be incorrect. We -- if you just take the halves, second half '24 to first half '25, let's call it roughly flattish, plus or minus. I mean we'll have to see exactly how it goes. But it is going to be a little bit dependent on just when deployments happen. But that's kind of currently what we see.
Stacy Rasgon: Got it. Thanks. And I guess for my follow-up, maybe to follow on there, do you think your exit rate on GPUs in '25 is higher than your exit rate in '24. Are you willing to commit to that?
Lisa Su : Absolutely. But yes, of course. It would be hard to grow strong double digits otherwise, right?
Operator: And the final question comes from the line of Toshiya Hari with Goldman Sachs. Please proceed with your question.
Toshiya Hari: Hi, thank you so much for squeezing me in. Lisa, I had a question on the server CPU business. I'm curious how you're thinking about the market this year? And if you can delineate between cloud and enterprise, that would be really helpful. And then kind of part B to that question. In your prepared remarks, you talked about you all having more than 50% share across the major hyperscalers. How would you characterize the competitive intensity at those customers vis-a-vis some of the internal custom silicon that's expected to ramp over the coming quarters and years?
Lisa Su : Sure, Toshiya. So let me say, as we look into 2025, I think we see a good server market between cloud and enterprise. I think as we went into sort of the early part of '24, there was a little bit of, let's call it, less investments on the CPU side as people were optimizing investments for AI. We saw that sort of pick up in the second half of the year in '24, and we would expect that to go into '25. So the enterprise refresh cycles are coming in again. And certainly, there are a number of cloud vendors that are now, let's call it, reupdating some of their data centers. And then your second question was, as it relates to --.
Toshiya Hari: [Competitive custom silicon] (ph).
Lisa Su : Yes. Look, I think it's about the same. What I would say, Toshiya is, it is less about custom silicon versus x86. It is much more about do you have the right product for the right workload. And look, the server market is always a competitive market. What we've done, and you've seen it in our Zen 4 product line as well as in our Zen 5 product-line. We've expanded the design points for each of the core generation so that we have cloud native and then we have enterprise optimized low core count, high core count, highest performance, best perf per dollar. And I think as we do those things, I think we’re continuing to grow share across both cloud and enterprise. And look, it is always very competitive. We take every design win with very seriously, but we are winning our fair share. And I think that's the strength of the product portfolio. And also, I think there is a good amount of trust for our delivery capability as we've built up our sort of our franchise over the last number of years.
Toshiya Hari: That's great. And then as a quick follow-up, maybe one for Jean. So you're guiding gross margin to 54% in the first quarter. I'm curious what some of the major puts and takes are and those are the things that we should be cognizant of going into Q2 and more importantly, the second half. Given your data center commentary skewed more to the second half, I would expect margins to improve in the second half. But yes, if you can kind of run through the pluses and minuses, that would be really helpful. Thank you.
Jean Hu : Yes. Thanks for the question. You are right. Our gross margin is primarily driven by our revenue mix, I think when you look at looking to 2025, Q1 guide, not only data center continued to grow significantly year-over-year. At the same time, client business is also growing year-over-year. So overall, the revenue mix is quite consistent with the Q4. So the gross margin guide is 54%. I think for the first half, if the revenue mix is at this level, we do feel the gross margin will be consistent with 54%. But going into second half, we do believe the data center is our fastest growth driver for the company and that will drive the gross margin to step up in second half.
Matt Ramsey : All right. With that, I think we are ready to close the call now, operator. I just wanted to say thank you to everybody that listened and participated today and for your interest in AMD. Thank you very much.
Operator: Thank you. And ladies and gentlemen, that does conclude today's teleconference. We thank you for your participation. You may disconnect your lines at this time.",2025-02-04
AMD,2025,1,2025-Q1-AMD,"Operator: Greetings. And welcome to the AMD First Quarter 2025 Conference Call. At this time all participants are in a listen-only mode. A question-and-answer session will follow the formal presentation. [Operator Instructions] And as a reminder, this conference is being recorded. It is now my pleasure to introduce to you Matt Ramsey, Vice President. Financial Strategy and Investor Relations. Thank you, sir. You may begin.
Matt Ramsey: Thank you, and welcome to AMD's 2025 first quarter financial results conference call. By now, you should have had the opportunity to review a copy of our earnings press release and accompanying slides. If you have not had the chance to review these materials, they can be found on the Investor Relations portion of amd.com. We will refer primarily to non-GAAP financial measures during today's call. The full non-GAAP to GAAP reconciliations is available in today's press release and slides posted on our website. Participants in today's conference call are Dr. Lisa Su, our Chair and Chief Executive Officer; and Jean Hu, our Executive Vice President and Chief Financial Officer and Treasurer. This is a live call and will be replayed via webcast on our website. Before we begin, I would like to note that Mark Papermaster, our Executive Vice President and Chief Technology Officer will attend the TD Cowen TMT Conference on Wednesday, May 28. And Jean Hu will attend the Bank of America Global Technology Conference on Tuesday, June 3rd. Today's discussion contains forward-looking statements based on our current beliefs, assumptions and expectations, speak only of today and as such, involve risks and uncertainties that could cause actual results to differ materially from our current expectations. Please refer to the cautionary statement in our press release for more information on factors that could cause our actual results to differ materially. You’ll also find detailed discussion of our risk factors in our filings with the SEC and particular AMD’s most recently quarterly report on Form 10-Q and annual report on Form 10-K. And with that, I’d like to hand the call over to Lisa.
Lisa Su: Thank you, Matt, and good afternoon to all those listening today. We delivered an outstanding start to the year, despite the evolving dynamics related to tariffs and the regulatory environment. Growth accelerated for the fourth consecutive quarter year-over-year, driven by strength in our core businesses and expanding data center and AI momentum. Revenue and EPS both exceeded consensus estimates as Instinct AI Accelerator, Epic, and Ryzen CPU sales grew significantly year-over-year. As a result, first quarter revenue increased 36% year-over-year to $7.4 billion, as our data center and client and gaming segments both grew by a large double-digit percentage. We expanded gross margin year-over-year for the fifth straight quarter and increased net income by 55%, driven by a higher overall percentage of data center product sales and a richer Ryzen processor mix. Despite the uncertain macroeconomic backdrop, our first quarter performance highlights the strength of our differentiated product portfolio and execution, and positions us well for strong growth in 2025. Turning to the segments, data center segment revenue increased 57% year-over-year to $3.7 billion. We gained server CPU share driven by the ramp of our latest fifth-gen EPYC Turin processors and sustained demand for fourth-gen EPYC. Hyperscaler demand remained strong as cloud providers expanded EPYC deployments to power their critical infrastructure and public services. More than 30 new instances launched from Alibaba, AWS, Google, Oracle, Tencent, and others in the quarter, including the initial wave of fifth-gen EPYC Turin instances. In addition, AWS launched new FPGA accelerated instances in the quarter, powered by EPYC processors with Xilinx Virtex FPGAs that are optimized for data and compute intensive workloads like genomics, multimedia processing, network security, and cloud-based video broadcasting. Every major cloud provider is deep in development on Turin programs, with a steady stream of public instances and internal deployments expected to ramp into production over the coming quarters. Enterprise adoption of EPYC instances was very strong in the quarter. The number of EPYC-powered cloud instances activated by Forbes 2000 enterprise customers more than doubled year-over-year, including new wins with internet-native streaming, transportation, financial services, and social media companies. For example, CrowdStrike achieved major performance and cost improvements by broadly deploying EPYC instances across its multi-cloud infrastructure. At the same time, we're also actively partnering with leading application and cloud providers to deploy EPYC-optimized solutions tailored for specialized industry verticals. Siemens launched their latest software-defined vehicle solution, powered by EPYC CPUs and Radeon Pro GPUs on Azure, leveraging digital twin technology to significantly speed up automotive design and validation. Oracle launched a new version of its Exadata database platform, which is used by more than half of the Fortune Global 100. The latest Exadata X11m has been optimized for fifth-gen EPYC processors to deliver up to 25% faster performance in transaction processing and analytics compared to the prior generation. Turning to enterprise on-prem adoption, EPYC CPU sales grew by a large double-digit percentage year-over-year for the seventh straight quarter, driven by new public sector wins and high-volume deployments with large automotive, semiconductor, financial services, retail, energy, and technology companies. We have built significant enterprise momentum over the last few years as our partners expanded the number of EPYC-based platforms to more than 450, and we scaled our joint go-to-market programs. As a result, EPYC is now deployed by all of the top 10 telecom, aerospace, and semiconductor companies, 9 out of the top 10 automotive, 7 out of the top 10 manufacturing, and 6 out of the top 10 energy companies on the Forbes 2000. We expect enterprise adoption to accelerate over the coming quarters as more than 150 Turin platforms become broadly available from Dell, Cisco, HPE, Lenovo, Supermicro, and others. Looking forward, we see a clear path to continued share gains as customers ramp their fifth-gen EPYC offerings that deliver unmatched performance, efficiency, and TCO across every major cloud and enterprise data center workload. We passed key milestones in April to begin manufacturing fifth-gen EPYC at TSMC's new Arizona fab, with first production shipments expected in the second half of 2025. Longer term, we announced our next-gen EPYC Venice processors are the lead HPC products for TSMC's 2-nanometer process node. Venice silicon is in our labs and performing well, with bring-up and validation progressing to plan to support a 2026 launch. Turning to our data center AI business, revenue increased by a significant double-digit percentage year-over-year, as MI325X shipments ramp to support new enterprise and cloud deployments. More than 35 MI300 series platforms are in production from all the leading service providers, supporting the expanding number of Instinct GPU deployments with cloud, enterprise, and AI customers. Several hyperscalers expanded their use of Instinct accelerators to cover an increasing range of generative AI search, ranking, and recommendation use cases. We also added multiple tier one cloud and enterprise customers in the quarter, including one of the largest frontier model developers that is now using Instinct GPUs to serve a significant portion of their daily inference traffic. The depth and breadth of our customer engagements continues to expand as breakthroughs in large-scale AI models, like OpenAI's o3 and DeepSeek-R1, drive increased demand for traditional inferencing and increasingly as a critical part of pre-training. The industry-leading memory capacity and bandwidth of our Instinct portfolio is ideally suited for these workloads, and we are actively working with multiple customers to scale Instinct from single-node deployments to distributed inferencing clusters. Training engagements also ramped in the quarter as multiple tier one hyperscale, AI, and enterprise customers scaled Instinct GPU clusters to train internal and next-gen frontier models. In parallel, we're making meaningful progress with Sovereign AI deployments as countries expand investments to establish domestic, nation-scale AI infrastructure. In February, we announced a strategic partnership with G42 to build one of France's most powerful AI compute facilities powered by Instinct accelerators. On the AI software front, we significantly accelerated our release cadence in the first quarter, shifting from quarterly ROCm updates to delivering ready-to-deploy training and inferencing containers on a bi-weekly basis that include performance optimizations and support for the latest libraries, kernels, and algorithms. We expanded our open-source community enablement in the quarter, making significantly more Instinct compute infrastructure available to enable developers to automatically build, test, and deploy updates to ROCm code nightly. As a result, more than two million models on Hugging Face now run out-of-the-box on AMD. We're also enabling an increasing number of models to launch with day zero support for Instinct accelerators, including Meta's LLAMA 4, Google's GEMMA 3, and DeepSeek-R1 models that were released in the first quarter. Beyond launch, we are delivering regular software updates that increase performance for new models. For example, in the weeks following the launch of DeepSeek-R1 model, we introduced ROCm optimizations that enabled MI300 to deliver leadership inferencing throughput. We released ROCm 6.4 in the quarter with major upgrades that increased training and inferencing performance across popular AI frameworks like PyTorch, JAX, and vLLM. The release also adds multiple ease-of-use features, including new cluster management tools that simplify the scaling and optimization of large-scale Instinct deployments. Turning to our AI solutions capabilities, earlier this quarter, we completed our acquisition of ZT Systems, adding world-class systems design expertise to complement our silicon and software leadership. With ZT, we can provide ready-to-deploy RAC-level AI solutions based on industry standards built with AMD CPUs, GPUs, and networking, reducing deployment time for hyperscalers, and accelerating time-to-market for OEM and ODM partners. The team is fully engaged in already co-designing with key customers on RAC-level designs optimized for our upcoming MI400 series and working with customers and OEM partners to accelerate time-to-market for our MI350 series. We have received significant interest in ZT's manufacturing business and expect to announce a strategic partner shortly. We began sampling our next-gen MI350 series with multiple customers in the first quarter and remain on track to begin accelerated production by mid-year. MI350 series performance is very strong based on the advances in our CDNA 4 Architecture. We designed CDNA 4 to deliver leadership performance across a wide range of AI workloads, increasing memory capacity and bandwidth 1.5x, adding support for new data types, and improving network efficiency to deliver 35x higher throughput and performance compared to MI300X. Customer interest in the MI350 series is very strong, setting the stage for broad deployment in the second half of this year. As one example, we are partnering with Oracle to deploy a large-scale cluster powered by MI355X accelerators, fifth-gen EPYC Turin processors, and Polara 400 AI NIC. This multi-billion-dollar initiative highlights the expanding AMD and OCI partnership and a growing demand for AMD Instinct to power the next wave of large-scale AI infrastructure. Looking ahead, our MI400 series development remains on track to launch next year. The MI400 series is designed to deliver leadership performance for both inferencing and training, scaling seamlessly from single servers to full data center deployments. Early customer feedback has been very positive, marking a major step forward in our Instinct roadmap and significantly expanding our AI Accelerator TAM as customers plan broader Instinct deployments to power a larger share of their AI infrastructure. I'm looking forward to sharing more details on the MI350 series, future MI400 RAC scale solutions and the growing customer adoption of our Instinct platforms at our advancing AI event on June 12th. Turning to our client and gaming segment, segment revenue increased 28% year-over-year to $2.9 billion. Client revenue grew 68% year-over-year marking our fifth consecutive quarter of revenue share gains. We delivered record client CPU ASP driven by a richer mix of high-end desktop and mobile Ryzen processors. Desktop channel sellout increased by more than 50% year-over-year. We set new sellout records in multiple regions as our latest generation Ryzen processors became the CPU of choice for gamers, topping bestseller lists at leading global retailers. To build on this momentum, we extended our desktop CPU portfolio with the launch of our 16-core Ryzen 9 9950 X3D processor that delivers significantly higher gaming and productivity performance than the competition. In mobile, AMD-based notebook sell-through was very strong in the quarter. We also saw strong demand for our latest generation AI PC processors as sales ramped, increasing by more than 50% quarter-on-quarter. The first notebooks powered by our new high-end Ryzen AI Max Plus and the first mainstream Ryzen AI 7 and 5 300 series processors launched to very positive reviews. These new processors set the standard for traditional computing and graphics performance while also delivering unmatched AI capabilities and battery life, positioning Ryzen as a CPU of choice for gaming, ultra-thin, and commercial notebooks. Demand for AMD-based commercial PCs was also very strong in the quarter. Ryzen Pro PC sell-through grew more than 30% year-over-year, driven by new end-customer wins and an 80% increase from 2024 in the number of AMD-powered commercial systems from HP, Lenovo, Dell, and Asus. We closed multiple wins with large auto, energy, healthcare, financial services, and telecom companies in the quarter. Looking more broadly across the PC market, we remain confident we can grow client processor revenue well ahead of the market in 2025, led by expanding adoption of our desktop channel and consumer and commercial notebook portfolio, as well as a richer mix. Turning to our gaming business results, gaming revenue decreased 30% year-over-year, as higher Radeon graphics sales were more than offset by lower semi-custom sales. While our semi-custom SoC sales declined year-over-year, console channel inventories have normalized, and demand signals have strengthened for 2025. For PC gaming, we launched our Radeon 9070 series to strong demand, as our new RDNA 4 Architecture delivers leadership performance for mainstream gamers. First week sellout set a record, and was more than 10x higher than our previous best Radeon launch. Demand remains very strong, and we are working closely with our board partners to replenish inventory weekly and meet the sustained demand. We also introduced FSR 4, our first machine learning-based rendering technology that delivers significantly higher frame rates and more immersive gaming experiences. FSR 4 is already enabled in over 30 games, with support expected to reach 75 titles by yearend. Turning to our embedded segment, first quarter revenue decreased 3% year-over-year to $823 million. Embedded demand continues to recover gradually. We expect improving demand in the test and measurement, communications, and aerospace markets will drive a return to growth in the second half of 2025. We completed initial shipments of our cost-optimized Spartan UltraScale Plus FPGAs, and second-generation Versal AI Edge SoCs to meet growing demand for AI at the Edge. As a part of continuing to grow our embedded x86 business, we launched our EPYC-embedded 9005 series CPUs that deliver leadership performance for networking, storage, and industrial edge applications. Cisco selected our new EPYC-embedded processors for their latest high-end firewall solutions, and IBM is using them to power its latest storage-scale System 6000 for performance-intensive enterprise analytics and AI workloads. We also released our latest Vitis AI software suite, expanding support for the latest models, and accelerating edge AI deployment across a broader range of applications, further strengthening our leadership in the rapidly emerging edge AI market. In summary, our strong first quarter results and second quarter outlook reflect the momentum we are building across our business. While we face some headwinds from the dynamic macro and regulatory environments, including the recently announced export controls for Instinct MI308X shipments to China, we believe they are more than offset by the powerful tailwinds from our leadership product portfolio. Against this backdrop, we remain confident we can deliver strong double-digit-percentage revenue growth in 2025 based on accelerating share gains with our latest generation of Zen 5 EPYC and Ryzen CPUs and Radeon GPUs, and ramping production of our Instinct MI350 series accelerators in the second half of the year to support an expanded set of customers and AI workloads. We also expect full year growth in our semi-custom business, and for our embedded business to return to year-over-year growth in the second half of the year, driven by the reduced inventory levels and improving demand environment. To capitalize on our unprecedented growth opportunities and deliver our next major growth arc, we are expanding investments in our product and technology roadmaps, go-to-market initiatives, and full-stack AI software and data center scale solutions capabilities. We're also doubling down on our execution to deliver, and where possible, accelerate our industry-leading roadmaps. We view the current environment as a strategic opportunity to further differentiate AMD as we deliver an expanding product portfolio that combine leadership compute and AI capabilities for data centers, Edge, PCs, and embedded end devices. Now I'd like to turn the call over to Jean to provide some additional color on our first quarter results. Jean?
Jean Hu: Thank you, Lisa, and good afternoon, everyone. I'll start with a review of our financial results and then provide our current outlook for the second quarter of fiscal 2025. As a reminder, for comparative purposes, our first quarter fiscal year 2025 financial statement disclosures include the combination of our client and the gaming businesses into a single reportable segment to align with how we manage the business. We continue to provide distinct revenue disclosures for our data center, client, gaming, and embedded businesses. We are pleased with our record first quarter revenue of $7.4 billion, exceeding the high end of our guidance, up 36% year-over-year, driven by 57% revenue growth in the data center segment and a 28% revenue growth in the client and the gaming segment. Revenue declined 3% sequentially due to lower revenue in the embedded and data center segments, partially offset by sequential growth in the client and the gaming segment. Gross margin was 54%, up 140 basis points from a year ago. Operating expenses were $2.2 billion, an increase of 28% year-over-year, as we continue to invest aggressively in go-to-market activities and in R&D to address the significant growth opportunities ahead of us. Operating income was $1.8 billion, representing a 24% operating margin. Taxes, increased expenses, and other was $213 million. For the first quarter of 2025, diluted earnings per share was $0.96, an increase of 55% year-over-year. Now turning to our reportable segments, starting with the data center. Data center segment revenue was $3.7 billion, up 57% year-over-year, primarily driven by continued CPU server share gains across both the cloud and enterprise customers, and a strong growth of AMD Instinct GPUs. On a sequential basis, data center segment revenue decreased 5%. Data center segment operating income was $932 million, or 25% of revenue, compared to $541 million, or 23% a year ago. Client and gaming segment revenue was $2.9 billion, up 28% year-over-year, driven primarily by strong customer demand for our latest generation Zen5 AMD Ryzen processors, partially offset by lower semi-customer revenue. Client revenue was $2.3 billion, up 68% year-over-year. More than half of the growth was driven by higher ASPs from a richer mix of high-end Ryzen processors. On a sequential basis, client and gaming segment revenue increased by 2%, primarily driven by stronger than seasonal performance of our client product portfolio, and increased to semi-customer product revenue. Client and gaming segment operating income was $496 million, or 17% of revenue, compared to $237 million, or 10% of year-ago, driven by operating leverage on higher revenue. Embedded segment revenue was $823 million, down 3% year-over-year. Embedded demand continues to recover gradually. Sequentially, embedded was down 11%, consistently without expectations. Embedded segment operating income was $328 million, or 40% of revenue, compared to $342 million, or 41% a year-ago. Turning to the balance sheet and the cash flow. During the quarter, we generated $939 million in cash from operations, and our free cash flow for the quarter was $727 million. We returned $749 million to shareholders through the repurchase of common stock and our repurchase program. We have $4 billion remaining in our share repurchase authorization. At the end of the quarter, cash, cash equivalents and short-term investment was $7.3 billion. Within the quarter, we raised $1.5 billion of debt and issued $950 million of commercial paper to help fund our acquisition of ZT Systems, which was completed on March 31st. Now turn to our second quarter 2025 outlook. As a reminder, in April, a new export license requirement was put in place for MI308 shipments to China, the impact of which is included in our guidance. We expect revenue to be approximately $7.4 billion, plus or minus $300 million. This includes an estimated $700 million revenue reduction as a result of the new export license requirement. Despite this headwind, the middle point of our guidance represents 27% year-over-year revenue growth. For the full year 2025, we estimated the revenue impact due to the export license requirement to be approximately $1.5 billion. Sequentially, we expect client and gaming segment revenue to increase by a double-digit percentage, embed segment revenue to be flattish, and we expect data center segment revenue to decrease due to the exclusion of MI308 revenue. In addition, we expect second quarter non-GAAP gross margin is estimated to be 43%, inclusive of approximately $800 million in charges for inventory and related reserves. Excluding this charge, our non-GAAP gross margin would be approximately 54%. Non-GAAP operating expenses to be approximately $2.3 billion, which includes approximately $50 million in OpEx due to the addition of the ZT System design key. The financials for the ZT manufacturing business will be reported as discontinued operations starting in the second quarter. We expect net interest and other expenses to be $5 million due to the debt associated with the ZT System transaction. Non-GAAP effective tax rate to be 13%, and the diluted share count is expected to be approximately 1.64 billion shares, which includes 9 million shares related to the ZT transaction. Looking forward, despite ongoing macro and trade policy related uncertainties, we believe the investment we are making will position us well to address the large growth opportunities ahead as AI expands the use of high-performance computing across all our end markets. In closing, 2025 is off to a strong start as we continue to execute on key strategic and financial goals. We delivered strong top line revenue growth, expanded gross and operating margins, and closed the key acquisition of ZT Systems to expand and accelerate our data center GPU and systems roadmaps. With that, I'll turn it back to Matt for the Q&A session.
Matt Ramsey : Thank you very much, Jean. John, can you go ahead and pull the callers for the Q&A session, please? Thank you.
Operator: [Operator Instructions] And the first question comes from the line of Joshua Buchalter with TD Cowen.
Joshua Buchalter: Thank you. Thank you for taking my questions, and congrats on the results. I was hoping you may expand on the drivers of upside in both the print and in particular the guide. How should we think about Q2 growth by segment? And I wanted to double-click on client in particular. That business is up 67% year-over-year in the first quarter, and there's obviously a lot of concerns on pull-ins. So, I was hoping you could walk through some of the drivers of the strength in client in particular and how you're thinking about that in Q2. Thank you.
Lisa Su: Okay, great, Josh. Thanks for the question. Look, we were very pleased with our performance in Q1. We actually saw a strength across a number of our businesses. We saw strength certainly in the client business, very strong desktop performance. We saw strength in our gaming business as well, which was really due to our strong Radeon launch. And we also saw some strength in our data center business across both stronger CPU and GPU. So, those are some of the drivers for our Q1 performance. And in particular, on your question of client performance, we've certainly looked very carefully at the ordering patterns and what customers are telling us. We have not seen a lot of tariff-related activity in that business. I would say, though, what we have seen is a real stronger mix in strength in our overall ASPs. So, the desktop channel, which is an area where we have a very strong, gaming products right now, actually performed well above seasonality in Q1. And that is really the strength of the ASPs there. So, that's what we saw in Q1. And then to your question about the guide for Q2, as Jean mentioned, we do have the new export control limitation on MI308. So, we have taken out that revenue, which is a $700 million headwind in Q2. But with that, we have a strong outlook given the strength across the rest of our businesses. So, we continue to see strength in clients going into the second quarter. Again, the desktop business continues to perform above typical seasonality. We're also seeing the beginning of the commercial ramp, which is a place where we have traditionally been quite underrepresented. We see continued strength in gaming. I would say much better than typical seasonality. That is really our AIB business with the Radeon products are ramping, as well as, consoles have now drained all of their inventory. And so they are starting their ramp into the year. And from a data center side, we see sequential growth on the CPU side. We see the GPU right on track, minus the China export controls. And so, for all of those reasons, we're pleased with where the performance of the business is right now.
Jean Hu: Yes, I'll just add one point to what Lisa just said on the client business. We had really strong performance in Q1, especially client revenue is largely flat issue versus Q4. When you look behind it, our unit actually declined a double digit. So the revenue flat issue is largely driven by the ASP increases sequentially due to the richer mix that Lisa just mentioned.
Joshua Buchalter: Thank you for all that color. To follow up, I wanted to ask about how the ex-China, ex-308 Instinct family performed in the quarter and how you're thinking about the back half of the year. I think you mentioned in the prepared remarks, significant double digit year-over-year. Could you maybe provide some color on how Instinct did in the first quarter, how you're thinking about the first half ahead of the 350 ramp in next month? Thank you.
Lisa Su: Sure. So, on the Instinct ramp, I would say a Q1 performance of data center GPU was in line with maybe a little bit better than expected. I think the key point that we've said about the Instinct ramp is I'm very excited about the MI350 launch. We're right on track for that launching mid-year. I would say customer interest has been very high. So from a competitiveness standpoint, we feel really good about where it's positioned. Overall, I think one of the advantages that we have with the MI350 launch is that, from a systems overall environment, it's actually very similar to the MI300. So, we believe it's going to ramp fast. And we already have a couple of deals that have been announced, including a very important relationship with Oracle in terms of the MI350 series for a number of joint customers. So we're excited about the overall AI business. I think we continue to see strength there. I know there are some uncertainties as it relates to tariffs and other things, but this is one of those areas where from an infrastructure standpoint, there continues to be investment in AI infrastructure. And so with that, we would expect strong growth into the second half of the year.
Operator: And the next question comes from the line of Timothy Arcuri with UBS.
Timothy Arcuri: Thanks a lot. Lisa, you said that data center GPU grew significant double digit, but it was like $600 million last March. So I would think that, I mean, I think a lot of us thought it was going to be like 1.7 to 1.75. So is that the wrong way to sort of interpret that? Because it seems like it went up triple digits at least. So can you help us there? And also, I'm curious, the additional $800 million that sort of has to come out from the ban, does that all come out in September or is there some remnants of that that have to come out in the fourth quarter as well?
Lisa Su: Yes, so again, what I would say is the data center GPU business did perform very well in the first quarter. I think we have to go back and look at what you had for first quarter 2024. But overall standpoint, it performed right where we would expect. Relative to your conversation as to where does it come out? I would say the vast majority comes out in the September quarter. So think about, Jean mentioned $1.5 billion, you would see the majority of it in Q2 and Q3 with very little in Q4. So we had always expected that the fourth quarter, because it would be very focused on the MI350 family would be non-China revenue and that's how it was planned.
Timothy Arcuri: Got it, and then Jean, just on the inventory, it was up a lot. Is that just due to ZT or is there something else happening there, thanks.
Jean Hu: Well, on the inventory side, we built some inventory primarily to support very strong client and the server ramp and also the second half data center GPU ramp. As you probably know, the lead time is really long to build for the Q3, Q4 ramp. We really need to start with us right now. That's why the inventory has increased.
Operator: And the next question comes from the line of Harlan Sur with JPMorgan.
Harlan Sur: Hey, good afternoon. Thanks for taking my question. I know there's been a lot of focus in your upcoming MI350 series, Lisa, but MI400 next year is where you potentially close the competitive gap in a big way, right? You're bringing frontier class model training, performance GPU in a RAC scale solution. More and more, the challenges have been standing up these Rack Scale platforms, power, cooling, footprint, networking, connectivity, telemetry, et cetera, right? Lots of well-telegraphed issues with standing up these Rack Scale Architectures. So as you've shared your MI400 Rack Scale Solution Architecture with customers, what is the AMD team doing to potentially address the ease of these deployments with the MI400? And just in general, what's been the overall feedback been like on MI400?
Lisa Su: Yes, Harlan, thank you for the question. I think, look, we're excited about the MI350 series launch that's coming up, but we are extremely excited as well about the MI400 series and the roadmap there. I think we've been very active with customers on our roadmap. As this is one of those areas where you absolutely have to be planning many quarters in advance for that. One of the primary reasons we acquired ZT Systems was exactly to address this Rack Scale Architecture. And so from that standpoint, the closing of the ZT acquisition has been very timely. What we're doing right now is together with our ZT design team, as well as our customers design teams and our own systems design capability, really actively planning what those Rack Scale Systems are going to look like. I would say the MI400 series enthusiasm from customers is high. And there's a lot of activities that are going on right now to ensure that we do in fact learn from some of the, let's call it some of the challenges that have occurred with some of the recent deployments.
Harlan Sur: Thanks for that. And then I continue to be impressed. I mean, seven consecutive quarters of strong year-over-year growth in your EPYC Enterprise and on-prem traction, right? You have high 30s, low 40s type share of the overall server market and enterprise and on-prem. Your share is probably in the sort of low 20% range, but significant share momentum. Can you just remind us like what has the AMD team done? What have you put in place sort of go-to-market wise to drive the strong tailwind here in what has been a very, very tough market segment to crack?
Lisa Su: I think there are a couple of things, Harlan. First of all, the strength of the product cannot be undersold, right? At this moment with fifth-gen EPYC, the overall cloud adoption has been fantastic. And then on the enterprise side, we've really broadened the product portfolio for Turin that includes, let's call it low core count up through the highest core count and frequency ranges. So that's very helpful. But probably the largest impact has been in go-to-market. In the go-to- market space, we have added significant headcount and capability to address end users directly. And with the use cases, I think some of the things that we talked about across industries, we're actually learning from each deployment and replicating that across many of the industrial partners. So overall, I think it's been a strong effort on enterprise and we're really still in the very early stages of that. I would say we're still quite underrepresented enterprise, but with the platform coverage and the processor coverage, I think we feel good about the opportunities.
Operator: And the next question comes from the line of Aaron Rakers with Wells Fargo.
Aaron Rakers: Yes, thanks for taking the question. Going back to kind of the data center business and particularly the GPU business, I think last quarter you had alluded to the fact that you'd expected the data center revenue to be roughly flat in the first half of the year. I guess if we were to take out the $700 million impact from China, would the expectation still be flat for the year? Is that a fair assumption?
Jean Hu: So Aaron, so you're right. Last time we did mention the first half data center GPU, it's flat issue versus second half. The way to think about what Lisa mentioned is the $1.5 billion impact largely will be in Q2 and Q3. And so when you take out $700 million in Q2 and majority in Q3, that is what the impact in Q2 and Q3. But remember what Lisa mentioned is that we do see second half weighted. As we launch MI355, we will see significant ramp. Year-over-year, we see strong double digital growth of our data center business and the GPU business also.
Aaron Rakers: Okay. And then as a quick follow-up, kind of thinking about the gross margin, obviously this quarter's guidance reflective of the charge that you're taking. Should we assume that in the back half with mixed attributes to be considered that you would see a return to that 54 plus percent gross margin in the second half of the year? Is that a fair assessment?
Jean Hu: Yes, Aaron, thank you for the question. Yes, there are a few puts takes on the gross margin. If you think about the Q2, excluding $800 million charge related to the MI308, our gross margin actually is around 54%. So at a company level, right, the mix is less favorable because the client and the gaming business is growing sequentially. But we do have a few drivers to drive the gross margin up. First, as I mentioned earlier, if you look at our client business, the gross margin has been improving because the richer mix of our latest generation product portfolio, that really helps. And also, secondly, within data center, when we expand the enterprise market share, we do see gross margin improvement. Of course, in addition, MI308 data center, GPU gross margin is on the low end of our data center GPU margin. So that also helps us. Overall, when we think about the second half, we actually think the gross margin will improve slightly because data center continues to be very strong growth driver, number one growth driver, second half versus the first half, which will be partially offset by continued strength on the client and the gaming side. Hope that answers your question.
Operator: And the next question comes from the line of Thomas O'Malley with Barclays.
Thomas O'Malley: Hey, Lisa and others. Thanks for taking my question. I really appreciate it. And Jean, thanks for the helpful answer there. I just wanted to understand your view on system-based architectures and whether you feel like you have what you need right now. Obviously, UALink 1.0 is coming out. You can use third party providers to kind of do the interconnect. ZT System does do a lot for you in terms of the system architecture. But from the interconnect side, do you think that you need more? Is that something that you're going to do internally? Look externally? Just want to understand where you think the portfolio is today and whether you can address system-based architectures of what you have today.
Lisa Su: Sure, Tom. Absolutely. I think we feel like we have all the pieces required as well as deep partnerships in the ecosystem. And I consider it a system level optimization between CPU, GPU, networking capability, rack scale architecture. I think all of those pieces are things that we are investing in. And we're also partnering with others in the industry who are offering these capabilities. I think when we look at the architectures that our customers want, our customers are really asking for one, that we have a reference architecture that works, but also that we work with them as they want to interchange various pieces, particularly on the networking side. I think there are a couple of different solutions out there. And we are very much focused on ensuring that we interoperate across the spectrum.
Thomas O'Malley: Helpful. And then if we look at the full year, I mean, we'll get the units with the filing, but it looks like there's some material share gains here in the first quarter. When you look at the full year, just to level set us on share gains versus market growth, could you maybe talk about what you see the client business growing as a base level? And then just, obviously, it's difficult to kind of predict where share will go, but just any comments on what you're seeing thus far is a couple points of shares, kind of what you're seeing in the first quarter as well. We'll get a little more later, but mostly just on the market growth for 2025. Thank you.
Lisa Su: Sure, Tom. So if you're asking about sharing the client business, I think that was the conversation. Look, we are very pleased with our client business performance over the last couple of quarters. I think we are seeing unit growth, particularly in desktop, but where we're seeing probably the most growth is overall revenue share. And so it's, we're gaining share in the right places, which is in, sort of high-end, notebook and commercial as well as in desktop overall. So from that standpoint, that's where we think we're going. As we go through the year, I know there's a good amount of conversation about what happens in the macro and what happens with tariffs and does that change things going forward. We are spending quite a bit of time ensuring that we are aligning with our customers, looking at inventory levels, looking at sort of consumption and overall sell-through. And we believe that we have a good overall inventory position and there is not, let's call it, a tremendous amount of pull-ins or other things that are coming into play. And we will continue to be very agile in how we look at that going forward.
Operator: And the next question comes from the line of Vivek Arya with Bank of America Securities.
Vivek Arya: Thank you. I had two questions as well. On the first one, just near-term, Lisa, did your GPU sales grow sequentially in Q1? How much was MI308 in that number? And if you look at 2025 overall, do you think GPUs can still grow despite the China headwind that you mentioned relative to the $5 billion plus you did last year?
Lisa Su: Yes, sure, Vivek. So let me answer the second question first. We absolutely believe the data center GPU will grow and we think it will grow strong double digits. We had a plan that was second half weighted and it still is. Relative to the MI308 situation, it's certainly a headwind but one which we think is well contained given everything else that we have going on. And relative to the Q1 performance of data center GPU, it was down very modestly from Q4 which is what we expected. We did see good overall demand actually in the first quarter driven by MI325 so we had a significant adoption by a large foundational model company which was very positive there and as we go forward, we expect that we will continue to broaden both customers as well as workloads within our current customers for the Instinct portfolio.
Jean Hu: And Vivek, in Q1, MI325 and MI300 will achieve a majority of our revenue.
Vivek Arya: Great. And then longer term, Lisa, in the past you described I believe almost a $500 billion or so addressable market for AI accelerators. How much of that roughly is China because that now seems to be somewhat restricted for US companies and then also kind of related to that how should we think about these AI diffusion rules that I think there is an implementation date that is coming up on May 15th. I'm curious what you have heard. So just sort of the implication of China restrictions and these AI diffusion rules on thinking about the addressable opportunity for you longer term. Thank you.
Lisa Su: So, Vivek, I think it's a good question. I think overall it is a very dynamic market so you will appreciate that. On the China export controls, I think, we always expected that there would be some amount of what's called limitation on sort of leading edge GPUs going into China. So that was factored into our TAM expectation when we talked about $500 billion. So I don't think that dramatically changes the TAM. But what I will say is on the AI diffusion side we're very actively working with the government as they're thinking through these rules and it's a very fine balance that we have to have. At the end of the day when we look at sort of the US AI companies, we have leading edge technology. We want to ensure that the rest of the world can really use us as the primary platform. So I think it will be important to work through the AI diffusion rules and all of that as we think about longer term TAM. We're certainly spending quite a bit of efforts trying to ensure that it's well understood the importance of the overall ecosystem and having the rest of the world really adopt the US ecosystem given our strength and leadership overall.
Operator: And the next question comes from C J Muse with Cantor Fitzgerald.
C J Muse: Yes, good afternoon. Thank you for taking the question. I wanted to revisit your assumptions around client. If you were to just flat line the Q1 actual, you would grow the business above 30%, you're obviously very bullish on taking share. You talked about huge tailwinds from ASPs. But curious when you put it all together, how should we think about traditional seasonality into the second half particularly with the potential of some pulling here in the first half?
Lisa Su: Sure, CJ. It's a fair question. Look, we want to be very clear that our client business performance is primarily driven by the strength of the product portfolio and it's driven by some of the desktop channel products that traditionally are not so well tracked. If you look at sort of the IDCs of the world, we are planning for let’s call it second half sub seasonal given we're off to a strong start in the first half of the year. And that is what we are putting into our sort of internal planning number. So, you wouldn't see necessarily typical seasonality since the first half is better than seasonal. That being the case, I think we feel strongly that from a consumption base standpoint, we can see the data. So when we look at the Q1 performance, it was a very, very strong Q1 in terms of sellout and consumption for our desktop business. And as we start Q2, we are now four weeks into it, we see those patterns continuing. So, we're in an upgrade cycle right now. Gaming CPUs are usually purchased when they are gaming CPUs that come out in new cycles. And I think we're benefiting from that on both the CPU and GPU side which is great. I mean we are very happy with that. And we're ramping up production to ensure we keep the channel full.
C J Muse: Very helpful. And then I guess looking to next year, can you talk about 400 series and rack level solution, go-to-market strategy? You talked about kind of trying to obtain partners. Is there a certain number you're targeting? And then how are you thinking about kind of getting through learning curve challenges of getting the rack scale working with your OEM partners such that you can deliver that ramp in 2026? Thanks so much.
Lisa Su: Of course, CJ. I think the right answer is we're getting a very early start. That's what we have to do so that we maximize the overall learning cycle that is required for rack scale solutions. We are working very closely with a number of our hyperscale partners today to define those solutions and make sure that we're thinking about the various areas that could require work. And we're also working with our OEM partners who also have, let’s call, learned quite a bit over the past couple of months and quarters as other rack scale solutions have been coming online. So, I think we're doing everything to move, let’s call it, move ahead of the learning cycle. And again, we have the benefit of the MI350 series being a relatively, let’s call it, not large list. So the And so the focus on the rack scale stuff is on MI400.
Operator: And the next question comes from Stacy Rasgon with Bernstein Research.
Stacy Rasgon: Hi, guys. Thanks for taking my questions. For the first one, given the China data center GPU headwinds in Q2 and Q3, do you think that GPU business actually grows year-over-year in Q2 and Q3? Understanding your comments for the full year on it. But do you think given those headwinds in Q2 and Q3 it can actually grow year-over-year?
Lisa Su: I think you're, let's see, Stacy, the best way to answer that question is in Q2 it's not going to grow year-over-year. Just given what we said about the $700 million coming out of Q2 and how we had previously talked about the evolution. But we do believe that it will grow year-over-year going forward in Q3 and Q4 certainly for us to do the full year with strong double-digit growth.
Stacy Rasgon: Okay. So you do think it can grow year-over-year in Q3. Okay. For my second question, I wanted to ask about kind of the trends in Q1. So you said it was data center GPU was down I guess modestly in Q1 as expected. But again if I go back to your sort of double-digit year-over-year comments, I mean, it couldn't have been any more than like $1.4 billion in Q1 for this [inaudible] and it feels like it's less than that. Which mean it would have down at least 20% sequentially maybe more which also implies the server CPUs in Q1 were up sequentially which is also well above seasonal similar to clients. I guess what I'm asking is are those trends correct? Am I modeling that correct? And I guess what are the implications in that case of server CPUs actually up well above seasonal in Q1 given this environment?
Jean Hu: No, I think Stacy, this is Jean, I think when you think about the Q1 data center performance it's declined 5%. So it's a little bit better from server perspective because it is declined sequentially. Same thing like data center GPU like Lisa mentioned earlier it did decline. So I think that is the overall data center performance. I think I don't know about your model but that is how we really look at the numbers how we think about it.
Operator: And the next question comes from the line of Ross Seymore with Deutsche Bank.
Ross Seymore: Hi guys, thanks for letting me ask a couple questions. Kind of going to go to the embedded space. I know it's not the biggest one but everything else has been addressed pretty detailed. You mentioned the second half getting up to year-over-year growth. Seems like that requires significant double digit growth sequentially in both quarters just to get the full half there. What gives you confidence in that sort of ramp?
Jean Hu: Ross, thank you for the question. On embedded side, we started to see gradual recovery. I think there are signs, especially the order pattern, the book to bill ratios, we see improving. Like aerospace and defense and also test measurement side, we see very visible improvement. Industrial side, the improvement is less so. There is inventory still among different customers. Overall, the trend, the demand pattern does improve. I think Q2, we did guide sequentially flattish and I think we start to see Q3, especially Q4, you will see year-over-year increase especially in Q4.
Ross Seymore: Great. Thanks for that. I guess this is my last question is on the OpEx side of things. You guided to the over number for the second quarter, $2.3 billion. You said there is $50 million from ZT in there. Is that the entirety of the ZT side of things? Or what should we think for kind of full year OpEx for the second half, however, you want to discuss it.
Jean Hu: Yes, Ross, thank for the question. For the ZT, design team, we view it as quarterly that incremental OpEx is about $50 million. That $2.3 billion includes everything from ZT because we closed the transaction on March 31st. I think when you look at the overall OpEx increase year-over-year, we continue to drive revenue growth to increase more than OpEx. Looking at Q2 at the middle point of our guidance revenue will be increasing 27% and we do expect the earnings per share growing much faster than the top line revenue growth. So OpEx side will be very disciplined to continue to manage it.
Matt Ramsey : Operator, I think we have time for one more caller. Thank you.
Operator: No problem. And the final question comes from the line of Joe Moore with Morgan Stanley.
Joe Moore: Great, thank you. One of the things your cloud customers have been talking about is this kind of growth in inference costs this sort of reasoning model using lot of inference compute and sometime tightness. Can you talk about that from AMD perspective? Are you seeing that in your business? Does that change the focus you’ve going forward?
Lisa Su: Sure, Joe. So I think overall what we're seeing is with these new reasoning models, the inferencing is more important. And there is also a move to more distributed inferencing. So, I think that plays into our strengths. I think, we have demonstrated that with MI300 that we are an excellent inference solution. And that holds true for 35 and 353 series as well. So, we continue to see with our memory bandwidth and memory capacity advantages that's a positive. I will say that as we're going into this, the number of workloads that we're seeing overall is expanding. So, we're seeing both training and inferencing as important workloads that we're working on. And our customers continue to demonstrate. I think the desire that we're seeing probably from a trend standpoint is that there are many models that people are using today. So, they're not necessarily using one model. They're actually using several different models. So, the optimizations around that are the things we're doing with our ROCm software suite.
Joe Moore: Great. Just an update on your thoughts on competing with custom silicon with A6 in AI space. Most of your largest customers also have a custom silicon offering. So will they invest in both AMD and A6 and just how do they decide how to apportion that investment?
Lisa Su: Joe, I mean I view them as really two different things. I think, one of the primary aspects as we talk about the $500 billion TAM and the opportunities there. Look, we think A6 have a place. We happened to think GPUs have a larger piece of that because the models are changing so much. And from our standpoint, it's really important to have competitive TCOs and people want choice to get there especially as inference costs become so important and we're working on trying to expand the overall inferencing sort of capability out there. So, I don't think it's an either or. I think it's a let's get the best solutions out there and we will certainly believe that we're very competitive in inferencing and I think we're also becoming a much more solution for training as well.
Operator: Ladies and gentlemen, that does conclude the question-and-answer session. And that also concludes today's teleconference. We thank you for your participation. You may disconnect your lines at this time.",2025-05-06
